<!DOCTYPE html>
<html lang="en"><head>
<script src="07_textAnalysisII_files/libs/clipboard/clipboard.min.js"></script>
<script src="07_textAnalysisII_files/libs/quarto-html/tabby.min.js"></script>
<script src="07_textAnalysisII_files/libs/quarto-html/popper.min.js"></script>
<script src="07_textAnalysisII_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="07_textAnalysisII_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="07_textAnalysisII_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="07_textAnalysisII_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="07_textAnalysisII_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="07_textAnalysisII_files/libs/quarto-contrib/videojs/video.min.js"></script>
<link href="07_textAnalysisII_files/libs/quarto-contrib/videojs/video-js.css" rel="stylesheet">
<script src="07_textAnalysisII_files/libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="07_textAnalysisII_files/libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="07_textAnalysisII_files/libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.4.533">

  <meta name="author" content="胡悦">
  <title>文本的数据分析进阶</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="07_textAnalysisII_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="07_textAnalysisII_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="07_textAnalysisII_files/libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="https://www.drhuyue.site/slides_gh/css/style_basic.css">
  <link href="07_textAnalysisII_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="07_textAnalysisII_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="07_textAnalysisII_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="07_textAnalysisII_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="https://gitlab.com/sammo3182/backup/raw/85b3c1ad4b459d7a9f901f124b936428eda5fcaf/logo_THPS.png?inline=true" data-background-position="top 10% right 5%" data-background-size="250px" class="quarto-title-block center">
  <h1 class="title">文本的数据分析进阶</h1>
  <p class="subtitle">政务大数据应用与分析 (80700673)</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
胡悦 
</div>
        <p class="quarto-title-affiliation">
            清华大学社会科学学院
          </p>
    </div>
</div>

</section>
<section id="个人简介" class="slide level2 Small">
<h2>个人简介</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p><em>个人经历</em></p>
<ul>
<li>政治学博士<span class="small">（University of Iowa)</span>
<ul>
<li>信息学<span class="small">（Graduated Certificate in Informatics)</span></li>
</ul></li>
<li>清华大学计算社会科学平台<span class="small">(副主任)</span>
<ul>
<li>清华数据与治理中心<span class="small">(副主任)</span></li>
<li>计算社会科学编程语言证书项目<span class="small">（负责人）</span></li>
<li>Learning R with Dr.&nbsp;Hu &amp; Friends 工作坊<span class="small">（创始人）</span></li>
</ul></li>
</ul>
<div class="fragment">
<p><em>研究兴趣：认知、行为与现代性</em></p>
<ul>
<li><strong>方法路径：计算政治学</strong>
<ul>
<li>实验室和调查实验</li>
<li>潜变量分析、网络分析、空间分析</li>
<li>文本大数据分析、数据可视化</li>
</ul></li>
</ul>
</div>
</div><div class="column fragment" style="width:40%;">
<p><em>研究领域：比较政治、国家治理</em></p>
<ul>
<li><strong>W. 心理学</strong>
<ul>
<li>政治<span class="red">认知</span>治理</li>
<li>行为公共<span class="red">政策</span></li>
<li>政治传播</li>
</ul></li>
<li><strong>W. 经济学</strong>
<ul>
<li>经济不平等<span class="red">感知</span></li>
<li>公共设施、服务均等化</li>
</ul></li>
<li><strong>W. 语言学</strong>
<ul>
<li>权力背书的<span class="red">语言效果</span>与机制</li>
<li>语言政策的治理功能</li>
</ul></li>
</ul>
</div>
</div>
</section>
<section id="复习" class="slide level2">
<h2>复习</h2>
<blockquote>
<p><span class="citation" data-cites="King2015">King (<a href="#/参考文献" role="doc-biblioref" onclick="">2015</a>)</span>: [The big-data approach is] the <span class="red">end</span> of the quantitative-qualitative divide.</p>
</blockquote>
<aside class="notes">
<p>King talked about this issue in many places including Shanghai Jiaotong University</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="columns">
<div class="column fragment" style="width:50%;">
<p>你应该已经知道……</p>
<ul>
<li>你能用文本数据做什么
<ul>
<li>你分析的是文字还是语言？</li>
<li>Close reading or distant reading？</li>
<li>文本/音频/视频分析的理论基础是什么？</li>
</ul></li>
<li>如何获取数据
<ul>
<li>文本数据的获取渠道有哪些？</li>
<li>网络爬取与正则表达式</li>
</ul></li>
</ul>
</div><div class="column fragment" style="width:50%;">
<ul>
<li>如何处理数据
<ul>
<li>如何结构化文本数据？</li>
<li>文本预处理的步骤有哪些</li>
<li>Tokenization的两种含义是什么？</li>
</ul></li>
<li>如何分析数据
<ul>
<li>词频能分析出什么？</li>
<li>如何鉴别关键词？</li>
<li>词的相似度？</li>
<li>主题模型在干什么？
<ul>
<li>Bag of Words (BOW)?</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</section>
<section id="提要" class="slide level2">
<h2>提要</h2>
<p>学完本课，你将了解:</p>
<div style="text-align:center">
<ul>
<li>如何捕捉“草蛇灰线”：<em>词汇层级</em>信息汇入</li>
<li>如何提升主题模型质量：<em>概念层级</em>信息汇入</li>
<li>词嵌入和LLM干了什么：<em>语义层级</em>信息汇入</li>
</ul>
<p><span class="fragment large">本讲的核心议题：<span class="red">突破词基限制，纳入有用信息</span></span></p>
</div>
<div class="fragment">
<div class="callout callout-warning callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Warning</strong></p>
</div>
<div class="callout-content">
<ul>
<li class="fragment">学习本课内容，你不需要编程知识😱</li>
<li class="fragment">应用本课内容，你需要一种编程知识😜
<ul>
<li class="fragment"><a href="https://www.drhuyue.site/course/method-series/04-r-workshop/">如果你想学……</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>
</section>
<section>
<section id="问题源头" class="title-slide slide level1 center">
<h1>问题源头</h1>

</section>
<section id="让计算机读懂人言的代价" class="slide level2">
<h2>让计算机读懂人言的代价</h2>
<div class="r-stack">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://drhuyue.site:10002/sammo3182/figure/text_bagOfWords.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img data-src="https://drhuyue.site:10002/sammo3182/figure/text_bagOfWords.png" class="quarto-figure quarto-figure-center" height="400"></a></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://drhuyue.site:10002/sammo3182/figure/theory_bagOfWords2.jpg" class="lightbox" data-glightbox="description: .lightbox-desc-2" data-gallery="quarto-lightbox-gallery-2" title="Document-Term Matrix (DTM)"><img data-src="https://drhuyue.site:10002/sammo3182/figure/theory_bagOfWords2.jpg" class="fragment quarto-figure quarto-figure-center" height="600" alt="Document-Term Matrix (DTM)"></a></p>
<figcaption>Document-Term Matrix (DTM)</figcaption>
</figure>
</div>
</div>
<aside class="notes">
<p>In linguistics, the opposite of natural language is artificial/constructed language (conlangs), like Klingon in “Star Trek,” Dothraki in “Game of Thrones”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="丢失了什么" class="slide level2">
<h2>丢失了什么</h2>
<div class="fragment large" style="text-align:center; margin-top: 2em">
<ul>
<li>词的重要性</li>
<li>语序/位置</li>
<li>虚词</li>
<li>语法</li>
<li>Meta data</li>
</ul>
</div>
</section></section>
<section>
<section id="词汇层级信息汇入" class="title-slide slide level1 center">
<h1>词汇层级信息汇入</h1>

</section>
<section id="加权" class="slide level2">
<h2>加权</h2>
<p>DTM的问题：</p>
<ol type="1">
<li>未将词的重要性纳入考量</li>
<li>过度体现常见词</li>
<li>轻视少见词</li>
</ol>
<div class="fragment">
<p>举例：Term frequency-inverse document frequency (TF-IDF)</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><span class="math display">\[\displaystyle \mathrm {tf} (t,d)={\frac {f_{t,d}}{\sum _{t'\in d}{f_{t',d}}}},\]</span> where <span class="math inline">\(f_{t,d}\)</span> is the number of times that term t occurs in document d.&nbsp;</p>
</div><div class="column" style="width:50%;">
<p><span class="math display">\[\displaystyle \mathrm {idf} (t,D)=\log {\frac {N}{|\{d:d\in D{\text{ and }}t\in d\}|}},\]</span></p>
<ul>
<li><span class="math inline">\(N\)</span>: total number of documents; D.</li>
<li><span class="math inline">\(|\{d\in D:t\in d\}|\)</span> : number of documents where the term <span class="math inline">\(t\)</span> appears.</li>
</ul>
</div>
</div>
</div>
<aside class="notes">
<p>TF： Importance of a term in a document IDF： Frequency a term appear across documents</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="加权带来什么" class="slide level2">
<h2>加权带来什么</h2>
<ul>
<li>好处：
<ol type="1">
<li>识别重要词汇</li>
<li>减少常见词汇的权重</li>
<li>提高机器学习性能 (why?)</li>
</ol></li>
</ul>
<div class="fragment">
<ul>
<li>副作用：
<ol type="1">
<li>假定词汇独立（与DTM相同）</li>
<li>对在语料库中非常罕见但在特定文档中出现过几次的罕见词汇给予高权重</li>
<li>对语料库的大小和多样性敏感</li>
</ol></li>
</ul>
</div>
</section>
<section id="n-gram分析" class="slide level2">
<h2>N-gram分析</h2>
<ul>
<li>Markov Model of Order N
<ul>
<li>Unigram: 清华 大学 社会 科学 学院</li>
<li>Bigram: 清华大学 大学社会 社会科学 科学 学院</li>
<li>Trigram：清华大学社会 大学社会科学 社会科学学院</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://drhuyue.site:10002/sammo3182/figure/text_ngram.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img data-src="https://drhuyue.site:10002/sammo3182/figure/text_ngram.png" class="fragment quarto-figure quarto-figure-center" height="400"></a></p>
</figure>
</div>
</section>
<section id="搭配分析" class="slide level2">
<h2>搭配分析</h2>
<ul>
<li>连续搭配（Contiguous collocations）：在文本中直接相邻出现。</li>
<li>揭示语言使用中的模式，这些模式从查看单个单词时并不立即明显。</li>
</ul>
<p>示例数据：2012年到2016年的6,000篇《卫报》新闻文章</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Corpus consisting of 6,000 documents and 9 docvars.
text136751 :
"London masterclass on climate change | Do you want to unders..."

text118588 :
"As colourful fish were swimming past him off the Greek coast..."

text45146 :
"FTSE 100 | -101.35 | 6708.35 | FTSE All Share | -58.11 | 360..."

text93623 :
"Australia's education minister, Christopher Pyne, has vowed ..."

text136585 :
"block-time published-time 3.05pm GMT | The former leader of ..."

text65682 :
"Darren Wilson will be unable to return to work as a police o..."

[ reached max_ndoc ... 5,994 more documents ]</code></pre>
</div>
</div>
</section>
<section id="collocation-示例" class="slide level2">
<h2>Collocation 示例</h2>
<ul>
<li>最常见的词对（pairs of words）</li>
<li>最常见的三词模式（three-word patterns）</li>
</ul>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>       collocation count count_nested length    lambda         z
1    david cameron   861            0      2  8.186347 147.76683
2     donald trump   774            0      2  8.353969 123.09383
3   george osborne   364            0      2  8.687785 107.95642
4  hillary clinton   526            0      2  9.125811 102.77388
5         new york  1016            0      2 10.474860 100.52567
6    islamic state   330            0      2  9.829185  98.41582
7      white house   478            0      2  9.938355  96.56095
8   european union   351            0      2  8.288569  95.07175
9    jeremy corbyn   244            0      2  8.756533  91.07510
10   boris johnson   245            0      2  9.691163  85.00475</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                  collocation count count_nested length     lambda          z
1             new south wales    85            0      3  8.9133533  4.3907828
2       european central bank    95            0      3  4.4049316  4.3095051
3 international monetary fund   101            0      3  2.2155907  1.0661709
4               new york city    96            0      3  1.0061265  0.6134988
5      photograph mike bowers    90            0      3  0.5209553  0.3473888
6              new york times   128            0      3 -0.5342360 -0.3516073</code></pre>
</div>
</div>
</section>
<section id="靶向分析" class="slide level2">
<h2>“靶向”分析</h2>
<ul>
<li>关键性(Keyness)：识别在目标语料库中比在参照语料库中<strong>统计上更频繁</strong>出现的词语的度量方法 <span class="citation" data-cites="Gabrielatos2018">(<a href="#/参考文献" role="doc-biblioref" onclick="">Gabrielatos 2018</a>)</span>。</li>
</ul>
<p>示例1：对比《卫报》新闻2016年与2012—2015年之间的新闻</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><a href="07_textAnalysisII_files/figure-revealjs/keyness-out-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img data-src="07_textAnalysisII_files/figure-revealjs/keyness-out-1.png" width="960"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="keyness-示例2" class="slide level2">
<h2>Keyness 示例2</h2>
<p>在2012年到2016年的6,000篇《卫报》新闻文章中与欧盟（“EU”, “europ*“,”european union”）相关的词汇</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><a href="07_textAnalysisII_files/figure-revealjs/relevantKey-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img data-src="07_textAnalysisII_files/figure-revealjs/relevantKey-1.png" width="960"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="入木三分分析-liu2022" class="slide level2">
<h2>“入木三分”分析 <span class="citation" data-cites="Liu2022">(<a href="#/参考文献" role="doc-biblioref" onclick="">Liu 2022</a>)</span></h2>
<div class="r-stack">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://drhuyue.site:10002/sammo3182/figure/text_pronoun.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img data-src="https://drhuyue.site:10002/sammo3182/figure/text_pronoun.png" class="quarto-figure quarto-figure-center" height="400"></a></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://drhuyue.site:10002/sammo3182/figure/css_liwcTree.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img data-src="https://drhuyue.site:10002/sammo3182/figure/css_liwcTree.png" class="fragment quarto-figure quarto-figure-center" height="600"></a></p>
</figure>
</div>
</div>
</section>
<section id="小结" class="slide level2">
<h2>小结</h2>
<div style="text-align:center; margin-top: 2em">
<ul>
<li>Weighing ← 从<span class="red">词频</span>攫取信息</li>
<li>N-gram ← 从<span class="red">邻居</span>攫取信息</li>
<li>Collocation ← 从<span class="red">共现</span>攫取信息</li>
<li>Keyness ← 从<span class="red">关键词定位</span>攫取信息</li>
<li>Functional words ← 从<span class="red">社会心理</span>攫取信息</li>
</ul>
</div>
</section></section>
<section>
<section id="概念层级信息汇入" class="title-slide slide level1 center">
<h1>概念层级信息汇入</h1>

</section>
<section id="主题模型能干什么" class="slide level2">
<h2>主题模型能干什么</h2>
<video id="video_shortcode_videojs_video1" height="600" class="video-js vjs-default-skin " controls="" preload="auto" data-setup="{}" title="What happened in topic modeling"><source src="https://drhuyue.site:10002/sammo3182/video/theory_topicModeling.webm"></video>
<aside class="notes">
<p>基于词频与共线的unsupervised降维，是一种frequency-based的降维</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="主题模型缺什么" class="slide level2">
<h2>主题模型缺什么</h2>
<blockquote>
<p>“他的脸突然被魔杖的光照亮了。这是一张因痛苦、恐惧和愤怒而变得生动的脸。红色的眼睛向那个看不见的男孩站着的地方射去，他的隐形斗篷遮住了他。他的声音，当他发出声音时，就像一个冬天的夜晚一样冷。他说，“我回来了，比以前更强大了。”</p>
</blockquote>
<aside class="notes">
<p>哈利波特与火焰杯</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="large fragment" style="text-align:center">
<ul>
<li>主题之间的联系</li>
<li>篇章之间的联系</li>
<li>内容背景知识（外部信息）</li>
</ul>
</div>
<div class="large fragment" style="text-align:center">
<p>↓<br>
STM/SeedLDA/keyATM</p>
</div>
</section>
<section id="correlated-topic-model-ctm" class="slide level2">
<h2>Correlated Topic Model (CTM)</h2>
<p>主题之间彼此关联被纳入考量</p>
<div class="r-vstack">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://drhuyue.site:10002/sammo3182/figure/cluster_ldaDiagram.png" class="lightbox" data-glightbox="description: .lightbox-desc-8" data-gallery="quarto-lightbox-gallery-8" title="LDA"><img data-src="https://drhuyue.site:10002/sammo3182/figure/cluster_ldaDiagram.png" class="quarto-figure quarto-figure-center" height="150" alt="LDA"></a></p>
<figcaption>LDA</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://drhuyue.site:10002/sammo3182/figure/cluster_ctmDiagram.png" class="lightbox" data-glightbox="description: .lightbox-desc-9" data-gallery="quarto-lightbox-gallery-9" title="CTM"><img data-src="https://drhuyue.site:10002/sammo3182/figure/cluster_ctmDiagram.png" class="quarto-figure quarto-figure-center" height="150" alt="CTM"></a></p>
<figcaption>CTM</figcaption>
</figure>
</div>
</div>
<p><span class="math display">\[\{\mu,\Sigma\}\sim N(\mu,\Sigma).\]</span></p>
<aside class="notes">
<p>CTM模型（correlated topic model）的进步之处在于哪里呢？</p>
<p>最初人们做LDA模型的时候，人们认为不同的主题之间是不存在什么联系的，但这是不可能的。 想象一下，我们可以从《人民日报》提炼出关于经济发展、民生工程等主题，但是我们绝对不可能从中抽取出关于妇科广告的主题，因为这是这份报纸的性质决定的。 所以我们从语料中抽取出来的主题，彼此之间肯定是具有高度的相关性的。</p>
<p>CTM的名字中之所以有一个correlated，就是因为这个模型可以把所有的主题放在一起，放在一个结构（structure）里面去理解每一个主题。 因此CTM是一种层次化主题模型，它明确抓取了主题间的潜在相关性。</p>
<p>相比于LDA，CTM模型多了两个参数μ &amp; Σ：一个K维的均值和协方差矩阵 <span class="math inline">\(\{\mu,\Sigma\}\sim N(\mu,\Sigma)\)</span>。</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="sparse-additive-generative-model-sage" class="slide level2">
<h2>Sparse Additive Generative Model (SAGE)</h2>
<p>每个主题都被赋予一个模型，能够描述给予恒定背景分布对数频率的偏差。</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://drhuyue.site:10002/sammo3182/figure/cluster_sageDiagram.png" class="lightbox" data-glightbox="description: .lightbox-desc-10" data-gallery="quarto-lightbox-gallery-10" title="SAGE"><img data-src="https://drhuyue.site:10002/sammo3182/figure/cluster_sageDiagram.png" class="quarto-figure quarto-figure-center" height="400" alt="SAGE"></a></p>
<figcaption>SAGE</figcaption>
</figure>
</div>
</section>
<section id="structure-topic-model-stm-robertsetal2013" class="slide level2">
<h2>Structure Topic Model <span class="citation" data-cites="RobertsEtAl2013">(STM, <a href="#/参考文献" role="doc-biblioref" onclick="">Roberts et al. 2013</a>)</span></h2>
<p>CTM + SAGE</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://drhuyue.site:10002/sammo3182/figure/cluster_stmDiagram.png" class="lightbox" data-glightbox="description: .lightbox-desc-11" data-gallery="quarto-lightbox-gallery-11" title="STM"><img data-src="https://drhuyue.site:10002/sammo3182/figure/cluster_stmDiagram.png" class="quarto-figure quarto-figure-center" height="500" alt="STM"></a></p>
<figcaption>STM</figcaption>
</figure>
</div>
</section>
<section id="操作" class="slide level2">
<h2>操作</h2>
<p>示例：美国总统就职演说数据</p>
<ol type="1">
<li>设定主题数目</li>
</ol>
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><a href="07_textAnalysisII_files/figure-revealjs/stm-searchKresult-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img data-src="07_textAnalysisII_files/figure-revealjs/stm-searchKresult-1.png" width="960"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="主题归类" class="slide level2">
<h2>2. 主题归类</h2>
<p><span class="math display">\[Topic \sim Party + s(Year).\]</span></p>
<div class="cell" data-exercise="true" data-exercise.setup="stm-searchKresult">
<div class="cell-output cell-output-stdout">
<pre><code>Topic 1 Top Words:
     Highest Prob: ,, ., us, world, america 
     FREX: story, thank, americans, :, moment 
     Lift: —, 1980, 30, 50th, adventure 
     Score: story, americans, thank, –, senator 
Topic 2 Top Words:
     Highest Prob: ,, ., ;, government, people 
     FREX: case, parties, measures, former, circumstances 
     Lift: 120,000,000, 14th, 1774, 1778, 1801 
     Score: fellow-citizens, case, revenue, roman, academies 
Topic 3 Top Words:
     Highest Prob: ,, ., people, government, upon 
     FREX: partisan, ballot, citizenship, patriotic, commercial 
     Lift: 1780, 1790, 1880, 1886, 1890 
     Score: revenue, ballot, arrive, policy, patriotic </code></pre>
</div>
</div>
<ul>
<li>Highest Prob：高频词</li>
<li>FREX：主题高频词</li>
<li>lift：通过词语在其他主题中的频率相除来加权词语</li>
<li>score：将词语在主题中的对数频率除以词语在其他主题中的对数频率</li>
</ul>
<aside class="notes">
<p>这行代码为我们返回了每个主题下面的一些词语。</p>
<ul>
<li><p>“Highest Prob”指的是这个<em>语料库</em>中频率最高的词语，我们可以看到出现了逗号和句号，还有“america”等。</p></li>
<li><p>FREX矩阵（FREX matrix）中的词语依然是高频词，但是它是仅在这个主题中的高频词，也就是能够区分这一主题和其他主题之间特殊性的高频词。 它的算法是通过词语的整体频率及其对主题的专有程度来加权词语。</p></li>
<li><p>提升（lift）：与FREX相同，但是算法不一样，它通过词语在其他主题中的频率相除来加权词语，因此给在其他主题中较少出现的词语赋予更高的权重。</p></li>
<li><p>赋分（score）：与FREX相同，但是算法是将词语在主题中的对数频率除以词语在其他主题中的对数频率。</p></li>
</ul>
<p>所以我们通常建议大家，当你去对于每个主题的含义进行解释的时候，可以基于FREX，lift和score来解读，而不是只看高频词去解释它的含义，也就是说我们讲的这三个测量这是帮助我们去解读主题用的。</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="主题相关性" class="slide level2">
<h2>3. 主题相关性</h2>
<p>以余弦相似度来计算相关性，越接近于1表示两个主题越相关，越接近于0表示两个主题越不相关。</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><a href="07_textAnalysisII_files/figure-revealjs/topicCorrelation-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img data-src="07_textAnalysisII_files/figure-revealjs/topicCorrelation-1.png" width="960"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="协变量的影响党派" class="slide level2">
<h2>协变量的影响：党派</h2>
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><a href="07_textAnalysisII_files/figure-revealjs/covariateParty-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img data-src="07_textAnalysisII_files/figure-revealjs/covariateParty-1.png" width="960"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="协变量的影响时间" class="slide level2">
<h2>协变量的影响：时间</h2>
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><a href="07_textAnalysisII_files/figure-revealjs/covariateTime-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img data-src="07_textAnalysisII_files/figure-revealjs/covariateTime-1.png" width="960"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="seed-lda" class="slide level2">
<h2>Seed LDA</h2>
<p>以种子词（seeds）引领主题分类。</p>
<p>示例数据：《卫报》2016</p>
<p>种子词：经济、政治、社会、外交和军事，基于对该类新闻的认知获取</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Dictionary object with 5 key entries.
- [economy]:
  - market*, money, bank*, stock*, bond*, industry, company, shop*
- [politics]:
  - lawmaker*, politician*, election*, voter*
- [society]:
  - police, prison*, school*, hospital*
- [diplomacy]:
  - ambassador*, diplomat*, embassy, treaty
- [military]:
  - military, soldier*, terrorist*, marine, navy, army</code></pre>
</div>
</div>
</section>
<section id="效果比较lda" class="slide level2">
<h2>效果比较：LDA</h2>
<div class="cell">
<div class="cell-output-display">
 

  
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>tinytable_rpeg57vu8e3i5pn6ktmz</title>
    <style>
.table td.tinytable_css_gqi82jn5h08ylmwr4wkv, .table th.tinytable_css_gqi82jn5h08ylmwr4wkv {    border-bottom: solid 0.1em #d3d8dc; }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      }
    };
    </script>
  

  
    <div class="container">
      <table class="table table-borderless" id="tinytable_rpeg57vu8e3i5pn6ktmz" style="width: auto; margin-left: auto; margin-right: auto;" data-quarto-disable-processing="true">
        <thead>
        
              <tr>
                <th scope="col">topic1</th>
                <th scope="col">topic2</th>
                <th scope="col">topic3</th>
                <th scope="col">topic4</th>
                <th scope="col">topic5</th>
              </tr>
        </thead>
        
        <tbody>
                <tr>
                  <td>labor     </td>
                  <td>refugees</td>
                  <td>violence</td>
                  <td>clinton</td>
                  <td>oil    </td>
                </tr>
                <tr>
                  <td>corbyn    </td>
                  <td>syria   </td>
                  <td>officers</td>
                  <td>sanders</td>
                  <td>markets</td>
                </tr>
                <tr>
                  <td>australian</td>
                  <td>brussels</td>
                  <td>prison  </td>
                  <td>cruz   </td>
                  <td>climate</td>
                </tr>
                <tr>
                  <td>budget    </td>
                  <td>isis    </td>
                  <td>victims </td>
                  <td>obama  </td>
                  <td>energy </td>
                </tr>
                <tr>
                  <td>johnson   </td>
                  <td>talks   </td>
                  <td>hospital</td>
                  <td>hillary</td>
                  <td>sales  </td>
                </tr>
                <tr>
                  <td>turnbull  </td>
                  <td>un      </td>
                  <td>sexual  </td>
                  <td>trump's</td>
                  <td>food   </td>
                </tr>
                <tr>
                  <td>australia </td>
                  <td>syrian  </td>
                  <td>cases   </td>
                  <td>bernie </td>
                  <td>prices </td>
                </tr>
                <tr>
                  <td>leadership</td>
                  <td>military</td>
                  <td>child   </td>
                  <td>ted    </td>
                  <td>rates  </td>
                </tr>
        </tbody>
      </table>
    </div>

    <script>
      function styleCell_tinytable_jhrcai5qdacfrgdjgw9y(i, j, css_id) {
        var table = document.getElementById("tinytable_rpeg57vu8e3i5pn6ktmz");
        table.rows[i].cells[j].classList.add(css_id);
      }
      function insertSpanRow(i, colspan, content) {
        var table = document.getElementById('tinytable_rpeg57vu8e3i5pn6ktmz');
        var newRow = table.insertRow(i);
        var newCell = newRow.insertCell(0);
        newCell.setAttribute("colspan", colspan);
        // newCell.innerText = content;
        // this may be unsafe, but innerText does not interpret <br>
        newCell.innerHTML = content;
      }
      function spanCell_tinytable_jhrcai5qdacfrgdjgw9y(i, j, rowspan, colspan) {
        var table = document.getElementById("tinytable_rpeg57vu8e3i5pn6ktmz");
        const targetRow = table.rows[i];
        const targetCell = targetRow.cells[j];
        for (let r = 0; r < rowspan; r++) {
          // Only start deleting cells to the right for the first row (r == 0)
          if (r === 0) {
            // Delete cells to the right of the target cell in the first row
            for (let c = colspan - 1; c > 0; c--) {
              if (table.rows[i + r].cells[j + c]) {
                table.rows[i + r].deleteCell(j + c);
              }
            }
          }
          // For rows below the first, delete starting from the target column
          if (r > 0) {
            for (let c = colspan - 1; c >= 0; c--) {
              if (table.rows[i + r] && table.rows[i + r].cells[j]) {
                table.rows[i + r].deleteCell(j);
              }
            }
          }
        }
        // Set rowspan and colspan of the target cell
        targetCell.rowSpan = rowspan;
        targetCell.colSpan = colspan;
      }

window.addEventListener('load', function () { styleCell_tinytable_jhrcai5qdacfrgdjgw9y(0, 0, 'tinytable_css_gqi82jn5h08ylmwr4wkv') })
window.addEventListener('load', function () { styleCell_tinytable_jhrcai5qdacfrgdjgw9y(0, 1, 'tinytable_css_gqi82jn5h08ylmwr4wkv') })
window.addEventListener('load', function () { styleCell_tinytable_jhrcai5qdacfrgdjgw9y(0, 2, 'tinytable_css_gqi82jn5h08ylmwr4wkv') })
window.addEventListener('load', function () { styleCell_tinytable_jhrcai5qdacfrgdjgw9y(0, 3, 'tinytable_css_gqi82jn5h08ylmwr4wkv') })
window.addEventListener('load', function () { styleCell_tinytable_jhrcai5qdacfrgdjgw9y(0, 4, 'tinytable_css_gqi82jn5h08ylmwr4wkv') })
    </script>

  


</div>
</div>
</section>
<section id="效果比较seed-lda" class="slide level2">
<h2>效果比较：Seed LDA</h2>
<div class="cell">
<div class="cell-output-display">
 

  
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>tinytable_4l2z1vp9avxkecs325pg</title>
    <style>
.table td.tinytable_css_bgh7niwbktxrbwogx26c, .table th.tinytable_css_bgh7niwbktxrbwogx26c {    border-bottom: solid 0.1em #d3d8dc; }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      }
    };
    </script>
  

  
    <div class="container">
      <table class="table table-borderless" id="tinytable_4l2z1vp9avxkecs325pg" style="width: auto; margin-left: auto; margin-right: auto;" data-quarto-disable-processing="true">
        <thead>
        
              <tr>
                <th scope="col">economy</th>
                <th scope="col">politics</th>
                <th scope="col">society</th>
                <th scope="col">diplomacy</th>
                <th scope="col">military</th>
              </tr>
        </thead>
        
        <tbody>
                <tr>
                  <td>markets</td>
                  <td>clinton</td>
                  <td>hospital </td>
                  <td>corbyn  </td>
                  <td>military </td>
                </tr>
                <tr>
                  <td>banks  </td>
                  <td>sanders</td>
                  <td>schools  </td>
                  <td>labor   </td>
                  <td>syria    </td>
                </tr>
                <tr>
                  <td>oil    </td>
                  <td>cruz   </td>
                  <td>prison   </td>
                  <td>turnbull</td>
                  <td>officers </td>
                </tr>
                <tr>
                  <td>sales  </td>
                  <td>obama  </td>
                  <td>water    </td>
                  <td>johnson </td>
                  <td>refugees </td>
                </tr>
                <tr>
                  <td>energy </td>
                  <td>hillary</td>
                  <td>food     </td>
                  <td>budget  </td>
                  <td>terrorist</td>
                </tr>
                <tr>
                  <td>prices </td>
                  <td>trump's</td>
                  <td>hospitals</td>
                  <td>cabinet </td>
                  <td>isis     </td>
                </tr>
                <tr>
                  <td>stock  </td>
                  <td>bernie </td>
                  <td>climate  </td>
                  <td>brussels</td>
                  <td>army     </td>
                </tr>
                <tr>
                  <td>sector </td>
                  <td>senator</td>
                  <td>violence </td>
                  <td>talks   </td>
                  <td>syrian   </td>
                </tr>
        </tbody>
      </table>
    </div>

    <script>
      function styleCell_tinytable_zie3chq0ck8cx1z1t64v(i, j, css_id) {
        var table = document.getElementById("tinytable_4l2z1vp9avxkecs325pg");
        table.rows[i].cells[j].classList.add(css_id);
      }
      function insertSpanRow(i, colspan, content) {
        var table = document.getElementById('tinytable_4l2z1vp9avxkecs325pg');
        var newRow = table.insertRow(i);
        var newCell = newRow.insertCell(0);
        newCell.setAttribute("colspan", colspan);
        // newCell.innerText = content;
        // this may be unsafe, but innerText does not interpret <br>
        newCell.innerHTML = content;
      }
      function spanCell_tinytable_zie3chq0ck8cx1z1t64v(i, j, rowspan, colspan) {
        var table = document.getElementById("tinytable_4l2z1vp9avxkecs325pg");
        const targetRow = table.rows[i];
        const targetCell = targetRow.cells[j];
        for (let r = 0; r < rowspan; r++) {
          // Only start deleting cells to the right for the first row (r == 0)
          if (r === 0) {
            // Delete cells to the right of the target cell in the first row
            for (let c = colspan - 1; c > 0; c--) {
              if (table.rows[i + r].cells[j + c]) {
                table.rows[i + r].deleteCell(j + c);
              }
            }
          }
          // For rows below the first, delete starting from the target column
          if (r > 0) {
            for (let c = colspan - 1; c >= 0; c--) {
              if (table.rows[i + r] && table.rows[i + r].cells[j]) {
                table.rows[i + r].deleteCell(j);
              }
            }
          }
        }
        // Set rowspan and colspan of the target cell
        targetCell.rowSpan = rowspan;
        targetCell.colSpan = colspan;
      }

window.addEventListener('load', function () { styleCell_tinytable_zie3chq0ck8cx1z1t64v(0, 0, 'tinytable_css_bgh7niwbktxrbwogx26c') })
window.addEventListener('load', function () { styleCell_tinytable_zie3chq0ck8cx1z1t64v(0, 1, 'tinytable_css_bgh7niwbktxrbwogx26c') })
window.addEventListener('load', function () { styleCell_tinytable_zie3chq0ck8cx1z1t64v(0, 2, 'tinytable_css_bgh7niwbktxrbwogx26c') })
window.addEventListener('load', function () { styleCell_tinytable_zie3chq0ck8cx1z1t64v(0, 3, 'tinytable_css_bgh7niwbktxrbwogx26c') })
window.addEventListener('load', function () { styleCell_tinytable_zie3chq0ck8cx1z1t64v(0, 4, 'tinytable_css_bgh7niwbktxrbwogx26c') })
    </script>

  


</div>
</div>
<aside class="notes">
<p>而比较LDA与seeded LDA做出的主题分类结果，我们很容易发现，在LDA分成的主题3下面，不仅有“climate”和”water”，还有”apple”和”education”，它分类的效果很明显是不太好的。 但是在seeded LDA中，每个主题下面的词语大体上符合我们的认知。</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="keyword-assisted-topic-models-keyatm-eshimaetal2023" class="slide level2">
<h2>Keyword-Assisted Topic Models <span class="citation" data-cites="EshimaEtAl2023">(keyATM, <a href="#/参考文献" role="doc-biblioref" onclick="">Eshima, Imai, and Sasaki 2023</a>)</span></h2>
<div class="r-stack">
<ul>
<li>针对概念测量而设计，而非探索主题</li>
<li>基于关键词（种子词） （类似于seedLDA）</li>
<li>允许没有关键词的主题 （不同于seedLDA）</li>
<li>对词频加权防止“词频主导”现象（类似于 weightedLDA）</li>
<li>允许文档向量、元信息的动态变化 （类似于STM）</li>
<li>贝叶斯方法</li>
<li>当种子词<span class="red">质量高</span>时，性能优于加权LDA和STM</li>
</ul>
<div class="fragment">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><a href="07_textAnalysisII_files/figure-revealjs/atm-input-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img data-src="07_textAnalysisII_files/figure-revealjs/atm-input-1.png" width="960"></a></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="model-fit" class="slide level2">
<h2>Model Fit</h2>
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><a href="07_textAnalysisII_files/figure-revealjs/atm-fitness-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img data-src="07_textAnalysisII_files/figure-revealjs/atm-fitness-1.png" width="960"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="base-model-result" class="slide level2">
<h2>Base Model Result</h2>
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><a href="07_textAnalysisII_files/figure-revealjs/atm-result-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img data-src="07_textAnalysisII_files/figure-revealjs/atm-result-1.png" width="960"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="covariate-effect" class="slide level2">
<h2>Covariate Effect</h2>
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><a href="07_textAnalysisII_files/figure-revealjs/atmCov-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img data-src="07_textAnalysisII_files/figure-revealjs/atmCov-1.png" width="960"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="topic-dynamics" class="slide level2">
<h2>Topic Dynamics</h2>
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><a href="07_textAnalysisII_files/figure-revealjs/atmDyn-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20"><img data-src="07_textAnalysisII_files/figure-revealjs/atmDyn-1.png" width="960"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="小结-1" class="slide level2">
<h2>小结</h2>
<div style="text-align:center; margin-top: 1em">
<div class="fragment semi-fade-out">
<ul>
<li>Weighing ← 从<span class="red">词频</span>攫取信息</li>
<li>N-gram ← 从<span class="red">邻居</span>攫取信息</li>
<li>Collocation ← 从<span class="red">共现</span>攫取信息</li>
<li>Keyness ← 从<span class="red">关键词定位</span>攫取信息</li>
<li>Functional words ← 从<span class="red">社会心理</span>攫取信息</li>
</ul>
</div>
<div class="fragment">
<ul>
<li>STM ← 纳入概念<span class="red">关系</span>与<span class="red">外部</span>信息</li>
<li>SeedLDA ← 纳入<span class="red">背景</span>知识</li>
<li>keyATM ← 纳入研究<span class="red">意图</span></li>
</ul>
</div>
</div>
</section></section>
<section>
<section id="语义层级信息汇入" class="title-slide slide level1 center">
<h1>语义层级信息汇入</h1>
<aside class="notes">
<ul>
<li>语法：Grammar</li>
<li>语义: Semantic</li>
<li>语用: Pragmatic</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="给词义建模词嵌入word-embedding" class="slide level2">
<h2>给词义建模：词嵌入(Word embedding)</h2>
<blockquote>
<p>Words’ meanings depend not just on immediate neighbors</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://drhuyue.site:10002/sammo3182/figure/theory_wordEmbedding.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21"><img data-src="https://drhuyue.site:10002/sammo3182/figure/theory_wordEmbedding.png" class="quarto-figure quarto-figure-center" height="550"></a></p>
</figure>
</div>
<aside class="notes">
<p>The term “embedding” comes from the neural network literature, in which an “embedding layer” is an input function that efficiently compresses high-dimensional data down to a low-dimensional dense representation for input to subsequent neural network layers.</p>
<ul>
<li>The embedding model GloVe (“Global Vectors”) by <span class="citation" data-cites="PenningtonEtAl2014">Pennington, Socher, and Manning (<a href="#/参考文献" role="doc-biblioref" onclick="">2014</a>)</span> is explicitly designed to construct word vectors encoding local co-occurrence.</li>
<li>An equally influential word embedding model is Word2Vec <span class="citation" data-cites="BengioEtAl2000">(<a href="#/参考文献" role="doc-biblioref" onclick="">Bengio, Ducharme, and Vincent 2000</a>)</span>, which treats each instance of a word and its context as a separate prediction problem that word vectors are chosen to solve.</li>
</ul>
<p>LSA, NMF, and LDA can also be viewed as producing word embeddings. In particular, the (V × K) matrix B from (2) contains a series of row vectors corresponding to each term in the vocabulary (see also Levy and Goldberg 2014). Those vectors contain information about word co-occurrence at the document level, rather than within a local context.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="能做什么" class="slide level2">
<h2>能做什么</h2>
<ul>
<li>纳入词语意义的表达
<ul>
<li>哪个最接近<code>paris - france + germany</code>（柏林）？</li>
<li>哪个最接近<code>berlin - germany + uk + england</code>（伦敦）？</li>
</ul></li>
</ul>
<div class="fragment">
<ul>
<li>与分类和聚类相比: Document-feature matrix → context-feature matrix (FCM)
<ul>
<li>分类：不关注单个词语间的关系，而是关注词语在文档中的分布。</li>
<li>聚类：提供对文档集合内容的更高级，而不是专注于单个词语的含义。</li>
</ul></li>
</ul>
<aside class="notes">
<p><strong>context-feature matrix (FCM)</strong> 是<code>quantada</code>中另一个重要的矩阵形式，它用来测量在用户定义的上下文语境中，一些特征的共现性，也就是利用上下文信息来捕捉词汇之间的语义关系。 具体来说，FCM 使用了一个上下文窗口，对每个词汇建模时考虑其周围的上下文。 这使得 FCM 能够更好地捕捉词汇之间的语义相似性，因为它不仅考虑了词汇本身的信息，还考虑了它们在语境中的使用情况。</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
<div class="fragment">
<ul>
<li>应用
<ul>
<li>词条表征（term representation）</li>
<li>情感分析（sentiment analysis）</li>
</ul></li>
</ul>
</div>
</section>
<section id="应用举例latent-semantic-scaling-watanabe2021" class="slide level2">
<h2>应用举例：Latent Semantic Scaling <span class="citation" data-cites="Watanabe2021">(<a href="#/参考文献" role="doc-biblioref" onclick="">Watanabe 2021</a>)</span></h2>
<ul>
<li>专门用于区分<span class="red">对立的立场</span></li>
<li>基于词嵌入技术的，在构建模型之前将文档和特征转换为高维度向量空间
<ul>
<li>GloVe</li>
<li>Singular Value Decomposition (SVD)</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://drhuyue.site:10002/sammo3182/figure/text_svd.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22"><img data-src="https://drhuyue.site:10002/sammo3182/figure/text_svd.png" class="fragment quarto-figure quarto-figure-center" height="400"></a></p>
</figure>
</div>
<aside class="notes">
<p>SVD is a math tool that helps us break down a big matrix (which you can think of like a giant table of numbers) into smaller parts. SVD, a matrix is decomposed into three other matrices: U, Σ, and V . The columns of U and V are called left and right singular vectors, respectively.</p>
<p>Comparison in Semantic Scaling:</p>
<ul>
<li>SVD: Better for general-purpose dimensionality reduction and identifying broad patterns in text. It’s more of a tool for finding overall structure and relationships, but it may miss finer semantic distinctions.</li>
<li>GloVe: Superior for scaling semantics in a more nuanced way, capturing both local (nearby words) and global (overall context) word meanings. This makes GloVe more effective for specific tasks like word similarity and analogy.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="应用判断卫报新闻的情感走向" class="slide level2">
<h2>应用：判断《卫报》新闻的情感走向</h2>
<div class="r-stack">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><a href="07_textAnalysisII_files/figure-revealjs/lss-result-svd-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23"><img data-src="07_textAnalysisII_files/figure-revealjs/lss-result-svd-1.png" width="960"></a></p>
</figure>
</div>
</div>
</div>
<div class="fragment">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><a href="07_textAnalysisII_files/figure-revealjs/lss-result-glove-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24"><img data-src="07_textAnalysisII_files/figure-revealjs/lss-result-glove-1.png" width="960"></a></p>
</figure>
</div>
</div>
</div>
</div>
</div>
<aside class="notes">
<p>高亮的为词典中的词汇, 注意SVD结果，有一些词落在了0右面，而glove都落在了0左边</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="趋势分析" class="slide level2">
<h2>趋势分析</h2>
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><a href="07_textAnalysisII_files/figure-revealjs/glovePrediction-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25"><img data-src="07_textAnalysisII_files/figure-revealjs/glovePrediction-1.png" width="960"></a></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<p>2016年以后波动比较大</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="还缺什么" class="slide level2">
<h2>还缺什么</h2>
<blockquote>
<p>Machine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy <span class="citation" data-cites="IBM2021">(<a href="#/参考文献" role="doc-biblioref" onclick="">IBM 2021</a>)</span>.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://drhuyue.site:10002/sammo3182/figure/text_machineLearning.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-26"><img data-src="https://drhuyue.site:10002/sammo3182/figure/text_machineLearning.jpg" class="quarto-figure quarto-figure-center" height="400"></a></p>
</figure>
</div>
<aside class="notes">
<ul>
<li><p>自动性：self-supervised learning</p></li>
<li><p>加强: reinforcement</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="自监督学习" class="slide level2">
<h2>自监督学习</h2>
<div class="r-stack">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://drhuyue.site:10002/sammo3182/figure/text_selfSupervised.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27"><img data-src="https://drhuyue.site:10002/sammo3182/figure/text_selfSupervised.png" class="quarto-figure quarto-figure-center" height="400"></a></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://drhuyue.site:10002/sammo3182/figure/text_pretrain.webp" class="lightbox" data-gallery="quarto-lightbox-gallery-28"><img data-src="https://drhuyue.site:10002/sammo3182/figure/text_pretrain.webp" class="fragment quarto-figure quarto-figure-center" height="600"></a></p>
</figure>
</div>
</div>
<aside class="notes">
<p>Self-Supervised Learning: In self-supervised learning, the model generates its own labels from the input data, creating a supervised-like setup. For instance, a model might be given part of a sentence and asked to predict the missing word. The labels (the missing word) come from the data itself. This is often used in tasks like language modeling (e.g., predicting the next word in a sentence).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="强化学习" class="slide level2">
<h2>强化学习</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://drhuyue.site:10002/sammo3182/figure/text_reinforcement.png" class="lightbox" data-gallery="quarto-lightbox-gallery-29"><img data-src="https://drhuyue.site:10002/sammo3182/figure/text_reinforcement.png" class="quarto-figure quarto-figure-center" height="600"></a></p>
</figure>
</div>
</section>
<section id="注意力机制-attention-mechanism-vaswanietal2017" class="slide level2">
<h2>注意力机制 <span class="citation" data-cites="VaswaniEtAl2017">(Attention Mechanism, <a href="#/参考文献" role="doc-biblioref" onclick="">Vaswani et al. 2017</a>)</span></h2>
<p>一般的word embedding认为所有词和词之间关系都同等重要<span class="large">🤦‍♂️</span></p>
<div class="fragment fade-in-then-semi-out">
<p>“Attention is all you need” <span class="citation" data-cites="VaswaniEtAl2017">(<a href="#/参考文献" role="doc-biblioref" onclick="">Vaswani et al. 2017</a>)</span></p>
<p>以下是关于大型语言模型中注意力机制的示例翻译：</p>
<blockquote>
<p>作为在_____领域的头部企业，我们雇佣了大量高水平的软件工程师。<br>
作为在_____领域的头部企业，我们雇佣了大量高水平的太阳能工程师。</p>
</blockquote>
<p>应该在 “_____” 填入什么词？你是如何得出这个结论的？</p>
</div>
<div class="fragment">
<p>作为在<em>信息技术</em>领域的头部企业，我们雇佣了大量高水平的<span class="red">软件</span>工程师。<br>
作为在<em>绿色能源</em>领域的头部企业，我们雇佣了大量高水平的<span class="red">太阳能</span>工程师。</p>
</div>
<aside class="notes">
<p>Self-Attention in Transformers: Self-Attention: A specific type of attention called self-attention is key to Transformers. In self-attention, every word in a sentence can pay attention to every other word, not just the nearby words. This allows the model to capture complex relationships, even when words are far apart in the sentence.</p>
<p>For instance, in the sentence “The cat that was sitting on the mat is happy,” self-attention allows the model to recognize that “cat” is related to “is happy,” even though several words separate them.</p>
<p>Multi-Headed Attention: Transformers use multiple attention heads to learn different aspects of relationships between words. Each attention head focuses on a different aspect of the word relationships, which helps the model understand the text in a richer and more nuanced way.</p>
<ol start="3" type="1">
<li>During Pre-Training and Fine-Tuning: Pre-Training Phase (Self-Supervised Learning): The attention mechanism helps the model learn language representations by focusing on relevant parts of the input when predicting the next word or filling in gaps in sentences.</li>
</ol>
<p>Fine-Tuning Phase (Reinforcement Learning and Beyond): The attention mechanism continues to play a role when the model is fine-tuned using reinforcement learning, such as RLHF. The model uses the attention mechanism to generate responses during interactions, determining which parts of the input prompt to focus on when creating its output.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>自注意力机制</strong></p>
</div>
<div class="callout-content">
<p>输入一个初始词元嵌入序列，并输出一个新的词元嵌入序列，<span class="red">使初始嵌入能够相互作用</span>。</p>
</div>
</div>
</div>
</div>
</section>
<section id="组装起来" class="slide level2">
<h2>组装起来</h2>
<ul>
<li>由堆叠的<em>注意力机制</em>和<em>前馈神经网络层</em>组成的大型神经网络可以使用专用处理器高效并行训练，即 <strong>t</strong>ransformer，通常通过预训练（<strong>p</strong>re-training)获得。
<ul>
<li>→ 应用于基于学习成果的生成式（<strong>g</strong>enerative）任务</li>
</ul></li>
</ul>
<aside class="notes">
<ul>
<li>BERT 使用transformer（encoder）来进行discriminative jobs，e.g, classification or predicting missing words in sentences</li>
<li>GPT 使用transformer (decoder)来进行generative jobs, e.g., generating sentences</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="fragment">
<ul>
<li>强化学习/微调过程</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://drhuyue.site:10002/sammo3182/figure/text_finetune.webp" class="lightbox" data-gallery="quarto-lightbox-gallery-30"><img data-src="https://drhuyue.site:10002/sammo3182/figure/text_finetune.webp" class="quarto-figure quarto-figure-center" height="400"></a></p>
</figure>
</div>
</div>
<aside class="notes">
<p>Fine-Tuning: After pretraining, the model undergoes fine-tuning on more specific data, often with human feedback or additional tasks. This process helps the model adjust its knowledge to be more useful for specific applications. For instance, fine-tuning might include adjusting the model’s responses to be more helpful, accurate, or aligned with certain safety guidelines. This phase often involves techniques like Reinforcement Learning from Human Feedback (RLHF), where the model learns from human-provided rankings of response quality.</p>
<p>Interaction with ChatGPT: not fine tune</p>
<p>Interaction with ChatGPT (Ask-Answer Rounds): When you engage in ask-answer rounds with ChatGPT, the model uses the knowledge it gained during training and fine-tuning to respond to your queries. However:</p>
<ul>
<li>No Learning Happens: The model is not updating its parameters or “learning” from your individual interactions. The model’s behavior is static, and its responses are generated based on the preexisting knowledge and patterns it has learned.</li>
<li>Inference: The process you’re engaging in is called inference, where the model is simply generating responses based on what it already knows.</li>
</ul>
<p>The reason you often get better answers after interacting with ChatGPT is not because the model is learning from your specific questions in real-time (since it doesn’t update itself during these interactions). Instead, it’s due to the way the model processes context and maintains a conversation. Here’s why:</p>
<ol type="1">
<li><strong>Context Awareness</strong>: ChatGPT can remember the context of the ongoing conversation within the session. As the interaction progresses, the model uses previous information from the conversation to better understand your current question. This allows it to generate more accurate, relevant, and coherent responses.</li>
</ol>
<p>For example: - If you ask a series of related questions, ChatGPT can “build on” the information exchanged earlier in the conversation, leading to more refined answers. - It can keep track of clarifications you’ve provided and adapt its responses to align with your preferences or focus on specific details you’re interested in.</p>
<ol start="2" type="1">
<li><strong>Clarification and Refinement</strong>: In a conversation, you often provide more details, clarifications, or corrections as you interact with the model. This helps ChatGPT refine its understanding of your needs, enabling it to give more relevant answers.</li>
</ol>
<p>For instance: - If an initial response is too vague or off-target, you might ask follow-up questions or provide additional information. With this new input, ChatGPT can refine its responses to better match what you’re looking for.</p>
<ol start="3" type="1">
<li><p><strong>Pattern Matching</strong>: ChatGPT has been trained on a vast amount of conversational data, so it’s very good at recognizing patterns in dialogue. As the conversation continues, the model can “hone in” on the patterns that seem most relevant to your questions based on prior exchanges. This can give the appearance of improvement in the quality of responses.</p></li>
<li><p><strong>Elaboration and Deeper Explanation</strong>: With more interaction, you might be guiding ChatGPT to provide deeper or more nuanced explanations. The initial responses might be general, but as you ask for further detail or clarification, the model responds with more in-depth information, which can feel like an improvement.</p></li>
<li><p><strong>Conversational Flow</strong>: ChatGPT is designed to simulate a conversational flow, so as you continue to interact, the model attempts to align more closely with your communication style, the specific topic, and your expressed needs. This ongoing refinement can feel like it’s “learning,” but it’s really just adapting to the conversation in progress.</p></li>
</ol>
<p>Conclusion: The improvement in the quality of answers you receive during the conversation is due to <strong>contextual understanding</strong> and <strong>clarification through interaction</strong>, rather than real-time learning or fine-tuning. The model is designed to keep track of the dialogue and adjust its responses based on the context of your ongoing discussion.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="总结" class="slide level2">
<h2>总结</h2>
<blockquote>
<p>本讲的核心议题：<span class="red">突破词基限制，找回有用信息</span></p>
</blockquote>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>词汇层级的信息汇入</strong></p>
<div class="fragment">
<ul>
<li>Weighing ← 从<span class="red">词频</span>攫取信息</li>
<li>N-gram &amp; Collocation ← 从<span class="red">邻居/共现</span>攫取信息</li>
<li>Functional words ← 从<span class="red">心理</span>攫取信息</li>
</ul>
</div>
<p><strong>概念层级的信息汇入</strong></p>
<div class="fragment">
<ul>
<li>STM ← 纳入概念<span class="red">关系</span>与<span class="red">外部</span>信息</li>
<li>SeedLDA ← 纳入<span class="red">背景</span>知识</li>
<li>keyATM ← 纳入研究<span class="red">意图</span></li>
</ul>
</div>
</div><div class="column" style="width:50%;">
<p><strong>语义层级的信息汇入</strong></p>
<div class="fragment">
<ul>
<li>Word embedding ← 词汇之间的<span class="red">语义</span>关联</li>
<li>Self-supervised learning &amp; Attention model ← <span class="red">自动</span>化和自我<span class="red">提升</span></li>
<li>Reinforcement learning ← 具体任务<span class="red">情境</span></li>
</ul>
</div>
</div>
</div>
</section></section>
<section>
<section id="感谢倾听欢迎交流" class="title-slide slide level1 center" data-background="#43464B">
<h1>感谢倾听，欢迎交流</h1>
<div style="text-align: right; margin-top: 1em">
<p><a href="https://github.com/sammo3182"><svg viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="height:1em;position:relative;display:inline-block;top:.1em;" xmlns="http://www.w3.org/2000/svg"> <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>&nbsp; sammo3182</a></p>
<p><a href="mailto:yuehu@tsinghua.edu.cn"><svg viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="height:1em;position:relative;display:inline-block;top:.1em;" xmlns="http://www.w3.org/2000/svg"> <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path> <polyline points="22,6 12,13 2,6"></polyline></svg>&nbsp; yuehu@tsinghua.edu.cn</a></p>
<p><a href="https://www.drhuyue.site"><svg viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="height:1em;position:relative;display:inline-block;top:.1em;" xmlns="http://www.w3.org/2000/svg"> <circle cx="12" cy="12" r="10"></circle> <line x1="2" y1="12" x2="22" y2="12"></line> <path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"></path></svg>&nbsp; https://www.drhuyue.site</a></p>
<p><a href="https://user-images.githubusercontent.com/6463211/232207708-b0e64eee-7fb3-45a4-9779-ec52397f786c.png" class="lightbox" data-gallery="quarto-lightbox-gallery-31"><img data-src="https://user-images.githubusercontent.com/6463211/232207708-b0e64eee-7fb3-45a4-9779-ec52397f786c.png" height="250"></a></p>
</div>
</section>
<section id="参考文献" class="slide level2 smaller scrollable">
<h2>参考文献</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-BengioEtAl2000" class="csl-entry" role="listitem">
Bengio, Yoshua, Réjean Ducharme, and Pascal Vincent. 2000. <span>“A neural probabilistic language model.”</span> In <em>Advances in Neural Information Processing Systems</em>. Vol. 13. MIT Press.
</div>
<div id="ref-EshimaEtAl2023" class="csl-entry" role="listitem">
Eshima, Shusei, Kosuke Imai, and Tomoya Sasaki. 2023. <span>“Keyword-Assisted Topic Models.”</span> <em>American Journal of Political Science</em>, Early View. <a href="https://doi.org/10.1111/ajps.12779">https://doi.org/10.1111/ajps.12779</a>.
</div>
<div id="ref-Gabrielatos2018" class="csl-entry" role="listitem">
Gabrielatos, Costas. 2018. <span>“Keyness Analysis: Nature, Metrics and Techniques.”</span> In <em>Corpus Approaches to Discourse</em>, edited by Charlotte Taylor and Anna Marchi, 34–65. Routledge.
</div>
<div id="ref-IBM2021" class="csl-entry" role="listitem">
IBM. 2021. <span>“What Is Machine Learning (ML)?”</span> Think: Tech news, education; events. September 22, 2021.
</div>
<div id="ref-King2015" class="csl-entry" role="listitem">
King, Gary. 2015. <span>“Big Data Is Not about the Data!”</span> Guest talk presented at the Talk at the capital markets cooperative research centre, Sydney, Australia, November 11.
</div>
<div id="ref-Liu2022" class="csl-entry" role="listitem">
Liu, Amy H. 2022. <span>“Pronoun Usage as a Measure of Power Personalization: A General Theory with Evidence from the Chinese-Speaking World.”</span> <em>British Journal of Political Science</em> 52 (3, 3): 1258–75. <a href="https://doi.org/10.1017/S0007123421000181">https://doi.org/10.1017/S0007123421000181</a>.
</div>
<div id="ref-PenningtonEtAl2014" class="csl-entry" role="listitem">
Pennington, Jeffrey, Richard Socher, and Christopher Manning. 2014. <span>“GloVe: Global Vectors for Word Representation.”</span> In <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 1532–43. Doha, Qatar: Association for Computational Linguistics. <a href="https://doi.org/10.3115/v1/D14-1162">https://doi.org/10.3115/v1/D14-1162</a>.
</div>
<div id="ref-RobertsEtAl2013" class="csl-entry" role="listitem">
Roberts, Margaret E., Brandon M. Stewart, Dustin Tingley, and Edoardo M. Airoldi. 2013. <span>“The Structural Topic Model and Applied Social Science.”</span> <em>Advances in Neural Information Processing Systems Workshop on Topic Models: Computation, Application, and Evaluation</em> 1737: 1–4.
</div>
<div id="ref-VaswaniEtAl2017" class="csl-entry" role="listitem">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. <span>“Attention Is All You Need.”</span> In <em>Advances in Neural Information Processing Systems</em>. Vol. 30. Curran Associates, Inc.
</div>
<div id="ref-Watanabe2021" class="csl-entry" role="listitem">
Watanabe, Kohei. 2021. <span>“Latent Semantic Scaling: A Semisupervised Text Analysis Technique for New Domains and Languages.”</span> <em>Communication Methods and Measures</em> 15 (2): 81–102. <a href="https://doi.org/10.1080/19312458.2020.1832976">https://doi.org/10.1080/19312458.2020.1832976</a>.
</div>
</div>

</section><div class="quarto-auto-generated-content">
<div class="footer footer-default">

</div>
</div></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="07_textAnalysisII_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="07_textAnalysisII_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="07_textAnalysisII_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="07_textAnalysisII_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="07_textAnalysisII_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="07_textAnalysisII_files/libs/revealjs/plugin/reveal-spotlight/spotlight.js"></script>
  <script src="07_textAnalysisII_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="07_textAnalysisII_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="07_textAnalysisII_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="07_textAnalysisII_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="07_textAnalysisII_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'spotlight': {"size":50,"lockPointerInsideCanvas":false,"toggleSpotlightOnMouseDown":false,"spotlightOnKeyPressAndHold":73,"spotlightCursor":"none","presentingCursor":"default","initialPresentationMode":true,"disablingUserSelect":true,"fadeInAndOut":100,"useAsPointer":false,"pointerColor":"red"},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: true,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealSpotlight, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
              // target, if specified
              link.setAttribute("target", "_blank");
              if (link.getAttribute("rel") === null) {
                link.setAttribute("rel", "noopener");
              }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    <script>videojs(video_shortcode_videojs_video1);</script>
    <script>var lightboxQuarto = GLightbox({"descPosition":"bottom","openEffect":"fade","loop":false,"closeEffect":"fade","selector":".lightbox"});
    window.onload = () => {
      lightboxQuarto.on('slide_before_load', (data) => {
        const { slideIndex, slideNode, slideConfig, player, trigger } = data;
        const href = trigger.getAttribute('href');
        if (href !== null) {
          const imgEl = window.document.querySelector(`a[href="${href}"] img`);
          if (imgEl !== null) {
            const srcAttr = imgEl.getAttribute("src");
            if (srcAttr && srcAttr.startsWith("data:")) {
              slideConfig.href = srcAttr;
            }
          }
        } 
      });

      lightboxQuarto.on('slide_after_load', (data) => {
        const { slideIndex, slideNode, slideConfig, player, trigger } = data;
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(slideNode);
        }
      });

    };
              </script>
    

</body></html>