---
title: "潜变量分析（基础篇）"
subtitle: "政务大数据应用与分析 (80700673)"
author: "胡悦"
institute: "清华大学" 
knitr: 
    opts_chunk: 
      echo: false
format: 
  revealjs:
    css: https://www.drhuyue.site/slides_gh/css/style_basic.css
    theme: ../../../css/goldenBlack.scss
    slide-number: true
    incremental: true
    preview-links: true # open an iframe for a link
    link-external-newwindow: true
    self-contained: false
    chalkboard: false # allwoing chalk board B, notes canvas C
    # callout-icon: false
    show-slide-number: all # `speaker` only print in pdf, `all` shows all the time
    title-slide-attributes:
      data-background-image: https://gitlab.com/sammo3182/backup/raw/85b3c1ad4b459d7a9f901f124b936428eda5fcaf/logo_THPS.png?inline=true
      data-background-size: 250px   
      data-background-position: top 10% right 5%
    default-image-extension: png
revealjs-plugins:
  - spotlight
lightbox: 
  match: auto
  effect: fade
spotlight:
  size: 50
  presentingCursor: default
  toggleSpotlightOnMouseDown: false
  spotlightOnKeyPressAndHold: 73 # keycode for "i"
editor_options: 
  chunk_output_type: console
---

```{r setup}
#| include = FALSE

library(pacman)

p_load(psych,
       lavaan,
       semPlot,
       qgraph,
       haven,
       here,
       corrplot,
       tidyverse)

# Functions preload
set.seed(313)

theme_set(
  theme_minimal(base_size = 18)
)

theme_update(
  plot.title = element_text(size = 18), 
  axis.title = element_text(size = 22), 
  axis.text = element_text(size = 18)
)
```

## 概要

:::: {.columns}

::: {.column width="50%"}

1. 概念与分析逻辑
    - 什么是潜变量
    - 怎么分析
1. 探索性因子分析
1. 验证性因子分析（与结构方程模型）

:::

::: {.column .fragment .nonincremental width="50%"}
**操作语言**

* R
    + [`psych`](https://personality-project.org/r/psych/vignettes/intro.pdf)
    + [`laavan`](https://lavaan.ugent.be/)
:::

::::



# 潜变量概念与分析逻辑


## 潜在变量 (Latent variables)

:::{.r-hstack}

![](https://drhuyue.site:10002/sammo3182/figure/lv_angry.jpg){fig-align="center" height=600}

![](https://drhuyue.site:10002/sammo3182/figure/lv_happy.jpg){.fragment fig-align="center" height=600}

:::



## Why bother

:::{.r-stack}
![Liberty leading the people](https://drhuyue.site:10002/sammo3182/figure/lv_liberty.jpg){fig-align="center" height=600}

![战狼II](https://drhuyue.site:10002/sammo3182/figure/lv_patriotism.webp){.fragment fig-align="center" height=600}
:::


---

> Latent variable analysis is the [cornerstone]{.red} of successful scientific inquiry.^[Delli Carpini, M. X., and S. Keeter. 1993. “Measuring Political Knowledge: Putting First Things First.” *American Journal of Political Science* 37 (4): 1179–1206.]


:::: {.columns}

::: {.column width="30%"}
涵盖所有社会科学学科

* 抽象
* 复杂
* 综合


:::

::: {.column .fragment width="30%"}
1. 不可见(Unobservable)
1. 多维度(Multidimensional)
1. 有效果(Consequential)


:::{.notes}
兜里有多少钱，不可见，但维度单一，不宜用潜变量分析，更好的办法是翻兜

The latent variable per se can't be directly measured. But its consequences in opinions and behaviors can be observed.
:::

:::

::: {.column width="40%"}
![](https://drhuyue.site:10002/sammo3182/figure/lv_jamesStimson.jpg){.fragment fig-align="center" height=400}

:::{.notes}
Jaes Stimson (1991), University of North Carolina at Chapel Hill
:::
:::

::::



## 分析逻辑：

:::{style="text-align:center; margin-top: 2em"}
结果 [&larr;]{.red} 共因
:::

:::{.notes}
爱缘取，取缘有，有缘生，生缘老死
:::

🌰 个体的社会资本（social capital）

:::{.notes}
Three dimensions of social capital:

1. Trust
1. Norms
1. Networks
:::

:::{.fragment .nonincremental style="text-align:center; margin-top: 2em"}
指标问题（1~10）：

1. 您是否信任身边人？
1. 您在政府机关有没有亲戚？
1. 您的朋友是否和您的想法经常一致？
:::


## 测量社会资本

:::: {.columns}

::: {.column width="50%"}
累加综合法(additive scales)

$$\tilde{X} = (X_1 + X_2 + X_3)/3.$$
:::

::: {.column .fragment width="50%"}
*潜在问题*

1. 平等权重(equal weight)
1. 数据敏感(extreme value sensitivity)
1. 忽略极化(polarity ignoring)
:::

::::

:::{.fragment .large style="text-align:center; margin-top: 2em"}
*如何做得更好？*
:::


## 因子分析基本模型

:::: {.columns}

::: {.column width="50%"}
**因素分析模型(Factorial Models)**

1. 探索性因子分析(EFA)
1. 验证性因子分析(CFA)
1. 结构方程模型(SEM)
:::

::: {.column width="50%"}
**类型分析模型(Topological Models)**

1. 项目反应理论(IRT)
1. MRP
1. 跨群组项目反应(GIRT, DCPO)
:::

::::


# 因子分析


## 基本原理

:::{style="text-align:center"}
结果 [&larr;]{.red} 共因

&uArr;

可见指标(indicators) [&larr;]{.red} 潜在变量
:::

:::{.fragment style="text-align:center"}
&uArr;

![Minimum factors for the variances](https://drhuyue.site:10002/sammo3182/figure/lv_jiangwei.jpg){fig-align="center" height=300}
:::

:::{.notes}
determine the minimum number of hypothetical factors or components that account for the variance between variables.
:::


## 操作挑战

:::: {.columns}

::: {.column width="60%"}

![](https://drhuyue.site:10002/sammo3182/figure/lv_efa.png){fig-align="center" height=600}
:::

::: {.column width="40%"}
- **目标**
  - I wanna fewer dimensons
- **挑战**: 
    - 降到几维
      - 一维是是不是最优选择
    - 如何降维
      - 如何克服“累加综合法”缺陷
    
::: {.fragment .r-fit-text}
*Exploratory* FA
:::

:::
::::


## 探索式因子分析

:::{.callout-important}
## 根本公式

$$X^* = \Phi\Lambda' + \epsilon,$$

:::{style="text-align:center"}
**$X^*$**: 潜在变量  
**&Phi;**: 指标选择  
**&Lambda;**: 单项贡献（a.k.a., factor loading）  
**&epsilon;** 选择误差
:::
:::

:::{.notes}
Quinn, Kevin M. undefined/ed. “Bayesian Factor Analysis for Mixed Ordinal and Continuous Responses.” Political Analysis 12(4): 338–53.
:::

:::{.fragment .nonincremental style="text-align:center"}
*操作步骤*

1. 因子个数选择
1. 因子提取
1. Rotation
1. 因子合成
1. 结果检验
:::



## 🌰：人格测试

19,719 参与者, Big5 personality

![](https://drhuyue.site:10002/sammo3182/figure/lv_big5.jpg){fig-align="center" height=400}

## 实证数据

```{r data-big5, cache=TRUE}
df_big5 <- read_csv("https://drhuyue.site:10002/sammo3182/data/lv_dataBIG5.csv")
df_big5[df_big5 == 0] <- NA
df_big5
```


:::{.notes}
经验开放性Openness, 尽责性Conscientiousness, 外向型Extraversion, 亲和性Agreeableness, 情绪不稳定型Neuroticism

https://quantdev.ssri.psu.edu/tutorials/intro-basic-exploratory-factor-analysis
:::

:::{.fragment .nonincremental style="text-align:center"}
*挑战（again）*

- 降到几维
- 如何降维
:::


## 维度选择方法：相关性分析

```{r corrplot, fig.align='center', fig.height=6}
df_big5 %>%
  select(8:57) %>%
  cor(use = "complete.obs") %>%
  corrplot(order = "hclust",
           tl.col = 'black',
           tl.cex = .75) 
```



## 维度选择方法：Horn's Parallel Analysis

:::: {.columns}

::: {.column width="70%"}
```{r parallelAnalysis, fig.align='center', fig.height=6, results='hide'}
df_big5 %>%
  select(8:57) %>%
  fa.parallel(fa = "fa")
```
:::

::: {.column width="30%"}
已知观测数据集**O**<sub>m&times;n</sub>

1. 创建随机数据集**R**<sub>m&times;n</sub>;  
1. 相关矩阵<sub>**R**</sub> &rarr; &lambda;<sub>**R**</sub>;  
1. 相关矩阵<sub>**Ok**</sub> &rarr; &lambda;<sub>**Ok**</sub> (k为因子数)
1. &lambda;<sub>**Ok**</sub> vs. &lambda;<sub>**R**</sub>

:::{.fragment}
A. 如果&lambda;<sub>**Ok**</sub> < &lambda;<sub>**R**</sub>, 则 ~~k~~
B. Kaiser criterion
:::

:::

::::



## 因子提取(Factor Extraction)

+ Minimum residual (OLS)
+ Principal axes
+ Alpha factoring
+ Weighted least squares
+ Minimum rank
+ [Maximum likelihood (ML, minimum &chi;<sup>2</sup> goodness of fit)]{.red}


## Rotation: 效果优化

![](https://drhuyue.site:10002/sammo3182/figure/lv_rotation.jpg){fig-align="center" height=400}   

:::{.notes}
Rotation:

A pattern of loadings where each item loads strongly on only one of the factors, and much more weakly on the other factors.
:::

* Orthogonal: Varimax, quartimax, bentlerT, geominT, bifactor  
* [Oblique]{.red}: Oblimin, quartimin, simplimax, bentlerQ, geominQ, biquartimin


:::{.notes}
Orthogonal(正交)

优选Oblique，允许factor间correlate
:::


## 合成结果

:::: {.columns}

::: {.column width="50%"}

ML + Oblimin

```{r efa, eval = TRUE}
result_efa <- df_big5 %>%
  select(8:57) %>%
  fa(nfactors = 5,
     rotate = "oblimin",
     fm = "ml")

print(result_efa$loadings, cutoff = .296) # the point was picked for the purpose of presentation
```
:::

::: {.column width="50%"}
```{r scores, fig.align='center', fig.height=8}
# Reshape the data to a long format
df_scores_long <- as.data.frame(result_efa$scores) |>
  pivot_longer(cols = everything(), 
               names_to = "Factor", 
               values_to = "Score")

# Create the histograms using ggplot2 and facet by factor
ggplot(df_scores_long, aes(x = Score)) +
  geom_histogram(binwidth = 0.5) +  # Adjust binwidth as needed
  facet_wrap(~ Factor, scales = "free_y", ncol = 1) +  # Facet into 1 column, adjust y scales independently
  labs(x = "Score", y = "Frequency", title = "Histograms of EFA Factors")  # Adjust labels as necessary
```
:::

::::


## 诊断指标

1. Sum of squared (SS) loading^[特征值]: 1
1. Communality/Uniqueness
1. Root means square of residuals(RMSR): 0.05
1. Tucker-Lewis Indes (TLI): 0.9
1. Reliability test (Crobach's &alpha;)^[为每个因子分别计算]

:::{.notes}
SS：Kaiser criterion: &lambda; < 1 不可
Communality:  SS of all the factor loadings for a given variable
Uniqueness: 1 - Communality
RMSR < 0.05
TLI > 0.9

Crobach's &alpha;: 计算因子分布的variables是不是内部一致，除非发表，不大必要
:::

---

```{r efa-full}
summary(result_efa)
```

## 注意事项

- EFA是*归纳式*研究方法，[并非统计推断]{.red}
- EFA应用需满足以下假定:
    1. [*Linearity*]{.red} between the observed and latent
    1. [*Sufficient correlation*]{.red} between the observed and latent
    1. [*Homoscedasticity*]{.red}
    1. [*Multivariate normality*]{.red} among the observed
    1. [*No singularity*]{.blue} among the observed
    1. [*Large N*]{.blue}: 10 ~ 300
    1. [*Factorial Simplicity*]{.blue}
- EFA不是唯一合理的合并方式
    - [IRT]{.gray}
    - PCA


:::{.notes}
Red: bias; blue: efficiency

1. **Linearity**: EFA assumes a linear relationship between observed variables and underlying factors. This means that changes in the levels of factors are associated with proportional changes in the observed variables.

2. **Multivariate Normality**: Ideally, the observed variables should follow a multivariate normal distribution. While EFA can be performed on data that do not perfectly adhere to this assumption, deviations from multivariate normality can affect the robustness of the factor analysis, especially when estimating parameters and computing fit indices.

3. **Adequate Sample Size**: There is no strict rule for the minimum sample size in EFA, but a larger sample size can provide more reliable and stable factor solutions. A commonly cited guideline suggests having at least 5 to 10 observations per variable, though some scholars recommend a minimum of 300 cases as a more general benchmark.

4. **No Perfect Multicollinearity or Singularity**: While EFA aims to identify the underlying structure by exploring the correlations between variables, perfect multicollinearity (where one variable is a perfect linear combination of others) should be avoided. Similarly, singularity (where some variables are redundant) should be avoided, as these conditions can distort the analysis.

5. **Sufficient Correlation**: For a factor model to be meaningful, there must be some degree of correlation among the observed variables. If variables are completely uncorrelated, there would be no underlying factors to extract. The Kaiser-Meyer-Olkin (KMO) measure of sampling adequacy and Bartlett's test of sphericity are commonly used to assess this assumption.

6. **Homoscedasticity**: The assumption of homoscedasticity (equal variances) among variables is also important for the generalizability of EFA results. Significant heteroscedasticity can lead to biased estimates of factor loadings and uniqueness.

7. **Factorial Simplicity**: This is more of a desired property than a strict assumption. Factorial simplicity implies that each variable should load strongly on one factor and have minimal loadings on other factors. This assumption facilitates the interpretability of factors.

Violations of these assumptions can lead to inaccurate factor solutions, misleading interpretations, and conclusions. It is therefore important to assess these assumptions before proceeding with EFA. In practice, some of these assumptions can be relaxed or addressed through data transformation, adopting robust estimation methods, or increasing the sample size.
:::

## Principal Component Analysis

:::{.callout-important}
## 根本公式

$$C = w_iY_i,$$

:::{style="text-align:center"}
**C**: Components， “因子”

**Y**: Measures
:::

:::

![](https://drhuyue.site:10002/sammo3182/figure/lv_pca.png){fig-align="center" height=300}


:::{.notes}
create one or more index variables (Components) from a larger set of measured variables (Y)
:::

## PCA vs. EFA

![](https://drhuyue.site:10002/sammo3182/figure/lv_pcaVsEfa.PNG){fig-align="center" height=500}


::: {.fragment .r-fit-text}
结果或近似，逻辑大不同
:::


:::{.notes}
PCA: measurement to index   

write all variables in terms of a smaller set of features which allows for a maximum amount of variance to be retained in the data.   


EFA: indices to measurement (of a latent variable)   

find a set of features which allow for understanding as much of the correlations between measured variables as possible. individually.
:::



## When to usd what

* PCA最大程度保留可见变量信息，EFA旨在提取不可变量特征；
* 当Variable之间关系不那么紧密或受同一变量影响，PCA > EFA；
* 当估计潜在变量时，PCA可能夸大可见指标的影响



# 验证性因子分析

## 探索性 vs 验证性

:::: {.columns}

::: {.column width="50%"}
**EFA: 数据指向**

1. 实证观察（归纳）
    - *无法统计推断*
1. 未知维度
    + 每个维度都产生影响
1. 多重指标
    + Loading**大小**之分
1. 无视测量偏差关联
1. Underidentified
:::

::: {.column width="50%"}
**CFA: 理论指向**

1. 理论定义（演绎）
    - [*专为统计推断*]{.red}
1. 明确维度
    + 维度-指标关系明确
1. 单一指标
    + Loading[有无]{.red}之分
1. 允许测量误差相关
1. 必须identifiable
:::

::::


## CFA指标选择

:::: {.columns}

::: {.column width="50%"}

1. 严格依据理论：~~原因~~效果指标
1. 每维度一指标^[但维度拆分，[艺术>技术]{.red}.]

:::{.fragment}
🌰 人际信任: [相信]{.red}他人不会[伤害自己]{.red}或[违背约定]{.red}.

```{r cfa, eval=FALSE}
DiagrammeR::grViz(
  "digraph {

graph[layout = dot]

node[shape = rectangle, style = filled, fillcolor = Linen]

s [label = 'Interpersonal Trust', shape = 'ellipse']
d [label = 'General Trust']
j [label = 'Altruism']
i [label = 'Credibility']

# edge definitions with the node IDs
s -> {d, j, i}
}"
)
```

![](https://drhuyue.site:10002/sammo3182/figure/lv_interTrust.png){fig-align="center" height=300}
:::

:::

::: {.column .fragment .nonincremental width="50%"}
指标：

1. 总体而言，您是认同多数人是值得信任的，还是防人之心不可无？
1. 您认为多数时候人们是乐于助人的还是自私自利的？
1. 如果有机会，您认为别人是会占您便宜，还是说会恪守约定、公平行事？
:::

::::



## 另一个🌰：运动员评价

![](https://drhuyue.site:10002/sammo3182/figure/lv_multitrait.png){fig-align="center" height=600}

:::{.notes}
裁判对滑雪运动员的评判

单侧: factor complexity = 1 （一个变量只贡献一个latent）  
双侧: factor complexity > 1
:::

## 定义公式

:::: {.columns}

::: {.column width="40%"}
:::{.callout-important}

$$
\begin{align}
X^* =& \Phi\Lambda' + \epsilon; \\
X =& \Lambda X_\xi + \epsilon,
\end{align}
$$

:::{style="text-align:center"}
**X**： 指标向量  
**&xi;**：潜在变量  
**&Lambda;<sub>X</sub>**: X = f(&xi;)系数(a.k.a., loading, path)  
**&epsilon;**：偏误向量  

**&Phi;**: 潜在变量的协方差矩阵  
**&Theta;<sub>&epsilon;</sub>**: 偏误的协方差矩阵
:::

:::


:::{.notes}
**&xi;**: ksi  
**&delta;**: delta  
**&Phi;**: phi  
**&Theta;<sub>&sigma;</sub>**: theta  

在EFA中潜在变量在等号左边，观测变量在右边
:::
:::

::: {.column .fragment width="60%"}
![](https://drhuyue.site:10002/sammo3182/figure/lv_partMultitrait.png){ fig-align="center" height=600}
:::

::::


## 估算

[测量矩阵]{.red}

$$
\begin{bmatrix}
x_1\\
x_2\\
x_3\\
x_4\\
x_5
\end{bmatrix} = 
\begin{bmatrix}
1 & 1 & 0\\
\lambda_{21} & 1 & 0\\
\lambda_{31} & 1 & 0\\
\lambda_{41} & 0 & 1\\
\lambda_{51} & 0 & 1
\end{bmatrix} \begin{bmatrix}\xi_1\\
\xi_2\\
\xi_3
\end{bmatrix} + \begin{bmatrix}\epsilon_1\\
\epsilon_2\\
\epsilon_3\\
\epsilon_4\\
\epsilon_5
\end{bmatrix}
$$

:::: {.columns}

::: {.column width="35%"}
[潜变量矩阵]{.navy}

$$\Phi = \begin{bmatrix}
\phi_{11} & & \\
0 & \phi_{22} & \\
0 & \phi_{23} & \phi_{33}
\end{bmatrix}$$

:::{.notes}
&phi;23$: classical 和showy 裁判的相关性
:::
:::

::: {.column width="65%"}
[偏误矩阵]{.green}

diag **&Theta;<sub>&sigma;</sub>** = diag[var(&epsilon;<sub>1</sub>) var(&epsilon;<sub>2</sub>)...var(&epsilon;<sub>5</sub>)]
:::

::::


:::{.fragment}
似曾相识？
:::



## Identification

a.k.a., 最多能连多少线？

:::: {.columns}

::: {.column width="50%"}
Identified: 当**&Lambda;、&Phi;、&Theta;**存在唯一解

**&Lambda;**: $X = f(\xi)$系数 (a.k.a., loading)；    
**&Phi;**: 潜在变量的协方差矩阵；   
**&Theta;**: 偏误的协方差矩阵。


:::{.fragment}
**t rule**:

t < q(q + 1)/2

t: 不可见   
q：可见
:::


:::{.notes}
Another way to calculate df.
:::

:::

::: {.column width="50%"}
为保证identifable进行的限制

1. Scaling
    + &lambda;<sub>11</sub> = 1;
    + 将潜在变量方差设为1(Standardized metric)
2. 参数调整
    + 特定因子loading设为0；
    + 偏误的协方差设为0；
    + 偏误的方差设为0；
:::

::::


## 最优解

$$\Sigma(\theta) = \Lambda_X\Phi\Lambda_X' + \Theta_\epsilon,$$
**&Sigma;**: 所有可见指标得协方差矩阵

:::{.notes}
寻找最优**&Sigma;**
:::

:::: {.columns}

::: {.column .fragment .nonincremental width="50%"}
全信息估计 (Maximum likelihood)

- Generalized Least Squares  
- Unweighted Least Squares
:::

::: {.column .fragment .nonincremental width="50%"}
有限信息估计

- Two Stage Least Squares
:::

::::


## 常见问题

:::: {.columns}

::: {.column width="35%"}
`错误：待分析的矩阵不是正定的`

+ 数据或协方差矩阵中录入错误
+ 缺失数据
+ 完全共线性
+ 异常值
:::

::: {.column width="35%"}
`错误：不恰当的解`

+ 录入错误
+ 总体至接近变量边界，加之抽样波动
+ 模型错误
+ 因素指标观测量过小（<150左右）且只有2指标
+ “Unlucky”样本
+ 异常值
:::

::: {.column width="30%"}
`错误：未收敛`

+ 录入错误
+ Unidentifiable
+ 模型不佳
+ 起始值不佳
+ 小样本（N<100）
+ 每个因素只有2指标
+ 异常值
+ 观测变量量纲极大差异
:::

::::

:::{.notes}
`Error: Matrix to be analyzed not positive definite`

+ Typo in data file or covariance matrix
+ Pairwise deletion of missing data
+ Perfect collinearity
+ Outliers/influential cases


`Error: Improper solutions`

+ Typo in program
+ Population value near the borderline combined with sampling fluctuation
+ Specification error
+ Small samples (<150 or so) combined with 2 indicators per factor
+ “unlucky” sample
+ Outliers/influential cases


`Error: Nonconvergence`

+ Typo in program, data file, or covariance matrix
+ Underidentified model
+ Poor model specification
+ Bad starting values
+ Small samples (N<100)
+ Only 2 indicators per factor
+ Outliers/influential cases
+ Observed variables in very different scale
:::



## 诊断

*Overall: &chi;<sup>2</sup>*，结果[显著]{.red}则说明整体模型可能[有问题]{.red}。^[然而，当N足够大时&chi;<sup>2</sup>通常显著。]

:::{.notes}
1. Because models are almost always incorrect, any otherwise reasonably fitting model can be rejected when sample size is sufficient
1. Also a poor fitting model could be accepted if there is insufficient power to detect misspecification.
:::


:::{.fragment .nonincremental}

*Incremental Fit Indices*：将模型与基线模型比较

1. Tucker-Lewis Index (TLI, &rho;<sub>2</sub>, Non-Normed Fit Index)
1. Comparative Fit Index (CFI)

:::

:::{.notes}
基线模型：只保留可见变量的方差和协方差

1 理想情况    
<.95 不可接受

CFI可以>1, 这种情况视为1
:::


:::{.fragment .nonincremental}
*Absolute Fit Indices*

1. Root Mean Square Error of Approximation (RMSEA)
1. Standardized Root Mean Square Residual (SRMR)
:::

:::{.notes}
+ 0 理想情况
+ &le; 0.05 不错
+ 0.05 ~ 0.08 差强人意
+ &ge; 0.1 不可接受
:::



## 🌰 Holzinger & Swineford 1939


对初中生精神状况的调查： 视觉因素（x<sub>1~3</sub>） + 阅读因素（x<sub>4~6</sub>）+ （表达因素：x<sub>7~9</sub>）

```{r diagram-cfa, fig.align='center'}
HS.model <- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '
fit <- cfa(HS.model, data = HolzingerSwineford1939)


semPaths(
  fit,
  layout = "tree",
  curve = 1,
  rotation = 4,
  nCharNodes = 0,
  mar = c(3, 20, 3, 20),
  border.width = 1.0,
  esize = 1.0,
  edge.color = "black",
  label.scale = FALSE,
  label.cex = 1.0,
  residuals = FALSE,
  fixedStyle = 1,
  freeStyle = 1,
  curvePivot = FALSE,
  sizeMan = 7,
  sizeLat = 10
)
```

## 估测结果与诊断

```{r results-hsModel}
fit <- cfa(HS.model, data = HolzingerSwineford1939)

summary(fit, fit.measures = TRUE)
```


## 结构方程模型

:::: {.columns}

::: {.column .nonincremental width="50%"}
- Structural equation model (SEM)   
- LISREL (Linear Structural ReLationships) models   
- Covariance structure models   
- Latent variable models    
- Structural equations with latent variables    

![](https://drhuyue.site:10002/sammo3182/figure/lv_sem.png){.fragment fig-align="center" height=200}
:::

::: {.column .fragment .nonincremental width="50%"}
- Confirmative factor analysis  
- Multiple regression  
- Multivariate regression  
- ANOVA  
- General linear model  
- Path analysis  
- Recursive models  
- Dichotomous and ordered probit  
- Seemingly unrelated regressions  
- Simultaneous models  
- Latent growth curve models  
......
:::

::::


## SEM (in terms of CFA)

:::: {.columns}

::: {.column width="50%"}
**结构**

+ 观察变量： X + Y
+ 模型建构：
    1. Latent variable model
    1. Measurement model (CFA)
    1. Relations among the errors 
+ 依然要求identification

**估计**：MLE
:::

::: {.column width="50%"}
**诊断** (完全一样)

+ Overall：&chi;<sup>2</sup>
+ Incremental：
    + TLI & CLI
    + Incremental Fit Index(IFI, &Delta;<sup>2</sup>)
+ Absolute:
    + RMSEA
    + BIC
:::

::::

:::{.fragment}
:::{.callout-tip}
## SEM进阶

*敬请注意*：[SEM结果仍表现相关关系。]{.red}

处理Measurement errors；处理非线性变量(hint: GSEM)；纳入多层效应；处理缺失值

:::
:::



## 🌰 Bollen 1989

政治民主（1960，1965）与工业化

```{r diagram-sem, fig.align='center', fig.height=4, fig.keep="last"}
model <- '
  # measurement model
    ind60 =~ x1 + x2 + x3
    dem60 =~ y1 + y2 + y3 + y4
    dem65 =~ y5 + y6 + y7 + y8
  # regressions
    dem60 ~ ind60
    dem65 ~ ind60 + dem60
  # residual correlations
    y1 ~~ y5
    y2 ~~ y4 + y6
    y3 ~~ y7
    y4 ~~ y8
    y6 ~~ y8
'
fit <- sem(model, data = PoliticalDemocracy)
Graph <- semPaths(
  fit,
  #layout=L,
  layout = "tree2",
  nCharNodes = 0,
  curve = 1,
  rotation = 4,
  #mar=c(3,3,3,3),
  edge.color = "black",
  border.width = 1.0,
  esize = 1.0,
  label.scale = FALSE,
  label.cex = 1.0,
  residuals = FALSE,
  fixedStyle = 1,
  freeStyle = 1,
  curvePivot = FALSE,
  #style="LISREL",
  exoVar = FALSE,
  sizeMan = 7,
  sizeLat = 10,
  DoNotPlot = FALSE
)
L <- matrix(
  c(
    0.4 ,
    1 ,
    0.7 ,
    1 ,
    1.0 ,
    1 ,
    -1.0 ,
    1 ,
    -1.0 ,
    0.71 ,
    -1.0 ,
    0.43 ,
    -1.0 ,
    0.14 ,
    -1.0 ,
    -0.14 ,
    -1.0 ,
    -0.43 ,
    -1.0 ,
    -0.71 ,
    -1.0 ,
    -1    ,
    0.7 ,
    0.4 ,
    0.0 ,
    0.4 ,
    0.0 ,
    -0.4
  ),
  14,
  2,
  byrow = TRUE
)
qgraph(Graph, layout = L, arrowAngle = 0.5)
```

## 结果与诊断

```{r results-semModel}
fit <- sem(model, data = PoliticalDemocracy)

summary(fit, fit.measures = TRUE)
```


## 总结

:::: {.columns}

::: {.column width="50%"}
:::{.fragment .nonincremental}

* 潜在变量分析概述
    + *因素分析*
    + 类型分析
    
:::


:::{.fragment .nonincremental}
* EFA
    + 探索性因子分析：通过loading找到潜在变量
    + EFA诊断：Kaiser's criterion
    + EFA vs. PCA: 结果相似，逻辑不同

:::

:::

::: {.column width="50%"}
:::{.fragment .nonincremental}
* CFA
    + 验证性因子分析：检验潜在变量对于观察指标是否有影响
    + CFA诊断：&chi;<sup>2</sup>, TLI/CFI，RMSEA/SRMR

:::


:::{.fragment .nonincremental}
* SEM 
    + Latent + measurement models
    + 不能证明因果关系！
:::
:::

::::

:::{.fragment}
::: {.r-fit-text}
**待解之题**：观测变量与潜变量之间关系要是[非线性]{.red}的呢？
:::

:::

