<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>潜在变量分析（基础）</title>
    <meta charset="utf-8" />
    <meta name="author" content="胡悦" />
    <script src="03_latentVariableI_files/header-attrs-2.11/header-attrs.js"></script>
    <link href="03_latentVariableI_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="03_latentVariableI_files/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="03_latentVariableI_files/tile-view-0.2.6/tile-view.js"></script>
    <link href="03_latentVariableI_files/tachyons-4.12.0/tachyons.min.css" rel="stylesheet" />
    <link href="03_latentVariableI_files/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="03_latentVariableI_files/panelset-0.2.6/panelset.js"></script>
    <script src="03_latentVariableI_files/js-cookie-3.0.0/js.cookie.js"></script>
    <script src="03_latentVariableI_files/peerjs-1.3.1/peerjs.min.js"></script>
    <script src="03_latentVariableI_files/tiny.toast-1.0.0/toast.min.js"></script>
    <link href="03_latentVariableI_files/xaringanExtra-broadcast-0.2.6/broadcast.css" rel="stylesheet" />
    <script src="03_latentVariableI_files/xaringanExtra-broadcast-0.2.6/broadcast.js"></script>
    <script src="03_latentVariableI_files/htmlwidgets-1.5.4/htmlwidgets.js"></script>
    <script src="03_latentVariableI_files/viz-1.8.2/viz.js"></script>
    <link href="03_latentVariableI_files/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
    <script src="03_latentVariableI_files/grViz-binding-1.0.6.1/grViz.js"></script>
    <link rel="stylesheet" href="zh-CN_custom.css" type="text/css" />
    <link rel="stylesheet" href="style_ui.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# 潜在变量分析（基础）
## Learning Latent Variable Analysis with Dr. Hu (Basic)
### 胡悦

---







.pull-left[
## 内容概要

潜在变量分析概述

什么是EFA
+ EFA诊断
+ EFA vs. PCA

什么是CFA
  + CFA诊断
  
SEM简介

]

--

.pull-right[
## 操作语言

* R
    + [`psych`](https://personality-project.org/r/psych/vignettes/intro.pdf)
    + [`laavan`](https://lavaan.ugent.be/)
]

---

class: inverse, bottom

# 潜在变量分析：一种方法

---

## 潜在变量

.pull-left[
&lt;img src="images/lv_LoveLife.jpg" height = 400 /&gt;
]

???

Anna Kendrick's 2020 show, showing how difficult to find "the one." This "being loved" is a latent variable.

--

.pull-right[
&lt;img src="images/lv_jamesStimson.jpg" height = 400 /&gt;
]

---


## 为什么要了解潜在变量？

.bg-black.golden.ba.shadow-5.ph4.mt3[
"Latent variable analysis is the .red[cornerstone] of successful scientific inquiry." .tr[--- Delli Carpini and Keeter (1993)]
]

???

Delli Carpini, M. X., and S. Keeter. 1993. “Measuring Political Knowledge: Putting First Things First.” American Journal of Political Science 37 (4): 1179–1206.

--

.pull-left[

*Latent Variable*

1. 不可见(Unobservable)
1. 多维度(Multidimensional)
1. 有效果(Consequential)

]

???

兜里有多少钱，不可见，但维度单一，不宜用潜变量分析，更好的办法是翻兜

The latent variable per se can't be directly measured. But its consequences in opinions and behaviors can be observed.

--

.pull-right[
几乎涵盖所有社会科学学科

* 抽象
* 复杂
* 综合
]


---

class: center

## 分析方法：一个例子

测量个体的“社会资本”（social capital）

指标问题X（1~10）：

1. 您是否信任身边人？
1. 您在政府机关有没有亲戚？
1. 您的朋友是否和您的想法经常一致？


--

.pull-left[
累加型综合法(additive scales)

`$$\tilde{X} = (X_1 + X_2 + X_3)/3.$$`

Getting the mean right (?)
]

--

.pull-right[
*Concerns*:

1. 平等权重(equal weight)
1. 数据敏感(extreme value sensitivity)
1. 忽略极化(polarity ignoring)
]

---

## 易求无价宝，难得有心郎！: Advanced Methods

.pull-left[
**因素分析模型(Factorial Models)**

1. 探索性因子分析(EFA)
1. 验证性因子分析(CFA)
1. 结构方程模型(SEM)
]

???

鱼玄机《赠邻女》：羞日遮罗袖，愁春懒起妆。易求无价宝，难得有心郎

--

.pull-right[

**类型分析模型(Topological Models)**

1. 项目反应理论(IRT)
1. MRP
1. 跨群组项目反应(GIRT, DCPO)

]

---

class: inverse, bottom

# 因素分析初探

---

## 理论与操作

可见指标(indicators) .red[.large[&amp;larr;]] 潜在变量

???

uncover the underlying structure of a relatively large set of variables. 

--

.pull-left[
### 操作

.red[Minimum] factors for the variances

a.k.a. 变量简化  
]

.pull-right[
&lt;img src="images/lv_jiangwei.jpg" height = 300 /&gt;
]

???

determine the minimum number of hypothetical factors or components that account for the variance between variables.

---

## 过程问题

.pull-left[&lt;img src="images/lv_efa.png" height = 500 /&gt;]

.pull-right[
*Known*: I wanna fewer variables

*Unknown*: 
+ How many? 
+ How to combine?
]

---

class: inverse, bottom

# 探索性因子分析
## Exploratory Factor Analysis

---

class: center

## 概念公式

.center[.large[**X&lt;sup&gt;*&lt;/sup&gt; = &amp;Phi;&amp;Lambda;' + &amp;delta;**]]


**X&lt;sup&gt;*&lt;/sup&gt;**: 潜在变量  
**&amp;Phi;**: 指标选择  
**&amp;Lambda;**: 单项贡献（a.k.a., factor loading）  
**&amp;delta;** 选择误差

???

Quinn, Kevin M. undefined/ed. “Bayesian Factor Analysis for Mixed Ordinal and Continuous Responses.” Political Analysis 12(4): 338–53.

--

## 实际操作

1. 因子个数选择
1. 因子提取
1. Rotation
1. 因子合成
1. 结果检验

---

## 一个心理学案例

19,719 参与者, the "Big Five Personality" Test

变量名：

```
## # A tibble: 19,719 x 57
##     race   age engnat gender  hand source
##    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
##  1     3    53      1      1     1      1
##  2    13    46      1      2     1      1
##  3     1    14      2      2     1      1
##  4     3    19      2      2     1      1
##  5    11    25      2      2     1      2
##  6    13    31      1      2     1      2
##  7     5    20      1      2     1      5
##  8     4    23      2      1     1      2
##  9     5    39      1      2     3      4
## 10     3    18      1      2     1      5
## # ... with 19,709 more rows, and 51 more
## #   variables: country &lt;chr&gt;, E1 &lt;dbl&gt;,
## #   E2 &lt;dbl&gt;, E3 &lt;dbl&gt;, E4 &lt;dbl&gt;,
## #   E5 &lt;dbl&gt;, E6 &lt;dbl&gt;, E7 &lt;dbl&gt;,
## #   E8 &lt;dbl&gt;, E9 &lt;dbl&gt;, E10 &lt;dbl&gt;,
## #   N1 &lt;dbl&gt;, N2 &lt;dbl&gt;, N3 &lt;dbl&gt;,
## #   N4 &lt;dbl&gt;, N5 &lt;dbl&gt;, N6 &lt;dbl&gt;, ...
```

???

经验开放性Openness, 尽责性Conscientiousness, 外向型Extraversion, 亲和性Agreeableness, 情绪不稳定型Neuroticism

https://quantdev.ssri.psu.edu/tutorials/intro-basic-exploratory-factor-analysis

---

## 因子个数选择

### 相关性分析

&lt;img src="03_latentVariableI_files/figure-html/corrplot-1.png" style="display: block; margin: auto;" /&gt;

---

### Horn's Parallel Analysis

.pull-left[
已知观测数据集**O**&lt;sub&gt;m&amp;times;n&lt;/sub&gt;

1. 创建随机数据集**R**&lt;sub&gt;m&amp;times;n&lt;/sub&gt;;  
1. 相关矩阵&lt;sub&gt;**R**&lt;/sub&gt; 和 &amp;lambda;&lt;sub&gt;**R**&lt;/sub&gt;;  
1. 相关矩阵&lt;sub&gt;**Ok**&lt;/sub&gt; 和 &amp;lambda;&lt;sub&gt;**Ok**&lt;/sub&gt; (k为因子数)
1. &amp;lambda;&lt;sub&gt;**Ok**&lt;/sub&gt; vs. &amp;lambda;&lt;sub&gt;**R**&lt;/sub&gt;

A. 如果&amp;lambda;&lt;sub&gt;**Ok**&lt;/sub&gt; &lt; &amp;lambda;&lt;sub&gt;**R**&lt;/sub&gt;, 则 ~~k~~  
B. Kaiser criterion
]

???

&amp;lambda;是相关矩阵特征值
Kaiser criterion: 特征值&lt;1 不可

--

.pull-right[
&lt;img src="03_latentVariableI_files/figure-html/parallelAnalysis-1.png" style="display: block; margin: auto;" /&gt;
]

---

## 因子提取(Factor Extraction)

+ Minimum residual (OLS)
+ Principal axes
+ Alpha factoring
+ Weighted least squares
+ Minimum rank
+ .red[Maximum likelihood (ML, minimum &amp;chi;&lt;sup&gt;2&lt;/sup&gt; goodness of fit)]

---

## Rotation

.center[&lt;img src="images/lv_rotation.jpg" height = 400 /&gt;]

???
Rotation:

A pattern of loadings where each item loads strongly on only one of the factors, and much more weakly on the other factors.

--

* Orthogonal: Varimax, quartimax, bentlerT, geominT, bifactor  
* .red[Oblique]: Oblimin, quartimin, simplimax, bentlerQ, geominQ, biquartimin


???

Orthogonal(正交)

优选Oblique，允许factor间correlate

---

.pull-left[
## 因子合成


```
## 
## Loadings:
##     MR1    MR2    MR3    MR4    MR5   
## E1  -0.505                            
## E2   0.496 -0.338                     
## E3  -0.698                            
## E4   0.571         0.299              
## E5  -0.649  0.309                     
## E6   0.541                            
## E7  -0.616                            
## E8   0.361         0.326              
## E9  -0.448        -0.314              
## E10  0.555                            
## N1   0.427  0.469                     
## N2  -0.346                            
## N3   0.336  0.439  0.302              
## N4                                    
## N5   0.384  0.373                     
## N6   0.464  0.531                     
## N7   0.449  0.508                     
## N8   0.483  0.523                     
## N9   0.491  0.412                0.342
## N10  0.534  0.378                     
## A1                                    
## A2  -0.486  0.352                     
## A3                -0.368              
## A4  -0.320  0.408  0.485        -0.328
## A5   0.367 -0.348 -0.319              
## A6          0.359  0.408              
## A7   0.518 -0.345                     
## A8  -0.360         0.337              
## A9  -0.329  0.428  0.417              
## A10 -0.503                            
## C1  -0.298         0.326         0.326
## C2          0.305 -0.320        -0.299
## C3                                    
## C4   0.414  0.399                     
## C5                 0.381         0.365
## C6          0.325 -0.336        -0.303
## C7                 0.380         0.328
## C8   0.371        -0.314              
## C9                 0.425         0.381
## C10                                   
## O1                        0.560       
## O2                       -0.494       
## O3                        0.484       
## O4                       -0.415       
## O5  -0.354                0.522       
## O6                       -0.425       
## O7  -0.297                0.454       
## O8                        0.543       
## O9                        0.352       
## O10 -0.320                0.586       
## 
##                  MR1   MR2   MR3   MR4
## SS loadings    7.505 4.071 3.149 2.905
## Proportion Var 0.150 0.081 0.063 0.058
## Cumulative Var 0.150 0.232 0.294 0.353
##                  MR5
## SS loadings    2.179
## Proportion Var 0.044
## Cumulative Var 0.396
```
]

--

.pull-right[
## 诊断指标

1. Sum of squared (SS) loading&lt;sup&gt;1&lt;/sup&gt;
1. Communality &amp; Uniqueness
1. Root means square of residuals(RMSR)
1. Tucker-Lewis Indes (TLI)
1. Reliability test (Crobach's &amp;alpha;)&lt;sup&gt;2&lt;/sup&gt;
]
.footnote[
[1] 特征值  
[2] 为每个因子分别计算
]
]

???

SS：Kaiser criterion: &amp;lambda; &lt; 1 不可
Communality:  SS of all the factor loadings for a given variable
Uniqueness: 1 - Communality
RMSR &lt; 0.05
TLI &gt; 0.9

Crobach's &amp;alpha;: 计算因子分布的variables是不是内部一致，除非发表，不大必要

---


```r
result_efa
```

```
## Factor Analysis using method =  minres
## Call: fa(r = ., nfactors = 5, rotate = "oblimin", fm = "minres")
## Standardized loadings (pattern matrix) based upon correlation matrix
##       MR1   MR2   MR3   MR4   MR5   h2
## E1  -0.50  0.26 -0.28 -0.12  0.21 0.46
## E2   0.50 -0.34  0.26  0.13 -0.18 0.48
## E3  -0.70  0.15 -0.11 -0.21  0.10 0.57
## E4   0.57 -0.19  0.30  0.17 -0.20 0.52
## E5  -0.65  0.31 -0.16 -0.11  0.20 0.60
## E6   0.54 -0.25  0.19 -0.06 -0.10 0.40
## E7  -0.62  0.28 -0.23 -0.16  0.19 0.57
## E8   0.36 -0.21  0.33  0.10 -0.18 0.33
## E9  -0.45  0.23 -0.31 -0.03  0.21 0.40
## E10  0.55 -0.15  0.28  0.15 -0.16 0.45
## N1   0.43  0.47  0.21  0.03  0.21 0.49
## N2  -0.35 -0.28 -0.16 -0.03 -0.20 0.27
## N3   0.34  0.44  0.30  0.08  0.15 0.43
## N4  -0.27 -0.22 -0.07 -0.11  0.00 0.14
## N5   0.38  0.37  0.05 -0.05  0.16 0.32
## N6   0.46  0.53  0.14  0.00  0.23 0.57
## N7   0.45  0.51 -0.01  0.08  0.24 0.52
## N8   0.48  0.52  0.00  0.07  0.25 0.57
## N9   0.49  0.41  0.02  0.09  0.34 0.54
## N10  0.53  0.38  0.09  0.16  0.07 0.47
## A1   0.25 -0.16 -0.24 -0.01  0.24 0.20
## A2  -0.49  0.35  0.14 -0.07 -0.17 0.41
## A3   0.26  0.10 -0.37  0.12  0.21 0.27
## A4  -0.32  0.41  0.48 -0.09 -0.33 0.62
## A5   0.37 -0.35 -0.32  0.10  0.29 0.45
## A6  -0.15  0.36  0.41 -0.13 -0.20 0.37
## A7   0.52 -0.34 -0.21  0.12  0.24 0.50
## A8  -0.36  0.28  0.34 -0.06 -0.20 0.36
## A9  -0.33  0.43  0.42 -0.04 -0.22 0.51
## A10 -0.50  0.18  0.13 -0.04 -0.03 0.31
## C1  -0.30 -0.24  0.33  0.16  0.33 0.39
## C2   0.13  0.31 -0.32  0.05 -0.30 0.31
## C3  -0.19 -0.07  0.29  0.29  0.17 0.24
## C4   0.41  0.40 -0.28  0.01 -0.20 0.45
## C5  -0.30 -0.22  0.38 -0.04  0.36 0.41
## C6   0.25  0.33 -0.34  0.01 -0.30 0.37
## C7  -0.12 -0.13  0.38  0.12  0.33 0.30
## C8   0.37  0.21 -0.31 -0.03 -0.14 0.30
## C9  -0.24 -0.13  0.43  0.02  0.38 0.40
## C10 -0.25 -0.10  0.28  0.26  0.24 0.28
## O1  -0.19  0.02 -0.09  0.56 -0.04 0.36
## O2   0.27  0.07  0.09 -0.49  0.17 0.36
## O3  -0.09  0.20 -0.07  0.48 -0.09 0.30
## O4   0.19 -0.04  0.04 -0.41  0.21 0.26
## O5  -0.35  0.04 -0.08  0.52  0.09 0.42
## O6   0.23 -0.11  0.08 -0.42  0.11 0.27
## O7  -0.30 -0.07  0.00  0.45  0.04 0.30
## O8  -0.03  0.08 -0.15  0.54 -0.01 0.32
## O9   0.01  0.17  0.18  0.35 -0.09 0.19
## O10 -0.32  0.14 -0.12  0.59  0.00 0.48
##       u2 com
## E1  0.54 2.7
## E2  0.52 2.9
## E3  0.43 1.4
## E4  0.48 2.3
## E5  0.40 1.9
## E6  0.60 1.8
## E7  0.43 2.1
## E8  0.67 3.4
## E9  0.60 2.9
## E10 0.55 2.0
## N1  0.51 2.8
## N2  0.73 3.1
## N3  0.57 3.1
## N4  0.86 2.5
## N5  0.68 2.4
## N6  0.43 2.5
## N7  0.48 2.5
## N8  0.43 2.5
## N9  0.46 2.9
## N10 0.53 2.1
## A1  0.80 3.7
## A2  0.59 2.4
## A3  0.73 2.9
## A4  0.38 3.7
## A5  0.55 4.1
## A6  0.63 3.0
## A7  0.50 2.8
## A8  0.64 3.5
## A9  0.49 3.4
## A10 0.69 1.4
## C1  0.61 4.3
## C2  0.69 3.4
## C3  0.76 3.5
## C4  0.55 3.2
## C5  0.59 3.5
## C6  0.63 3.8
## C7  0.70 2.7
## C8  0.70 2.9
## C9  0.60 2.8
## C10 0.72 4.2
## O1  0.64 1.3
## O2  0.64 1.9
## O3  0.70 1.6
## O4  0.74 2.0
## O5  0.58 1.9
## O6  0.73 2.0
## O7  0.70 1.8
## O8  0.68 1.2
## O9  0.81 2.2
## O10 0.52 1.8
## 
##                        MR1  MR2  MR3  MR4
## SS loadings           7.50 4.07 3.15 2.90
## Proportion Var        0.15 0.08 0.06 0.06
## Cumulative Var        0.15 0.23 0.29 0.35
## Proportion Explained  0.38 0.21 0.16 0.15
## Cumulative Proportion 0.38 0.58 0.74 0.89
##                        MR5
## SS loadings           2.18
## Proportion Var        0.04
## Cumulative Var        0.40
## Proportion Explained  0.11
## Cumulative Proportion 1.00
## 
## Mean item complexity =  2.7
## Test of the hypothesis that 5 factors are sufficient.
## 
## The degrees of freedom for the null model are  1225  and the objective function was  19.12 with Chi Square of  376676
## The degrees of freedom for the model are 985  and the objective function was  3.01 
## 
## The root mean square of the residuals (RMSR) is  0.03 
## The df corrected root mean square of the residuals is  0.04 
## 
## The harmonic number of observations is  19718 with the empirical chi square  52912.5  with prob &lt;  0 
## The total number of observations was  19719  with Likelihood Chi Square =  59268.15  with prob &lt;  0 
## 
## Tucker Lewis Index of factoring reliability =  0.807
## RMSEA index =  0.055  and the 90 % confidence intervals are  0.054 0.055
## BIC =  49527.15
## Fit based upon off diagonal values = 0.97
## Measures of factor score adequacy             
##                                                    MR1
## Correlation of (regression) scores with factors   0.97
## Multiple R square of scores with factors          0.93
## Minimum correlation of possible factor scores     0.87
##                                                    MR2
## Correlation of (regression) scores with factors   0.94
## Multiple R square of scores with factors          0.89
## Minimum correlation of possible factor scores     0.77
##                                                    MR3
## Correlation of (regression) scores with factors   0.92
## Multiple R square of scores with factors          0.84
## Minimum correlation of possible factor scores     0.69
##                                                    MR4
## Correlation of (regression) scores with factors   0.91
## Multiple R square of scores with factors          0.82
## Minimum correlation of possible factor scores     0.64
##                                                    MR5
## Correlation of (regression) scores with factors   0.89
## Multiple R square of scores with factors          0.79
## Minimum correlation of possible factor scores     0.59
```

---

## 因子在哪里？

"score"

&lt;img src="03_latentVariableI_files/figure-html/scores-1.png" style="display: block; margin: auto;" /&gt;

---

## Principal Component Analysis

与EFA比肩的选择

--

.center[&lt;img src="images/lv_pca.png" height = 300 /&gt;]

.large[.center[C = w&lt;sub&gt;i&lt;/sub&gt;Y&lt;sub&gt;i&lt;/sub&gt;]]

???

create one or more index variables (Components) from a larger set of measured variables (Y)

---

## PCA vs. EFA

结果或近似，逻辑大不同（注意箭头方向！）

.center[&lt;img src="images/lv_pcaVsEfa.PNG" height = 400 /&gt;]

???
PCA: measurement to index   

write all variables in terms of a smaller set of features which allows for a maximum amount of variance to be retained in the data.   


EFA: indices to measurement (of a latent variable)   

find a set of features which allow for understanding as much of the correlations between measured variables as possible. individually.

---

## 怎么选

--

* PCA最大程度保留可见变量信息，EFA旨在提取不可变量特征；

--

* 当Variable之间关系不那么紧密或受同一变量影响，PCA &gt; EFA；

--

* 当估计潜在变量时，PCA可能夸大可见指标的影响

---

class: inverse, bottom

# 验证性因子分析
## Confirmative Factor Analysis

---


## 探索性 vs 验证性：实现

.pull-left[
**EFA: 数据指向**

1. 实证观察（归纳）
1. 未知维度
    + 每个维度都产生影响
1. 多重指标
    + Loading大小之分
1. 无视测量偏差关联
1. Underidentified

]

.pull-right[
**CFA: 理论指向**

1. 理论定义（演绎）
1. 明确维度
    + 维度-指标关系明确
1. 单一指标
    + Loading有无之分
1. 允许测量误差相关
1. 必须identifiable
]

---

## CFA 指标选择

1. 严格依据理论
1. 每维度一指标

--

E.g., 人际信任

定义：.red[相信]他人不会.navy[伤害自己]或.navy[违背约定].

--

指标：

1. 总体而言，您是认同多数人是值得信任的，还是防人之心不可无？
1. 您认为多数时候人们是乐于助人的还是自私自利的？
1. 如果有机会，您认为别人是会占您便宜，还是说会恪守约定、公平行事？


---

## CFA 指标选择

操作原则：

1. 每个维度一个指标，但维度拆分.red[艺术&gt;技术]

--

1. .red[~~原因~~]效果指标

--

<div id="htmlwidget-7544e367878cb8a261f0" style="width:504px;height:360px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-7544e367878cb8a261f0">{"x":{"diagram":"digraph {\n\ngraph[layout = dot]\n\nnode[shape = rectangle, style = filled, fillcolor = Linen]\n\ns [label = \"Social Capital\", shape = \"ellipse\"]\nd [label = \"Interpersonal\n Trust\"]\nj [label =  \"Trusty\"]\ni [label = \"Credible\"]\n\n# edge definitions with the node IDs\ns -> {d, j, i}\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>


---

## 模型建构

.center[&lt;img src="images/lv_multitrait.png" height = 550 /&gt;]

???

裁判对滑雪运动员的评判

单侧: factor complexity = 1 （一个变量只贡献一个latent）  
双侧: factor complexity &gt; 1

---

## 定义公式

.center[
EFA: **X&lt;sup&gt;*&lt;/sup&gt; = &amp;Phi;&amp;Lambda;' + &amp;delta;**;    
CFA: **X = &amp;Lambda;&lt;sub&gt;X&lt;/sub&gt;&amp;xi;\* + &amp;delta;**]

**X**： 指标向量  
**&amp;xi;**：潜在变量  
**&amp;Lambda;&lt;sub&gt;X&lt;/sub&gt;**: X = f(&amp;xi;)系数(a.k.a., loading, path)  
**&amp;delta;**：偏误向量  

**&amp;Phi;**: 潜在变量的协方差矩阵  
**&amp;Theta;&lt;sub&gt;&amp;sigma;&lt;/sub&gt;**: 偏误的协方差矩阵

???

**&amp;xi;**: ksi  
**&amp;delta;**: delta  
**&amp;Phi;**: phi  
**&amp;Theta;&lt;sub&gt;&amp;sigma;&lt;/sub&gt;**: theta  

在EFA中潜在变量在等号左边，观测变量在右边

---

.center[&lt;img src="images/lv_partMultitraitpng.png" height = 250 /&gt;]

`$$\begin{bmatrix}
x_1\\
x_2\\
x_3\\
x_4\\
x_5
\end{bmatrix} = 
\begin{bmatrix}
1 &amp; 1 &amp; 0\\
\lambda_{21} &amp; 1 &amp; 0\\
\lambda_{31} &amp; 1 &amp; 0\\
\lambda_{41} &amp; 0 &amp; 1\\
\lambda_{51} &amp; 0 &amp; 1
\end{bmatrix} \begin{bmatrix}\xi_1\\
\xi_2\\
\xi_3
\end{bmatrix} + \begin{bmatrix}\delta_1\\
\delta_2\\
\delta_3\\
\delta_4\\
\delta_5
\end{bmatrix}$$`

---

潜在变量矩阵

`$$\Phi = \begin{bmatrix}
\phi_{11} &amp; &amp; \\
0 &amp; \phi_{22} &amp; \\
0 &amp; \phi_{23} &amp; \phi_{33}
\end{bmatrix}$$`


偏误矩阵

diag **&amp;Theta;&lt;sub&gt;&amp;sigma;&lt;/sub&gt;** = diag[var(&amp;delta;&lt;sub&gt;1&lt;/sub&gt;) var(&amp;delta;&lt;sub&gt;2&lt;/sub&gt;)...var(&amp;delta;&lt;sub&gt;5&lt;/sub&gt;)]

???

&amp;phi;23$: classical 和showy 裁判的相关性

---

## 你最多能连多少线？：Identification

\begin{cases}
y = x + z\\
x = 2y - 3z
\end{cases}

--

.pull-left[
当**&amp;Lambda;、&amp;Phi;、&amp;Theta;**存在唯一解时，模型是identified.


&amp;Lambda;: `\(X = f(\xi)\)`系数(a.k.a., loading)  
&amp;Phi;: 潜在变量的协方差矩阵  
&amp;Theta; 偏误的协方差矩阵


**t rule**:

t &lt; q(q + 1)/2

t: 不可见
q：可见
]

???

Another way to calculate df.

--

.pull-right[
为保证identifable， 要对CFA进行限制

1. Scaling
    + &amp;lambda;&lt;sub&gt;11&lt;/sub&gt; = 1;
    + 将潜在变量方差设为1(Standardized metric)
2. 参数调整
    + 特定因子loading设为0；
    + 偏误的协方差设为0；
    + 偏误的方差设为0；
]

---

## 解方程

**&amp;Sigma;**: 所有可见指标得协方差矩阵

.center[.large[**&amp;Sigma;(&amp;theta;) = &amp;Lambda;&lt;sub&gt;X&lt;/sub&gt;&amp;Phi;&amp;Lambda;&lt;sub&gt;X&lt;/sub&gt;' + &amp;Theta;&lt;sub&gt;&amp;delta;&lt;/sub&gt;**]]

.pull-left[
全信息估计：

Maximum likelihood:   
Generalized Least Squares  
Unweighted Least Squares
]

.pull-right[
有限信息估计：

Two Stage Least Squares

]

???

寻找最优**&amp;Sigma;**

---

## 常见问题
`Error: Matrix to be analyzed not positive definite`

+ Typo in data file or covariance matrix
+ Pairwise deletion of missing data
+ Perfect collinearity
+ Outliers/influential cases

--

`Error: Improper solutions`

+ Typo in program
+ Population value near the borderline combined with sampling fluctuation
+ Specification error
+ Small samples (&lt;150 or so) combined with 2 indicators per factor
+ “unlucky” sample
+ Outliers/influential cases

---

`Error: Nonconvergence`

+ Typo in program, data file, or covariance matrix
+ Underidentified model
+ Poor model specification
+ Bad starting values
+ Small samples (N&lt;100)
+ Only 2 indicators per factor
+ Outliers/influential cases
+ Observed variables in very different scale

---

## 效果诊断

*Overall: &amp;chi;&lt;sup&gt;2&lt;/sup&gt;*

结果.red[显著]则说明整体模型可能.red[有问题]。

--

然而，当N足够大时&amp;chi;&lt;sup&gt;2&lt;/sup&gt;通常显著

???

1. Because models are almost always incorrect, any otherwise reasonably fitting model can be rejected when sample size is sufficient
1. Also a poor fitting model could be accepted if there is insufficient power to detect misspecification.

--

*Incremental Fit Indices*

将模型与基线模型比较

???

基线模型：只保留可见变量的方差和协方差

--

1. Tucker-Lewis Index (TLI, &amp;rho;&lt;sub&gt;2&lt;/sub&gt;, Non-Normed Fit Index)

1. Comparative Fit Index (CFI)

+ 1 理想情况
+ &lt;.95 不可接受

???

CFI可以&gt;1, 这种情况视为1

---

*Absolute Fit Indices*

1. Root Mean Square Error of Approximation (RMSEA)
1. Standardized Root Mean Square Residual (SRMR)

+ 0 理想情况
+ &amp;le; 0.05 不错
+ 0.05 ~ 0.08 差强人意
+ &amp;ge; 0.1 不可接受

---

## 实例：Holzinger &amp; Swineford 1939

.pull-left[
对初中生精神状况的调查：
+ 视觉因素：x&lt;sub&gt;1~3&lt;/sub&gt;
+ 阅读因素：x&lt;sub&gt;4~6&lt;/sub&gt;
+ 表达因素：x&lt;sub&gt;7~9&lt;/sub&gt;
]

.pull-right[
&lt;img src="03_latentVariableI_files/figure-html/diagram-cfa-1.png" style="display: block; margin: auto;" /&gt;
]

--


```
## lavaan 0.6-9 ended normally after 35 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                        21
##                                                       
##   Number of observations                           301
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                                85.306
##   Degrees of freedom                                24
##   P-value (Chi-square)                           0.000
## 
## Model Test Baseline Model:
## 
##   Test statistic                               918.852
##   Degrees of freedom                                36
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    0.931
##   Tucker-Lewis Index (TLI)                       0.896
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)              -3737.745
##   Loglikelihood unrestricted model (H1)      -3695.092
##                                                       
##   Akaike (AIC)                                7517.490
##   Bayesian (BIC)                              7595.339
##   Sample-size adjusted Bayesian (BIC)         7528.739
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.092
##   90 Percent confidence interval - lower         0.071
##   90 Percent confidence interval - upper         0.114
##   P-value RMSEA &lt;= 0.05                          0.001
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.065
## 
## Parameter Estimates:
## 
##   Standard errors                             Standard
##   Information                                 Expected
##   Information saturated (h1) model          Structured
## 
## Latent Variables:
##                    Estimate  Std.Err
##   visual =~                         
##     x1                1.000         
##     x2                0.554    0.100
##     x3                0.729    0.109
##   textual =~                        
##     x4                1.000         
##     x5                1.113    0.065
##     x6                0.926    0.055
##   speed =~                          
##     x7                1.000         
##     x8                1.180    0.165
##     x9                1.082    0.151
##   z-value  P(&gt;|z|)
##                   
##                   
##     5.554    0.000
##     6.685    0.000
##                   
##                   
##    17.014    0.000
##    16.703    0.000
##                   
##                   
##     7.152    0.000
##     7.155    0.000
## 
## Covariances:
##                    Estimate  Std.Err
##   visual ~~                         
##     textual           0.408    0.074
##     speed             0.262    0.056
##   textual ~~                        
##     speed             0.173    0.049
##   z-value  P(&gt;|z|)
##                   
##     5.552    0.000
##     4.660    0.000
##                   
##     3.518    0.000
## 
## Variances:
##                    Estimate  Std.Err
##    .x1                0.549    0.114
##    .x2                1.134    0.102
##    .x3                0.844    0.091
##    .x4                0.371    0.048
##    .x5                0.446    0.058
##    .x6                0.356    0.043
##    .x7                0.799    0.081
##    .x8                0.488    0.074
##    .x9                0.566    0.071
##     visual            0.809    0.145
##     textual           0.979    0.112
##     speed             0.384    0.086
##   z-value  P(&gt;|z|)
##     4.833    0.000
##    11.146    0.000
##     9.317    0.000
##     7.779    0.000
##     7.642    0.000
##     8.277    0.000
##     9.823    0.000
##     6.573    0.000
##     8.003    0.000
##     5.564    0.000
##     8.737    0.000
##     4.451    0.000
```

---

class: inverse, bottom

# 结构方程模型
## Structural Equation Model

---

## 结构方程模型

+ Structural equation models (SEMs)
+ LISREL (Linear Structural ReLationships) models
+ Covariance structure models
+ Latent variable models
+ Structural equations with latent variables

---

## “老朋友”

Confirmative factor analysis  
Multiple regression  
Multivariate regression  
ANOVA  
General linear model  
Path analysis  
Recursive models  
Dichotomous and ordered probit  
Seemingly unrelated regressions  
Simultaneous models  
Latent growth curve models  
......

---

.pull-left[
## CFA之上

与CFA相比，SEM：

+ 观察变量： X, .red[Y]


+ 模型建构：
    1. Latent variable model
    1. Measurement model (CFA)
    1. Relations among the errors 
    

+ 依然要求identification
]

--

.pull-right[
## 估计

MLE

## 诊断

+ Overall：&amp;chi;&lt;sup&gt;2&lt;/sup&gt;
+ Incremental：
    + TLI &amp; CLI
    + Incremental Fit Index(IFI, &amp;Delta;&lt;sup&gt;2&lt;/sup&gt;): 1理想，&lt;0.9不可接受
+ Absolute:
    + RMSEA: &lt; 0.06
    + BIC: 越小越好
 ]
 
 
---

实例：Bollen 1989, 政治民主（1960，1965）与工业化

&lt;img src="03_latentVariableI_files/figure-html/diagram-sem-1.png" style="display: block; margin: auto;" /&gt;

--


```
## lavaan 0.6-9 ended normally after 68 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                        31
##                                                       
##   Number of observations                            75
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                                38.125
##   Degrees of freedom                                35
##   P-value (Chi-square)                           0.329
## 
## Model Test Baseline Model:
## 
##   Test statistic                               730.654
##   Degrees of freedom                                55
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    0.995
##   Tucker-Lewis Index (TLI)                       0.993
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)              -1547.791
##   Loglikelihood unrestricted model (H1)      -1528.728
##                                                       
##   Akaike (AIC)                                3157.582
##   Bayesian (BIC)                              3229.424
##   Sample-size adjusted Bayesian (BIC)         3131.720
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.035
##   90 Percent confidence interval - lower         0.000
##   90 Percent confidence interval - upper         0.092
##   P-value RMSEA &lt;= 0.05                          0.611
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.044
## 
## Parameter Estimates:
## 
##   Standard errors                             Standard
##   Information                                 Expected
##   Information saturated (h1) model          Structured
## 
## Latent Variables:
##                    Estimate  Std.Err
##   ind60 =~                          
##     x1                1.000         
##     x2                2.180    0.139
##     x3                1.819    0.152
##   dem60 =~                          
##     y1                1.000         
##     y2                1.257    0.182
##     y3                1.058    0.151
##     y4                1.265    0.145
##   dem65 =~                          
##     y5                1.000         
##     y6                1.186    0.169
##     y7                1.280    0.160
##     y8                1.266    0.158
##   z-value  P(&gt;|z|)
##                   
##                   
##    15.742    0.000
##    11.967    0.000
##                   
##                   
##     6.889    0.000
##     6.987    0.000
##     8.722    0.000
##                   
##                   
##     7.024    0.000
##     8.002    0.000
##     8.007    0.000
## 
## Regressions:
##                    Estimate  Std.Err
##   dem60 ~                           
##     ind60             1.483    0.399
##   dem65 ~                           
##     ind60             0.572    0.221
##     dem60             0.837    0.098
##   z-value  P(&gt;|z|)
##                   
##     3.715    0.000
##                   
##     2.586    0.010
##     8.514    0.000
## 
## Covariances:
##                    Estimate  Std.Err
##  .y1 ~~                             
##    .y5                0.624    0.358
##  .y2 ~~                             
##    .y4                1.313    0.702
##    .y6                2.153    0.734
##  .y3 ~~                             
##    .y7                0.795    0.608
##  .y4 ~~                             
##    .y8                0.348    0.442
##  .y6 ~~                             
##    .y8                1.356    0.568
##   z-value  P(&gt;|z|)
##                   
##     1.741    0.082
##                   
##     1.871    0.061
##     2.934    0.003
##                   
##     1.308    0.191
##                   
##     0.787    0.431
##                   
##     2.386    0.017
## 
## Variances:
##                    Estimate  Std.Err
##    .x1                0.082    0.019
##    .x2                0.120    0.070
##    .x3                0.467    0.090
##    .y1                1.891    0.444
##    .y2                7.373    1.374
##    .y3                5.067    0.952
##    .y4                3.148    0.739
##    .y5                2.351    0.480
##    .y6                4.954    0.914
##    .y7                3.431    0.713
##    .y8                3.254    0.695
##     ind60             0.448    0.087
##    .dem60             3.956    0.921
##    .dem65             0.172    0.215
##   z-value  P(&gt;|z|)
##     4.184    0.000
##     1.718    0.086
##     5.177    0.000
##     4.256    0.000
##     5.366    0.000
##     5.324    0.000
##     4.261    0.000
##     4.895    0.000
##     5.419    0.000
##     4.814    0.000
##     4.685    0.000
##     5.173    0.000
##     4.295    0.000
##     0.803    0.422
```

---

## SEM "骚操作"

1. SEM怎么对待Measurement errors
1. SEM怎么处理非线性变量(hint: GSEM)
1. SEM怎么对待群组效应
1. SEM如何处理缺失值(hint: 可能比MI还要好哦！)

--

.center[.red[单单应用SEM 不能证明因果关系！！]]

---

## 总结一下

* 潜在变量分析概述
    + **因素分析**
    + 类型分析
* 什么是EFA
    + 探索性因子分析：通过loading找到潜在变量
    + EFA诊断：Kaiser‘s criterion, reliability
    + EFA vs. PCA: 结果相似，逻辑不同
* 什么是CFA
    + 验证性因子分析：检验潜在变量对于观察指标是否有影响
    + CFA诊断：&amp;chi;&lt;sup&gt;2&lt;/sup&gt;, TLI/CFI，RMSEA/SRMR
* SEM 入门
    + Latent + measurement models
    + 不能证明因果关系！


---

class: inverse, middle, center

# Thank you!

&lt;i class="fa fa-envelope fa-lg"&gt;&lt;/i&gt;&amp;nbsp; [yuehu@tsinghua.edu.cn](mailto:yuehu@tsinghua.edu.cn) 

&lt;i class="fa fa-globe fa-lg"&gt;&lt;/i&gt;&amp;nbsp; https://sammo3182.github.io/

&lt;i class="fab fa-github fa-lg"&gt;&lt;/i&gt;&amp;nbsp; [sammo3182](https://github.com/sammo3182)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"highlightSpans": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
