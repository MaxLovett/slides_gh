---
title: "潜变量分析（进阶篇）"
subtitle: "政务大数据应用与分析 (80700673)"
author: "胡悦"
institute: "清华大学" 
knitr: 
    opts_chunk: 
      echo: false
format: 
  revealjs:
    css: https://www.drhuyue.site/slides_gh/css/style_basic.css
    theme: ../../../css/goldenBlack.scss
    slide-number: true
    filters: [appExclusion.lua] # not count appendices into page number
    incremental: true
    preview-links: true # open an iframe for a link
    link-external-newwindow: true
    self-contained: false
    chalkboard: false # allwoing chalk board B, notes canvas C
    # callout-icon: false
    show-slide-number: all # `speaker` only print in pdf, `all` shows all the time
    title-slide-attributes:
      data-background-image: https://gitlab.com/sammo3182/backup/raw/85b3c1ad4b459d7a9f901f124b936428eda5fcaf/logo_THPS.png?inline=true
      data-background-size: 250px   
      data-background-position: top 10% right 5%
    default-image-extension: png
revealjs-plugins:
  - spotlight
lightbox: 
  match: auto
  effect: fade
spotlight:
  size: 50
  presentingCursor: default
  toggleSpotlightOnMouseDown: false
  spotlightOnKeyPressAndHold: 73 # keycode for "i"
editor_options: 
  chunk_output_type: console
---

```{r setup}
#| include = FALSE

library(pacman)

p_load(ltm,
       mirt,
       TeachingSampling,
       lme4,
       ggalt,
       DCPO,
       latex2exp,
       knitr,
       kableExtra,
       drhutools,
       here,
       tidyverse)

# Functions preload
set.seed(313)

theme_set(
  theme_minimal(base_size = 18)
)

theme_update(
  plot.title = element_text(size = 18), 
  axis.title = element_text(size = 22), 
  axis.text = element_text(size = 18)
)
```



## 概要

:::{style="text-align:center
"}
**待解之题**

观测变量与潜变量之间关系要[非线性]{.red}
:::

:::: {.columns}

::: {.column .fragment .nonincremental width="50%"}
### 方法

1. 项目反应理论(IRT)
1. 项目反应聚合估计
:::

::: {.column .fragment .nonincremental width="50%"}
### 操作语言

* R^[现存处理IRT的R packages已超过[50](https://www.tandfonline.com/doi/full/10.1080/15366367.2019.1586404?src=recsys)个。]
    + [`mirt`](https://github.com/philchalmers/mirt/wiki)
    + [`DCPO`](https://github.com/fsolt/DCPO)
:::

::::

# 项目反应理论

## 超越因子分析
**因子分析弊端**：

:::{.nonicremental}
1. 假定潜在变量是[连续]{.red}的；
1. 对于指标[不区分]{.red}变量类型；
1. 难以捕捉[群组]{.red}差异
1. EFA无法囊括[指标间]{.red}关系;
1. CFA面临“[简略]{.red}理论vs测量质量”的矛盾
:::

:::{.fragment style="text-align:center"}
&dArr;

![离散回应模型](https://drhuyue.site:10002/sammo3182/figure/lv_irt.webp){fig-align="center" height=200}
:::

:::{.notes}
CFA理论通常简略，只涉及一部分indices，但实际可能很复杂；当囊括更多indices测量质量会高，但不符合理论。
:::


## 类型分析

![基于单一潜在变量划分“三六九等" (Queen's Gambit)](https://drhuyue.site:10002/sammo3182/figure/lv_game.jpg){fig-align="center" height=200}

:::: {.columns}

::: {.column .fragment width="50%"}
![Frederic M. Lord](https://drhuyue.site:10002/sammo3182/figure/lv_lord.png){fig-align="center" height=300}

:::{.notes}
Frederic M. Lord, psychometrician, first worked for the Carnegie Foundation in 1944. By 1950, he began working for the Educational Testing Service (ETS). 
Lord's research shaped the SAT, GRE, GMAT, LSAT and the TOEFL. 
Lord was called the "Father of Modern Testing" by the National Council on Measurement in Education.
:::

:::

::: {.column .fragment width="50%"}
*Item Response Theory *(IRT)

1. 天生为[二元]{.navy}指标设计（衍生适应定序变量和连续变量）；
1. 易与Bayesian inference结合，解决[潜在变量scale]{.navy}不确定问题；
1. 易与跨群组估计结合，实现指标[跨组可比]{.navy}
:::

::::



## Basic IRT

:::: {.columns}

::: {.column width="60%"}
- 调查层次：个体
- Item: "一道题"
- Response: "对一道题（的选项）"
- 指标种类
    1. Yes/No
    2. 可以转化为二元的问题
    3. 定序问题（e.g., Liker scale questions）
:::

::: {.column .fragment .nonincremental width="40%"}
[**Assumptions**]{.red}

1. Monotonicity
1. Unidimensionality
1. Local independence
1. Parameter invariance
:::

::::

## Monotonicity

![Item characteristic curve, 随潜在变量增加，获得1的可能性也随之增加](https://drhuyue.site:10002/sammo3182/figure/irt_icc.png){fig-align="center" height=500}


:::{.notes}
随着能力的提高，回答正确答案的机会也就越高
:::


## Unidimensionality

:::: {.columns}

::: {.column width="50%"}
+ 聚合的项目均指向同一个潜在变量^[直到引入multidimensional IRT]
+ 基于理论
:::

::: {.column .fragment width="50%"}
![](https://drhuyue.site:10002/sammo3182/figure/lv_angry.jpg){fig-align="center" height=500}
:::

::::

## Parameter Invarance

![](https://drhuyue.site:10002/sammo3182/figure/lv_gre.jpg){fig-align="center" height=350}

- 项目特点（parameters of items，比如难度、梯度等）在[项目间]{.red}不变
- 项目特点在[响应人群间]{.red}不变^[通过基于Wald and likelihood-ratio approach来检测Differential item functioning (DIF).]
    + 当进行Multiple Group IRT时尤其可能被违反

## Local Independency

:::{.nonincremental}

$$P(Y_{ip}, Y_{iq}|\theta_i) = P(Y_{ip}|\theta_i)P(Y_{iq}|\theta_i),$$

:::{style="text-align:center"}
- p, q: Items
- i: Respondent
- Y<sub>ip</sub>: i对于项目p的的反应
- &theta;<sub>i</sub>: 反应者i的潜在变量
:::

:::{.fragment}
对于不同项目的反应之间，关联性[只]{.red}来自共同的潜在变量。
:::


:::

:::{.notes}
换言之，控制潜在变量影响后，问题间响应相互独立
:::




## IRT模型发展

:::: {.columns}

::: {.column width="30%"}
Rasch Model (1PL)  

:::{.notes}
Rasch /resh/
:::
:::

::: {.column .fragment width="70%"}
&rarr; Two-Parameter Logistic Model (2PL)     
&rarr; Three-Parameter Logistic Model (3PL)     
&rarr; Four-Parameter Logistic Model (4PL)
:::

::::

:::{.fragment style="text-align:center; margin-top: 2em"}
&darr;

Multidimensional IRT        
Ordinal IRT       
Group IRT       
:::


## Rasch Model

+ y<sub>iq</sub>&isin;{0,1}: 反应，`i`对问题`q`的回答
+ &theta;<sub>i</sub>&isin;{-&infin;, +&infin;}: 反应能力，(Unbounded latent trait)
+ &sigma;<sub>q</sub>: Difficulty，问题难易程度，通常显示为z scores

:::{.fragment .nonincremental}
🌰 不同难度的项目：
    
+ 当面临重大公共卫生威胁时，政府是否应该及时响应，采取果断措施？
+ 政府是否可以牺牲少数民众权利，来换取大多数社会成员的公共卫生安全？
:::

:::{.fragment}
$$
\text{1PL: }\color{red}{P(Y_{iq} = 1)} = \color{blue}{logist^{-1}(\theta_i - \sigma_q)},
$$
:::

:::{.fragment}
$$
\color{red}{项目反应} = \color{blue}{反应理论}.
$$
:::


## 操作案例 (Bock & Lieberman 1970)

:::: {.columns}

::: {.column width="50%"}
![](https://drhuyue.site:10002/sammo3182/figure/lv_lsat.jpg){fig-align="center" height=600}
:::

::: {.column .fragment width="50%"}
Law School Admissions Test    
sec 7, 5个yes/no问题


```{r data-verbal}
df_lsat <- expand.table(LSAT7)
df_lsat
```


:::{.notes}
[`mirt` Workshop 1](http://philchalmers.github.io/mirt/extra/mirt-Workshop-2015_Day-1.pdf)
:::
:::

::::


## Difficulty Parameter

:::: {.columns}

::: {.column width="30%"}

```{r rasch-difficulty}
m_lsat <- mirt(df_lsat, model = 1, itemtype = "Rasch", verbose = FALSE)
coef(m_lsat, simplify = TRUE)$item
```

:::

::: {.column width="70%"}

```{r icc}
#| fig-cap: "Item Characteristic Curves"

plot(m_lsat, type = "trace", facet_items = FALSE)
```


:::{.notes}
检查各题affirmative的难易程度，看逐个是不是大体同一个趋势
:::

:::

::::



## Test Charactersitic Curve


```{r tcc}
plot(m_lsat, type = "infoSE")
```


:::{.notes}
TCC： 所有ICC之和，体现how reliable, information 理想是形成一个钟形,顶尖处代表平均水平，据此对比个人&theta;可以判断这人是否是outlier
SE(&theta;) = (test)<sup>-1/2</sup>
:::


## 1PL &rarr; 2PL {auto-animate=true}

Rasch局限：Measurement error

$$
\begin{align}
\text{Rasch: } P(Y_{iq} = 1) =& logist^{-1}(\theta_i - \sigma_q),\\
\text{2PL: } P(Y_{iq} = 1) =& logist^{-1}(\color{red}{\kappa_q}\theta_i - \sigma_q),
\end{align}
$$


&kappa;<sub>q</sub>: Discrimination (Parameter of dispersion)

另一种常见写法

$$Pr(y_{iq} = 1) = logist^{-1}[\frac{\theta_i - {\color{red}{\beta_q}}}{\color{red}{\alpha_q}}]$$

- &alpha;<sub>q</sub>: Dispersion

:::{.notes}
Dispersion: magnitude of the measurement error 

人们对同一个题理解不同，回答出affirmative答案可能性也不同。

Discrimination: how well a question can differentiate people from below to above;

Rule of thumb above 1 meaning a good question in terms of examination
:::


## Difficulty vs. Dispersion (Statistically) {auto-animate=true}

$$Pr(y_{iq} = 1) = logist^{-1}[\frac{\theta_i - {\color{blue}{\beta_q}}}{\color{red}{\alpha_q}}]$$


```{r irt-illustration}
#| fig-align: center

tibble(
  theta = rep(seq(-3, 3, length.out = 100), 6),
  beta = rep(c(-2, 0, 2, 0, 0, 0), each = 100),
  alpha = rep(c(1, 1, 1, .25, 1, 2), each = 100),
  pr_y = plogis((theta - beta) / alpha),
  line_no = rep(1:6, each = 100),
  plot_facet = rep(
    c("Varying Question Difficulty", "Varying Question Dispersion"),
    each = 300
  )
) %>%
  ggplot(aes(theta, pr_y, group = line_no)) +
  geom_line() +
  facet_wrap(~ plot_facet) +
  xlab(TeX("Individual Unbounded Latent Trait $\\theta'_{i}$")) +
  ylab(TeX("Pr(y_{iq} = 1)")) +
  theme_bw() +
  theme(
    strip.background = element_rect(colour = "white", fill = "white"),
    plot.title.position = "plot"
  ) +
  scale_x_continuous(breaks = seq(-3, 3, 1)) +
  geom_text(
    data = tibble(
      theta = -2.25,
      pr_y = .65,
      line_no = 1,
      plot_facet = "Varying Question Difficulty",
    ),
    label = TeX("$\\beta_1 = -2$", output = "character"),
    parse = TRUE
  ) +
  geom_text(
    data = tibble(
      theta = -.6,
      pr_y = .525,
      line_no = 1,
      plot_facet = "Varying Question Difficulty",
    ),
    label = TeX("$\\beta_2 = 0$", output = "character"),
    parse = TRUE
  ) +
  geom_text(
    data = tibble(
      theta = .9,
      pr_y = .4,
      line_no = 1,
      plot_facet = "Varying Question Difficulty",
    ),
    label = TeX("$\\beta_3 = 2$", output = "character"),
    parse = TRUE
  ) +
  geom_text(
    data = tibble(
      theta = 2.5,
      pr_y = 0.025,
      line_no = 1,
      plot_facet = "Varying Question Difficulty",
    ),
    label = TeX("$\\alpha_q = 1$", output = "character"),
    parse = TRUE
  ) +
  geom_text(
    data = tibble(
      theta = -.03,
      pr_y = .96,
      line_no = 1,
      plot_facet = "Varying Question Dispersion",
    ),
    label = TeX("$\\alpha_1 = .25$", output = "character"),
    parse = TRUE
  ) +
  geom_text(
    data = tibble(
      theta = 1.4,
      pr_y = .9,
      line_no = 1,
      plot_facet = "Varying Question Dispersion",
    ),
    label = TeX("$\\alpha_2 = 1$", output = "character"),
    parse = TRUE
  ) +
  geom_text(
    data = tibble(
      theta = 2.1,
      pr_y = .66,
      line_no = 1,
      plot_facet = "Varying Question Dispersion",
    ),
    label = TeX("$\\alpha_3 = 2$", output = "character"),
    parse = TRUE
  ) +
  geom_text(
    data = tibble(
      theta = 2.5,
      pr_y = 0.025,
      line_no = 1,
      plot_facet = "Varying Question Dispersion",
    ),
    label = TeX("$\\beta_q = 0$", output = "character"),
    parse = TRUE
  )
```


:::{.notes}
- &beta;<sub>q</sub>: &sigma;<sub>q</sub> &frasl; &kappa;<sub>q</sub>, threshold("difficulty", 控制location)
- &alpha;<sub>q</sub>: &kappa;<sub>q</sub><sup>-1</sup>, dispersion (控制斜率)
:::


## Difficulty vs. Dispersion (Substantively)

:::{.r-hstack}
![Difficulty](https://drhuyue.site:10002/sammo3182/figure/lv_triDimensionalChess.jpg){.fragment fig-align="center" height=500}

![Dispersion](https://drhuyue.site:10002/sammo3182/figure/lv_goes.jpg){.fragment fig-align="center" height=500}
:::

## Estimation

:::: {.columns}

::: {.column width="50%"}
**Rasch**


```{r outcome-1pl}
coef(m_lsat, simplify = TRUE)$item
```


:::

::: {.column .fragment width="50%"}
**2PL**


```{r outcome-2pl}
m_lsat2PL <-  mirt(df_lsat, model = 1, itemtype = "2PL", verbose = FALSE)
coef(m_lsat2PL, simplify = TRUE)$item
```

:::

::::

:::{.fragment}

:::{.callout-tip}

## 你真的需要2PL吗?


```{r llr}
anova(m_lsat, m_lsat2PL) %>%  
  select(AIC, SABIC, HQ, logLik, df, p) %>% 
  kable(caption = "Likelihood-Ratio Test")
```


:::

:::


## Further what if

如果发给了初中生高中数学题？&rarr; Three-Parameter Logistic Model (3PL)

:::{.notes}
全凭猜 &rarr; 大量低&theta;人群
:::

:::{.fragment}
$$Pr(y_{iq} = 1) = \color{red}{c_i + (1 - c_i)}logist^{-1}[\frac{(\theta_i - \beta_q)}{\alpha_q}],$$ c<sub>i</sub>：Item [lower]{.red} asymptote ("guessing")
:::


:::{.notes}
极大增加演算成本&rarr;通常需要1000以上观测点
:::

:::{.fragment}
如果有人不care咋办 &rarr; Four-Parameter Logistic Model (4PL)

$$Pr(y_{iq} = 1) = c_i + (\color{red}{d_i} - c_i)logist^{-1}[\frac{(\theta_i - \beta_q)}{\alpha_q}], $$ d<sub>i</sub>：Item [upper]{.red} asymptote ("carelessness"), d < 1
:::


:::{.notes}
鉴于3PL已经需要1000-ish观测点……
:::

## IRT Diagnosis

:::{.large .nonincremental style="text-align:center; margin-top: 2em"}
+ 测试层：Global fit
+ 项目层：Item fit & residual
+ 反应者层：Personal fit
:::



## Global Fit<sup>1</sup>

:::: {.columns}

::: {.column width="40%"}
$G^2 = 2[\sum_l^s r_lln(\frac{r_l}{N\tilde{P}_l})],$^[RMSEA, SRMSR, CFI, TLI对于IRT同样使用.]

N: 参与人数  
l: 可能的反应  
r: 做出特定反应的人数
:::

::: {.column width="60%"}
当数据过于稀疏时(item > 10)，M2, M2* 


```{r diagnostics-overall}
M2(m_lsat)
```


:::{.notes}
REDO: @Maydeu-Olivares2013

N is the number of subjects, L is number of possible response patterns, $P_ l$ is the estimated probability of observing response pattern l, and $r_ l$ is the number of subjects who have response pattern l

&chi; sig   
Tucker-lewis index, 1 ideal, < .95 poor   
Comparative fit index, the same   
Root mean square error of approximation, 0 perfect, <.05 good, [.05, .08] ok, > .1 poor    
Standardized root mean square residual <.08 acceptable
:::

:::

::::


## Item Diagnostics

:::: {.columns}

::: {.column width="50%"}
*Covariation-based residuals*


```{r diagnostics-residual}
residuals(m_lsat)
```


- 多用于检验multidimensionality

:::{.notes}
看item residual的协变程度，unidimnesionality 聚合的项目均指向同一个潜在变量， 不应有关联
:::
:::

::: {.column width="50%"}
*Single item/person fit*


```{r item-fit}
# Item 
itemfit(m_lsat, fit_stats = "infit")
```


:::{.fragment}

```{r person-fit}
# Person
personfit(m_lsat)
```

:::


:::{.notes}
infit/outfit, close to 1 is good

Z<sub>h</sub> > 0 better
:::

:::

::::


## 如果出现问题

1. 通过S-&chi;<sup>2</sup>、local dependency等检查观测和估计数值差别
1. 增加模型复杂程度, 比如2PL &rarr; 3PL
1. 如果最初用binary，尝试polytomous或者nominal response models
1. 尝试non-parametric smoothing techniques


# 发展的项目反应理论

## 发展方向

:::{.fragment .nonincremental}
- 个体层级
    - 一维到多维
    - 二分到多类
    - 单层到多层
:::

:::{.fragment .nonincremental}
- 群体层级
    - 更准确的、可比较的群体差异
:::


## 一维到多维

Multidimentional IRT (MIRT, Phil Chalmers, 2015)

$$Pr(y_{iq} = 1) = logist^{-1}[\frac{\boldsymbol{\theta_i} - \beta_q}{\boldsymbol{\alpha_q}}]$$

**&theta;<sub>i</sub>**和**&alpha;<sub>q</sub>**不再是单一值，而是一个矩阵。


## 二分到多类

:::: {.columns}

::: {.column width="65%"}
Logit &rarr; Cumulative logit

$$P(Y_{iq} = 1) \rightarrow Pr(\frac{Y_{iq}\leq c}{Y_{iq}>c}).$$


```{r twoDimension}
m_lsat2D <- mirt(df_lsat, model = 2, verbose = FALSE)
plot(m_lsat2D, type = "score")
```

:::

::: {.column .fragment width="35%"}
*三种主要类型*

1. (Modified) Graded Response Model
    + 用于scoring rubrics，比如 Likert
1. (Generalized) Partial Credit Model，Rating Scale Model
    + 用于可转化为定序的分类变量
1. Nominal Response Model
    + 用于无序分类变量

:::{.notes}
https://stats.stackexchange.com/questions/402440/how-should-we-select-between-various-item-response-theory-models-e-g-rsm-grm

:::
:::

::::

## 单层到多层

![](https://drhuyue.site:10002/sammo3182/figure/countryBias.png){fig-align="center" height=300}

Multilevel Mixture IRT with Item Bias Effects (Stegmueller 2011)

在估测&alpha;<sub>q</sub>时加入random effect.

:::{.notes}
Daniel Stegmueller, Duke U, poli sci
:::



## 超越个体

Why bother? Individual fallacy

:::{.r-stack}
![](https://drhuyue.site:10002/sammo3182/figure/lv_maleFeminist.jpg){fig-align="center" .fragment height=500}

![](https://drhuyue.site:10002/sammo3182/figure/lv_incomeGap.jpg){.fragment fig-align="center" height=500}
:::


:::{.notes}
Ecological fallacy (Simpson's paradox)

![](https://drhuyue.site:10002/sammo3182/figure/ea_yuleSimpson.gif){fig-align="center" height=600}

再比如，民主、不平等、政治文化……
:::



## 聚合层级上的尝试：Caughey & Warshaw (2015)

**Dynamic Group-level IRT（DGIRT)**


:::: {.columns}

::: {.column .fragment width="50%"}

*聚合（Group-level）*：

$\eta_{ktq} = logit^{-1}(\frac{\color{red}{\bar{\theta}_{kt}}- \beta_q}{\sqrt{\alpha^2_q + \color{red}{(1.7\sigma_{kt})^2}}}),$ 

$\bar{\theta}_k$ 和 &sigma;<sub>kt</sub> 是潜在变量在组k时间t的均值和SD。

:::{.notes}

1. 在群组层面估测IRT；^[个体：$p_{iq} = logist^{-1}[\frac{\theta_i - {\beta_q}}{\alpha_q}].$]
1. 在估测IRT过程中加入群组级别变量；
1. 将时间变量融入IRT估测；
1. 用[MrP](#sec-mrp)给估测进行权重。


1.7: sd of probit is (&pi;/3)<sup>1/2</sup> for logit, while Long 1997 found it is more close to 1.7 in actual estimations.

Mislevy, Robert J. 1983. “Item Response Models for Grouped Data.” Journal of Educational Statistics 8(4): 271–88.

&eta;: eta 
:::

:::

::: {.column .fragment width="50%"}

*囊括时间与空间 (Dynamic)*

$$
\begin{align}
\bar{\theta}_k\sim& N(\xi_t + \boldsymbol{x'_k\gamma}, \sigma^2_{\bar{\theta}}), \\
\xi_t \sim& N(\xi_{t-1}, \sigma^2_{\gamma}), \\
\gamma_{pt} \sim& N(\gamma_{p,t-1}, \delta_t + \boldsymbol{z'_p.\eta_t}, \sigma^2_{\gamma})
\end{align}
$$ 

:::{.notes}
&xi;<sub>t</sub>: xi

x 为群组级变量  

t-1, dynamic linear model  

**z'<sub>p.</sub>&eta;<sub>t</sub>**: geography-level attributes, &eta;是coefficients  

n<sup>*</sup><sub>kqt</sub>基于MrP
:::
:::

::::


:::{.fragment style="text-align:center"}

*效果*：

+ 囊括诸多因素
+ 可以部分平衡样本代表性问题
+ 强大，但[复杂]{.red}

:::

:::{.notes}
Caughey & Warshaw称会跑几个星期
:::


## 简化DGIRT (Claassen 2019)

$$
\begin{align}
\eta_{ktq} = logit^{-1}&(\frac{\bar{\theta}'_{kt}- \beta_q}{\sqrt{\alpha^2_q + (1.7\sigma_{kt})^2}}).\\
\downarrow&\\
\eta_{ktq} = logit^{-1}&(\frac{\bar{\theta}'_{kt}- (\beta_q \color{red}{+ \delta_{kq}})}{\alpha_q}).
\end{align}
$$

:::{.notes}
&delta;<sub>kq</sub>: 问题的difficulty随国家k变化。
:::

1. 只作用于代表性样本和[国家]{.red}级别  
1. 只对二分变量进行分析；
1. 将国家作用从估测&theta;变为估测difficulty  
1. 假定本地项目正态分布（忽略极化等现象😱）

:::{.fragment .large style="text-align:center"}
*过犹不及？*
:::


## 聚合IRT最新尝试：DCPO

:::: {.columns}

::: {.column width="50%"}
![](https://drhuyue.site:10002/sammo3182/figure/fsolt.jpeg){fig-align="center" height=400}
:::

::: {.column width="50%"}
[D]{.red}ynamic [C]{.red}omparative [P]{.red}ublic [O]{.red}pinion

:::{.fragment}
复杂程度：

Claasseen 2019 < DCPO < DGIRT
:::

:::

::::

## 操作

1. 收集survey数据，明确与感兴趣的变量相关的指标问题（手动）
1. 通过`DCPOtools`对数据进行预处理（半自动）
1. 通过`DCPO`进行数据分析（自动）
1. 通过`shinystan`诊断convergence（自动）

:::{.fragment}
:::{.callout-important}
## 千万注意！

如同其他方法一样，聚合IRT也需要对结果与数据拟合程度进行诊断。
DCPO等聚合IRT方法使用贝叶斯统计框架，结果需要对[reccurence, stationarity, aperodicity等](@sec-bayesian)进行检验。
:::
:::



## 效果与长处

:::{.r-stack}
![](https://drhuyue.site:10002/sammo3182/figure/irtCompare.png){fig-align="center" height=600}

![](https://drhuyue.site:10002/sammo3182/figure/irtFitCompare.png){.fragment fig-align="center"}
:::


:::{.notes}
Bounded: 使用logit归为0-1
:::


## 总结

:::: {.columns}

::: {.column width="50%"}
*离散回应模型*

- 解决问题：Modeling非连续性指标
- IRT
  - Rasch，nPL
  - Diagnoses: 总体/item/respondent
  - 发展
    - 多维、多类、多层
- GIRT
  - 解决问题：Individual fallacy
  - DGIRT, Claassen model
  - DCPO
:::

::: {.column width="50%"}
*连续因子模型*

- 解决问题：潜在变量描述与关系检验
- 探索性因子分析(EFA)
    - 潜在因子探索
- 验证性因子分析(CFA)
    - 统计推断
- 结构方程模型(SEM)
    - 潜在变量与外生变量关系
    
:::{.fragment}
:::{.callout-tip}
## 使用建议

- 没有高低之分
- 确有难易之别
- 指标量纲或为线索
:::
:::

:::

::::




# 附录：群组加权平均计算 {#sec-mrp .appendix}

## Individual &rarr; Aggregated

$$Y_{kq} = \frac{\sum Y_{ikq}}{n}.$$

:::{.fragment style="text-align:center"}
不妥之处？

1. 如果群组过小，其平均值的代表意义不大
2. 不同的指标对于潜在变量贡献不一样
:::

:::{.fragment style="text-align:center"}
[&darr;]{.large}

经过群组信息（地理、人口）加权的平均值    

Multilevel Regression and Post-stratification (MrP)
:::

:::{.notes}
Gelman, Andrew, and Thomas C. Little. 1997. “Poststratification Into Many Categories Using Hierarchical Logistic Regression.” Survey Methods 23: 127--135.
:::

## Get the mean right

$$\theta_h = \frac{\sum_{j \in h} N_j \mu_j }{\sum_{j \in h} n_j},$$

:::{style="text-align:center"}
N: 总体（来自普查）  
n: 样本（来自sample）
:::


1. 将总体（population）按群组（strata，如国家、地区）[切分]{.red}；
1. 估测对象为核心变量在[每个群组]{.red}中的平均值/比例， &theta;<sub>h</sub> (h &isin; {1, H});
1. 已知各群组以人口变量j（如老年男性、青年女性等）划分，确定[群组人口]{.red}（N<sub>j</sub>）或占总人口比；
1. 通过[multilevel model]{.red}进行估算各组总体平均值&mu;<sub>j</sub>。



## 一个经济学🌰

数据：某年某市五区域2396家产业公司的财政信息  
目标：估测每个区域的产业平均收入（记为&theta;<sub>1~5</sub>）

:::: {.columns}

::: {.column width="70%"}
公司规模和区域分布


```{r descriptive-level}
data(Lucy)
table(Lucy$Level, Lucy$Zone) %>% 
  kable()
```

:::

::: {.column .fragment width="30%"}
总体平均值（真值）


```{r trueMean}
tb_true <- group_by(Lucy, Zone) %>% 
  summarise(income = mean(Income) )
tb_true %>% 
  kable(digits = 2)
```

:::

::::


:::{.notes}
https://www.r-bloggers.com/gelmans-mrp-in-r-what-is-this-all-about/
:::

## 样本

我们随机选取数据中1000个产业公司作为样本：


```{r rawVsTrue}
SLucy <- sample_n(Lucy, size = 1000)
Np <- table(Lucy$Level, Lucy$Zone)

tb_compare <- group_by(SLucy, Zone) %>% 
  summarise(income = mean(Income)) %>% 
  left_join(tb_true, by = c("Zone")) %>% 
  mutate(incomeTrue = 0,
         rawDiff = income.x - income.y,)

ggplot(tb_compare, aes(x = incomeTrue, xend = rawDiff, y = Zone)) +
  geom_dumbbell(
    size = 4,
    color = gb_cols("light grey"),
    colour_x = gb_cols("gold"),
    colour_xend = gb_cols("black"),
  ) +
  xlab("样本平均值与真值差异") +
  ylab("区域")
```



## 计算

**Step I: Mr**

\begin{align}
收入 = \beta_{0z}& + \beta_{1Z=z}公司规模_{iz} + \epsilon_{iz}, \\
\beta_{0z}& = \gamma_{00} + \gamma_{01}区域_z + u_{0z}.
\end{align}

Output: Post-strata means ($\mu_z$)


```{r mr}
# Step 1: <<MR>> - Multilevel regression
M1 <- lmer(Income ~ Level + (1 | Zone), data = SLucy)
SLucy$Pred <- predict(M1)

# Summary
sum <- group_by(SLucy, Zone, Level) %>% 
  summarise(mean2 = mean(Pred))
Mupred <- matrix(sum$mean2, ncol = 5, nrow = 3)

rownames(Mupred) <- levels(SLucy$Level)
colnames(Mupred) <- levels(SLucy$Zone)

Mupred %>% kable(digits = 2)
```


**Step II: P** $\frac{N_z \times \mu_z}{n_z}$


```{r p}
colSums(Np * Mupred) / count(Lucy, Zone)$n
```



## 矫正效果

:::: {.columns}

::: {.column width="50%"}

```{r mrpVsraw}
tb_compare$mrpDiff <- colSums(Np * Mupred) / count(Lucy, Zone)$n - tb_compare$income.y

tb_compare %>%
  pivot_longer(rawDiff:mrpDiff, names_to = "methods", values_to = "diff") %>%
  ggplot(aes(x = incomeTrue, xend = diff, y = Zone, color = methods)) +
  geom_dumbbell(
    size = 4,
    colour_x = gb_cols("gold")
  ) +
  scale_color_viridis_d(alpha = 0.5, end = 0.7) +
  xlab("样本平均值与真值差异") +
  ylab("区域")
```

:::

::: {.column .fragment width="50%"}
MrP 没有解决的问题

+ 答题难度的地区差异
+ 题目的scale
+ Measurement error

:::

::::


# 附录：贝叶斯结果诊断 {#sec-bayesian}

## 贝叶斯分析参数检验

- 最常见的Bayesian inference方法：Markov Chain Monte Carlo (MCMC)
- 数据拟合“底线”：Convergence
- 当Chain的posterior停留在一个[相对稳定]{.red}的区域内([ergodic]{.red} chain)
    - $\lim_{n\to \infty}p^n(\theta_i, \theta_j) = \pi(\theta_j), \forall \theta_i, \theta_j.$
- 特征：
    + Reccurent
        + Homogeneous/Closed: At step m if the trasition probabilities at this step do not depend on m; for State A, B, p(A, B) = 0
        + Irreducible: If every reached point/point collection can be reached from every other reached point/point collection; p(&theta;<sub>i</sub>, &theta;<sub>j</sub>)&ne; 0, &forall; &theta;<sub>i</sub>, &theta;<sub>j</sub>
    + Stationary: no autocorrelation
    + Aperodic: even with a long time there's no identical cycle of chain values repeating

:::{.notes}
+ Homogeneity: at step m the transition probability at this step do not depend on
+ Ergodicity：遍历性
:::


## Converged时什么样：一个🌰

:::: {.columns}

::: {.column width="35%"}
>下雪啦天晴啦   
下雪别忘穿棉袄    
下雪啦天晴啦    
天晴别忘戴草帽    
带草帽~~~  
---《心中的太阳》

今晴，明80%也晴；  
今雪，明60%也雪。

|      |                     | 明天                |                     |
|------|---------------------|---------------------|---------------------|
|      |                     | &theta;<sub>1</sub> | &theta;<sub>2</sub> |
| 今天 | &theta;<sub>1</sub> | 0.8                 | 0.2                 |
|      | &theta;<sub>2</sub> | 0.6                 | 0.4                 |

:::{.notes}
刘欢：《心中的太阳》, 《雪城》主题曲，1988年，倪萍主演

该曲采用再现三段体结构形式写成，外加一个高亢、悠扬的尾声。A段采用悠扬自由的散板节奏，具有思忖沉寂的意境。“大实话”式的歌词，饱含着对自然、社会、人生的不解、疑惑与诘问。B段开始转为充满活力的快板速度，歌词开始由诘问转变为对人间常态的肯定。A'段的旋律不变，只是节律变得富于急迫感、动力感，在这种动力的驱动下，继续开始诘问。高亢、悠扬的尾声，以反复咏唱的“啊太阳”结束，寓意作者对人间真理的无限向往与坚定追求


example of converged
:::

:::

::: {.column .fragment width="65%"}
起始点: [0.5 0.5]

$S_1 = [0.5\; 0.5]\begin{bmatrix}0.8 & 0.2\\ 0.6 & 0.4 \end{bmatrix}=[0.7\; 0.3];$
$S_2 = [0.7\; 0.3]\begin{bmatrix}0.8 & 0.2\\ 0.6 & 0.4 \end{bmatrix}=[0.74\; 0.26];$
$S_3 = [0.74\; 0.26]\begin{bmatrix}0.8 & 0.2\\ 0.6 & 0.4 \end{bmatrix}=[0.748\; 0.252];$
$S_4 = [0.748\; 0.252]\begin{bmatrix}0.8 & 0.2\\ 0.6 & 0.4 \end{bmatrix}=[0.749\; 0.250].$

:::{.fragment}
再往下算，会发现概率变化越来越小，趋于稳定（congverged）
:::


:::

::::

## 检验Convergence

目前没有统计办法能够证明一个Markov Chain已经converged

1. 在给定时间内，无法保证Markov chain能够[达到]{.red}目标分布;
1. 无法预先确定一条Chain能够[遍历]{.red}目标分布的所有区域;
1. 只能诊断一条Chain是否[未]{.red}converged (诊断工具：Geweke's G, Gelman-Rubin)

:::{.fragment}
增加Convergence可能的方法

1. 足够的Burn-in rounds (诊断工具：Raftery-Lewis)
1. 尽可能排除autocorrelation（诊断工具：Heidelberger-Welch）
:::


## Geweke's G

比较parameters在Chain早期和晚期两个[不重叠]{.red}的窗口内的均值;用语检验recurrence特征

$$G = \frac{\bar{\theta_1}- \bar{\theta_2}}{\sqrt{\frac{s_1}{n_1} + \frac{s_2}{n_2}}}.$$


:::{.notes}
A fancy difference of means

converge 则显示不显著差异，增加burn-in
:::


## Gelman & Rubin 1992

$$\hat{R}= \sqrt{\frac{\hat{var(\theta)}}{W}}$$

1. 跑多条chains（5~10），每条长2n
1. 对每一个感兴趣的parameter计算
    1. Within chain variance(W)
    1. Between chain variance(B)
1. 计算总体variance： var(&theta;) = (1 - 1/n)W + (1/n)B
1. 计算Scale reduction (亦称shrink factor)


:::{.fragment}
:::{.callout-tip}
- R趋近于1表示chains operating on same distribution
    - < 1.1或1.2是可以接受的
::: 
:::
  

## Burn-In

给与足够的burning in以到达目标分布；“炸毛的毛毛虫”（Fuzzy Caterpillar）

![](https://drhuyue.site:10002/sammo3182/figure/fuzzyCaterpillar.png){fig-align="center" height=500}


## 检验Burn-in是否足够：Raftery & Lewis (1991, 1996)

+ 分别评价每一个Chain的每一个变量
    1. 根据Chain间的相关性，并据此提供一个迭代数（iteration number）
    1. 检验autocorrelation inflation
    
+ 输出
    + Burn-in：一位数或两位数为佳
    + Total：建议的burn-in数，未考虑cross-chain，因此真正burnin要乘上chain数
    + Dependence Factor


## Autocorrelation

特征：

1. Chain间高相关性
1. 单一parameter高相关性


:::{.notes}
1. Chain间高相关性：Slow convergence
1. 单一parameter的高相关：Individual nonconvergence
:::

:::{.r-hstack}
![Autocorrelated](https://drhuyue.site:10002/sammo3182/figure/isAutocorrelation.png){.fragment fig-align="center" height=300}

![Not autocorrelated](https://drhuyue.site:10002/sammo3182/figure/noAutocorrelation.png){.fragment fig-align="center" height=300}
:::



## Heidelberger and Welch

用于检验Stationarity

1. 确定一个迭代数N, 以及准确性（&epsilon;）和显著性数准(&alpha;)
1. 运行整个chain
1. 施用Cram&eacute;r-von Mises Test，Null: Chain是stationary
1. 如检验未通过则依次略去10%、20%,乃至50%的迭代，再次检测；
1. 如结果表示部分数据不是stationary，则对该部分数据进行halfwidth检验
1. 如果halfwidth ratio < &epsilon;, 则通过检验


## Thinning

Thinning 并[不会]{.red}提高Chain的运算速度、帮助convergence或增强估测质量

+ 每个Chain记录多少samples
    + Chain将仅记录第k个值，越高丢失的信息越多
    + k通常取值：4，5，10
+ 仅用于降低autocorrelation

:::{.fragment .nonincremental style="text-align:right"}
*何时调Thin*

1. 迭代中autocorrelation太高
1. Chain的convergence太低
1. 并行运算
1. 模型维度过高
:::
