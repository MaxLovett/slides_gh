@article{AshEtAl2023,
  title = {Relatio: {{Text Semantics Capture Political}} and {{Economic Narratives}}},
  shorttitle = {Relatio},
  author = {Ash, Elliott and Gauthier, Germain and Widmer, Philine},
  year = {2023},
  month = apr,
  journal = {Political Analysis},
  pages = {1--18},
  publisher = {{Cambridge University Press}},
  issn = {1047-1987, 1476-4989},
  doi = {10.1017/pan.2023.8},
  urldate = {2023-05-19},
  abstract = {Social scientists have become increasingly interested in how narratives\textemdash the stories in fiction, politics, and life\textemdash shape beliefs, behavior, and government policies. This paper provides an unsupervised method to quantify latent narrative structures in text documents. Our new software package relatio identifies coherent entity groups and maps explicit relations between them in the text. We provide an application to the U.S. Congressional Record to analyze political and economic narratives in recent decades. Our analysis highlights the dynamics, sentiment, polarization, and interconnectedness of narratives in political discourse.},
  langid = {english},
  keywords = {memes,narratives,natural language processing},
  file = {D\:\\Nutstore\\01_Literature\\Ash et al2023_Relatio.pdf;D\:\\Nutstore\\01_Literature\\Ash et al2023_Relatio3.pdf}
}

@article{AshHansen2023,
  title = {{Text Algorithms in Economics}},
  author = {Ash, Elliott and Hansen, Stephen},
  year = {2023},
  journal = {Annual Review of Economics},
  pages = {Forthcoming},
  abstract = {This paper provides an overview of the methods used for algorithmic text analysis in economics, with a focus on three key contributions. First, the paper introduces methods for representing documents as high-dimensional count vectors over vocabulary terms, for representing words as vectors, and for representing word sequences as embedding vectors. Second, the paper defines four core empirical tasks that encompass most text-as-data research in economics, and enumerates the various approaches that have been taken so far for these tasks. Finally, the paper flags limitations in the current literature, with a focus on the challenge of validating algorithmic output.},
  langid = {italian},
  file = {D\:\\Nutstore\\01_Literature\\Ash_Hansen2023_Text Algorithms in Economics.pdf}
}

@inproceedings{BengioEtAl2000,
  title = {{A Neural Probabilistic Language Model}},
  booktitle = {{Advances in Neural Information Processing Systems}},
  author = {Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal},
  year = {2000},
  volume = {13},
  publisher = {{MIT Press}},
  url = {https://proceedings.neurips.cc/paper/2000/hash/728f206c2a01bf572b5940d7d9a8fa4c-Abstract.html},
  urldate = {2023-05-27},
  abstract = {A goal  of statistical language modeling is  to  learn  the joint probability  function of sequences of words.  This is intrinsically difficult because of  the curse of dimensionality:  we propose to fight it with its own weapons.  In the proposed approach one learns simultaneously (1) a distributed rep(cid:173) resentation for each word (i.e.  a similarity between words) along with (2)  the probability function for word sequences, expressed with these repre(cid:173) sentations.  Generalization is  obtained because a sequence of words that  has  never been seen before gets  high probability if it is  made of words  that are similar to words forming an already seen sentence.  We report on  experiments using neural networks for the probability function, showing  on  two  text  corpora that  the  proposed approach  very  significantly  im(cid:173) proves on a state-of-the-art trigram model.},
  langid = {catalan},
  file = {D\:\\Nutstore\\01_Literature\\Bengio et al2000_A Neural Probabilistic Language Model.pdf}
}

@article{BenoitEtAl2016,
  title = {Crowd-Sourced Text Analysis: Reproducible and Agile Production of Political Data},
  shorttitle = {Crowd-Sourced Text Analysis},
  author = {Benoit, Kenneth and Conway, Drew and Lauderdale, Benjamin E. and Laver, Michael and Mikhaylov, Slava},
  year = {2016},
  month = may,
  journal = {American Political Science Review},
  volume = {110},
  number = {2},
  pages = {278--295},
  issn = {0003-0554, 1537-5943},
  doi = {10.1017/S0003055416000058},
  abstract = {Empirical social science often relies on data that are not observed in the field, but are transformed into quantitative variables by expert researchers who analyze and interpret qualitative raw sources. While generally considered the most valid way to produce data, this expert-driven process is inherently difficult to replicate or to assess on grounds of reliability. Using crowd-sourcing to distribute text for reading and interpretation by massive numbers of nonexperts, we generate results comparable to those using experts to read and interpret the same texts, but do so far more quickly and flexibly. Crucially, the data we collect can be reproduced and extended transparently, making crowd-sourced datasets intrinsically reproducible. This focuses researchers' attention on the fundamental scientific objective of specifying reliable and replicable methods for collecting the data needed, rather than on the content of any particular dataset. We also show that our approach works straightforwardly with different types of political text, written in different languages. While findings reported here concern text analysis, they have far-reaching implications for expert-generated data in the social sciences.},
  langid = {english},
  timestamp = {2019-05-30T02:39:34Z},
  file = {D\:\\Nutstore\\01_Literature\\Benoitet al2016_Crowd-Sourced Text Analysis - Reproducible and Agile Production of Political Data.pdf}
}

@article{Coase1960,
  title = {The {{Problem}} of {{Social Cost}}},
  author = {Coase, R. H.},
  year = {1960},
  journal = {The Journal of Law \& Economics},
  volume = {56},
  number = {4},
  eprint = {10.1086/674872},
  eprinttype = {jstor},
  pages = {837--877},
  publisher = {{[The University of Chicago Press, The Booth School of Business, University of Chicago, The University of Chicago Law School]}},
  issn = {0022-2186},
  doi = {10.1086/674872},
  urldate = {2023-05-27},
  langid = {english},
  file = {D\:\\Nutstore\\01_Literature\\Coase2013_The Problem of Social Cost.pdf}
}

@article{DietrichEtAl2019,
  title = {Pitch Perfect: Vocal Pitch and the Emotional Intensity of Congressional Speech},
  author = {Dietrich, Bryce J. and Hayes, Matthew and O'Brien, Diana Z.},
  year = {2019},
  journal = {American Political Science Review},
  pages = {Forthcoming},
  url = {http://www.brycejdietrich.com/files/working_papers/DietrichHayesOBrien.pdf},
  urldate = {2019-05-30},
  abstract = {Though audio archives are available for a number of political institutions, the data they provide receive scant attention from researchers. Yet, audio data offer important insights, including information about speakers' emotional states. Using one of the largest collections of natural audio ever compiled\textemdash 74,158 Congressional floor speeches\textemdash we introduce a novel measure of legislators' emotional intensity: small changes in vocal pitch that are difficult for speakers to control. Applying our measure to MCs' floor speeches about women, we show that female MCs speak with greater emotional intensity when talking about women as compared to both their male colleagues and their speech on other topics. Our two supplementary analyses suggest that increased vocal pitch is consistent with legislators' broader issue commitments, and that emotionally intense speech may affect other lawmakers' behavior. More generally, by demonstrating the utility of audio-as-data approaches, our work highlights a new way of studying political speech.},
  timestamp = {2019-05-30T02:50:44Z},
  file = {D\:\\Nutstore\\01_Literature\\Dietrichet al2019_Pitch Perfect - Vocal Pitch and the Emotional Intensity of Congressional Speech.pdf}
}

@article{EshimaEtAl2023,
  title = {Keyword-{{Assisted Topic Models}}},
  author = {Eshima, Shusei and Imai, Kosuke and Sasaki, Tomoya},
  year = {2023},
  journal = {American Journal of Political Science},
  volume = {n/a},
  number = {n/a},
  issn = {1540-5907},
  doi = {10.1111/ajps.12779},
  urldate = {2023-05-01},
  abstract = {In recent years, fully automated content analysis based on probabilistic topic models has become popular among social scientists because of their scalability. However, researchers find that these models often fail to measure specific concepts of substantive interest by inadvertently creating multiple topics with similar content and combining distinct themes into a single topic. In this article, we empirically demonstrate that providing a small number of keywords can substantially enhance the measurement performance of topic models. An important advantage of the proposed keyword-assisted topic model (keyATM) is that the specification of keywords requires researchers to label topics prior to fitting a model to the data. This contrasts with a widespread practice of post hoc topic interpretation and adjustments that compromises the objectivity of empirical findings. In our application, we find that keyATM provides more interpretable results, has better document classification performance, and is less sensitive to the number of topics.},
  langid = {english},
  file = {D\:\\Nutstore\\01_Literature\\Eshima et al2023_Keyword-Assisted Topic Models.pdf;D\:\\Nutstore\\01_Literature\\Eshima et al2023_Keyword-Assisted Topic Models2.pdf}
}

@book{FriedmanSchwartz2008,
  title = {A {{Monetary History}} of the {{United States}}, 1867-1960},
  author = {Friedman, Milton and Schwartz, Anna Jacobson},
  year = {2008},
  month = sep,
  publisher = {{Princeton University Press}},
  abstract = {Writing in the June 1965 issue of theEconomic Journal, Harry G. Johnson begins with a sentence seemingly calibrated to the scale of the book he set himself to review: "The long-awaited monetary history of the United States by Friedman and Schwartz is in every sense of the term a monumental scholarly achievement--monumental in its sheer bulk, monumental in the definitiveness of its treatment of innumerable issues, large and small . . . monumental, above all, in the theoretical and statistical effort and ingenuity that have been brought to bear on the solution of complex and subtle economic issues." Friedman and Schwartz marshaled massive historical data and sharp analytics to support the claim that monetary policy--steady control of the money supply--matters profoundly in the management of the nation's economy, especially in navigating serious economic fluctuations. In their influential chapter 7, The Great Contraction--which Princeton published in 1965 as a separate paperback--they address the central economic event of the century, the Depression. According to Hugh Rockoff, writing in January 1965: "If Great Depressions could be prevented through timely actions by the monetary authority (or by a monetary rule), as Friedman and Schwartz had contended, then the case for market economies was measurably stronger." Milton Friedman won the Nobel Prize in Economics in 1976 for work related to A Monetary History as well as to his other Princeton University Press book, A Theory of the Consumption Function (1957).},
  googlebooks = {Q7J\_EUM3RfoC},
  isbn = {978-1-4008-2933-0},
  langid = {english},
  keywords = {Business \& Economics / Economic History}
}

@article{Grimmer2010,
  title = {A Bayesian Hierarchical Topic Model for Political Texts: Measuring Expressed Agendas in Senate Press Releases},
  shorttitle = {A Bayesian Hierarchical Topic Model for Political Texts},
  author = {Grimmer, Justin},
  year = {2010},
  journal = {Political Analysis},
  volume = {18},
  number = {1},
  pages = {1--35},
  issn = {1047-1987, 1476-4989},
  doi = {10.1093/pan/mpp034},
  abstract = {Political scientists lack methods to efficiently measure the priorities political actors emphasize in statements. To address this limitation, I introduce a statistical model that attends to the structure of political rhetoric when measuring expressed priorities: statements are naturally organized by author. The expressed agenda model exploits this structure to simultaneously estimate the topics in the texts, as well as the attention political actors allocate to the estimated topics. I apply the method to a collection of over 24,000 press releases from senators from 2007, which I demonstrate is an ideal medium to measure how senators explain their work in Washington to constituents. A set of examples validates the estimated priorities and demonstrates their usefulness for testing theories of how members of Congress communicate with constituents. The statistical model and its extensions will be made available in a forthcoming free software package for the R computing language.},
  langid = {english},
  timestamp = {2019-05-30T02:36:53Z},
  file = {D\:\\Nutstore\\01_Literature\\Grimmer2010_A Bayesian Hierarchical Topic Model for Political Texts - Measuring Expressed.pdf}
}

@article{GrimmerStewart2013,
  ids = {grimmerₜext₂013},
  title = {Text as Data: The Promise and Pitfalls of Automatic Content Analysis Methods for Political Texts},
  author = {Grimmer, Justin and Stewart, Brandon M.},
  year = {2013},
  journal = {Political Analysis},
  volume = {21},
  number = {3},
  pages = {267--297},
  publisher = {{SPM-PMSAPSA}},
  timestamp = {2019-10-29T01:14:50Z},
  file = {D\:\\Nutstore\\01_Literature\\Grimmer_Stewart2013_Text as Data - The Promise and Pitfalls of Automatic Content Analysis Methods2.pdf}
}

@inproceedings{PenningtonEtAl2014,
  title = {{{GloVe}}: {{Global Vectors}} for {{Word Representation}}},
  shorttitle = {{{GloVe}}},
  booktitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
  year = {2014},
  month = oct,
  pages = {1532--1543},
  publisher = {{Association for Computational Linguistics}},
  address = {{Doha, Qatar}},
  doi = {10.3115/v1/D14-1162},
  urldate = {2023-05-27},
  langid = {english},
  file = {D\:\\Nutstore\\01_Literature\\Pennington et al2014_GloVe.pdf}
}

@article{RobertsEtAl2013,
  title = {The Structural Topic Model and Applied Social Science},
  author = {Roberts, Margaret E. and Stewart, Brandon M. and Tingley, Dustin and Airoldi, Edoardo M.},
  year = {2013},
  journal = {Advances in Neural Information Processing Systems Workshop on Topic Models: Computation, Application, and Evaluation},
  volume = {1737},
  pages = {1--4},
  owner = {Sammo},
  timestamp = {2019-10-29T01:14:50Z}
}

@article{RobertsEtAl2014,
  title = {Stm: {{R}} Package for Structural Topic Models},
  author = {Roberts, Margaret E. and Stewart, Brandon M. and Tingley, Dustin},
  year = {2014},
  journal = {R Package},
  volume = {1},
  pages = {12},
  owner = {Sammo},
  timestamp = {2019-10-29T01:14:50Z}
}

@article{RobertsEtAl2014a,
  ids = {robertsₛtructural₂014,robertsₛtructural₂014-1},
  title = {Structural Topic Models for Open-Ended Survey Responses},
  author = {Roberts, Margaret E. and Stewart, Brandon M. and Tingley, Dustin and Lucas, Christopher and {Leder-Luis}, Jetson and Gadarian, Shana Kushner and Albertson, Bethany and Rand, David G.},
  year = {2014},
  journal = {American Journal of Political Science},
  volume = {58},
  number = {4},
  pages = {1064--82},
  publisher = {{Wiley Online Library}},
  owner = {Sammo},
  timestamp = {2019-10-29T01:14:50Z}
}

@article{RobertsEtAl2016a,
  title = {A {{Model}} of {{Text}} for {{Experimentation}} in the {{Social Sciences}}},
  author = {Roberts, Margaret E. and Stewart, Brandon M. and Airoldi, Edoardo M.},
  year = {2016},
  month = jul,
  journal = {Journal of the American Statistical Association},
  volume = {111},
  number = {515},
  pages = {988--1003},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.2016.1141684},
  urldate = {2023-05-17},
  abstract = {Statistical models of text have become increasingly popular in statistics and computer science as a method of exploring large document collections. Social scientists often want to move beyond exploration, to measurement and experimentation, and make inference about social and political processes that drive discourse and content. In this article, we develop a model of text data that supports this type of substantive research. Our approach is to posit a hierarchical mixed membership model for analyzing topical content of documents, in which mixing weights are parameterized by observed covariates. In this model, topical prevalence and topical content are specified as a simple generalized linear model on an arbitrary number of document-level covariates, such as news source and time of release, enabling researchers to introduce elements of the experimental design that informed document collection into the model, within a generally applicable framework. We demonstrate the proposed methodology by analyzing a collection of news reports about China, where we allow the prevalence of topics to evolve over time and vary across newswire services. Our methods quantify the effect of news wire source on both the frequency and nature of topic coverage. Supplementary materials for this article are available online.},
  langid = {english},
  keywords = {Causal inference,Experimentation,High-dimensional inference,Social sciences,Text analysis,Variational approximation},
  file = {D\:\\Nutstore\\01_Literature\\Roberts et al2016_A Model of Text for Experimentation in the Social Sciences2.pdf;D\:\\zotero_system\\storage\\GXGL4AGF\\Roberts et al. - 2016 - A Model of Text for Experimentation in the Social .pdf}
}

@article{RobertsEtAl2020,
  title = {Adjusting for Confounding with Text Matching},
  author = {Roberts, Margaret E and Stewart, Brandon M and Nielsen, Richard A},
  year = {2020},
  journal = {American Journal of Political Science},
  pages = {Forthcoming},
  abstract = {We identify situations in which conditioning on text can address confounding in observational studies. We argue that a matching approach is particularly well-suited to this task, but existing matching methods are ill-equipped to handle high-dimensional text data. Our proposed solution is to estimate a low-dimensional summary of the text covariates and condition on this summary via matching. We propose a method of text matching, Topical Inverse Regression Matching, that allows the analyst to match both on the topical content of confounding documents and the probability that each of these documents is treated. We validate and illustrate the importance of conditioning on text to address confounding with two applications: the effect of perceptions of author gender on citation counts in academia and the effects of censorship on Chinese social media users.},
  langid = {english},
  timestamp = {2020-03-27T06:40:58Z},
  file = {D\:\\zotero_system\\storage\\GK26D6SV\\Robertset alAdjusting for Confounding with Text Matching.pdf}
}

@article{SuEtAl2020,
  title = {A Pattern Recognition Framework for Detecting Changes in Chinese Internet Management System},
  author = {Su, Yu-Sung and Ruan, Yanqin and Sun, Siyu and Chang, Yu-Tzung},
  year = {2020},
  month = sep,
  journal = {Journal of Social Computing},
  volume = {1},
  number = {1},
  pages = {28--39},
  issn = {2688-5255},
  doi = {10.23919/JSC.2020.0004},
  abstract = {Past studies on the Chinese Internet management system have revealed a smart Internet management system that takes advantage of time to filter content with collective action potential. How and why such a system was institutionalized? We offer a historical institutional analysis to explain the way in which the system evolved. We implement social network analysis to examine the Weibo posts of recurrent events, the elections in Area A in 2016 and 2018, to identify pattern changes in the system. There are two aspects of the changes: the centralization of the command line to a single authority and the implementation of a discriminatory strategy to deal with the various online expressions together forming this intelligent system. The improved Chinese information surveillance system demonstrates both a top-down information management and a bottom-up opinion formation.},
  keywords = {bottom-up opinion formation,Chinese information surveillance system,Chinese Internet management system,Cyberspace,devolution paradox,historical institutional analysis,Image color analysis,information management,Information management,intelligent system,Internet,internet censorship,pattern changes,pattern recognition,pattern recognition framework,Regulation,smart Internet management system,social network analysis,social networking (online),Social networking (online),top-down information management},
  timestamp = {2020-12-12T00:31:08Z},
  file = {D\:\\zotero_system\\storage\\4ZDHV3WC\\Suet al2020_A Pattern Recognition Framework for Detecting Changes in Chinese Internet.pdf}
}

@article{ZhangPan2019,
  title = {{{CASM}}: A Deep-Learning Approach for Identifying Collective Action Events with Text and Image Data from Social Media},
  shorttitle = {{{CASM}}},
  author = {Zhang, Han and Pan, Jennifer},
  year = {2019},
  month = aug,
  journal = {Sociological Methodology},
  volume = {49},
  number = {1},
  pages = {1--57},
  issn = {0081-1750},
  doi = {10.1177/0081175019860244},
  abstract = {Protest event analysis is an important method for the study of collective action and social movements and typically draws on traditional media reports as the data source. We introduce collective action from social media (CASM)\textemdash a system that uses convolutional neural networks on image data and recurrent neural networks with long short-term memory on text data in a two-stage classifier to identify social media posts about offline collective action. We implement CASM on Chinese social media data and identify more than 100,000 collective action events from 2010 to 2017 (CASM-China). We evaluate the performance of CASM through cross-validation, out-of-sample validation, and comparisons with other protest data sets. We assess the effect of online censorship and find it does not substantially limit our identification of events. Compared to other protest data sets, CASM-China identifies relatively more rural, land-related protests and relatively few collective action events related to ethnic and religious conflict.},
  langid = {english},
  timestamp = {2019-10-04T02:18:45Z},
  file = {D\:\\zotero_system\\storage\\N7MQGA2J\\Zhang_Pan2019_CASM - A Deep-Learning Approach for Identifying Collective Action Events with.pdf}
}
