---
title: "Survey Classification"
subtitle: "Data Generation Process Workshop"
author:
  - Yue Hu
institute: "Tsinghua University" 

format: 
  revealjs:
    css: style_basic.css
    theme: goldenBlack.scss
    # logo: https://gitlab.com/sammo3182/backup/raw/85b3c1ad4b459d7a9f901f124b936428eda5fcaf/logo_zzxx.png?inline=true
    slide-number: true
    incremental: true
    preview-links: true # open an iframe for a link
    link-external-newwindow: true
    chalkboard: true # allwoing chalk board B, notes canvas C
    
    show-slide-number: speaker # only print in pdf, `all` shows all the time
    width: 1600
    height: 900
    title-slide-attributes:
      data-background-image: https://gitlab.com/sammo3182/backup/raw/8b971bbac2a7a9a2763545bbe9a2d91007081016/logo_uiTSU.png?inline=true
      data-background-size: 500px   
      data-background-position: top 10% right 5%
---

```{r setup}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, htmltools.dir.version = FALSE)

xaringanExtra::use_xaringan_extra(c(
  "freezeframe", # make sure gif started right when switch to it
  "broadcast",
  "tachyons",
  "fit_screen"
))

# Functions preload
set.seed(313)
```


# Goal

## What to Achieve

-   Filter relevant questions from the survey pool
-   Classify the questions into themes
-   Verify assigned themes

# Question Filter

## Survey Selection

-   Download the pool of surveys from the `dcpotools` [website](https://github.com/fsolt/DCPOtools/raw/master/data/surveys_data.csv)

-   Have a look at the downloaded spreadsheet

    -   Select `Freeze Panes` from `Window` ![](images/class_freeze.webp){width="60%"}
    -   Start from the cross-national surveys (`country_var` is empty)

## Survey Achoring

-   Start from Column `archive`
    -   First on `dataverse`, [`gesis`](https://search.gesis.org/), [`icpsr`](https://www.icpsr.umich.edu/), [`roper`](https://ropercenter.cornell.edu), or [`ukds`](https://ukdataservice.ac.uk) labels
    -   If `dataverse`, use the `data_link` to achieve the questionnaire
    -   If others, go to the survey website
        -   Search the `file_id` in the search box
            -   If nothing comes back, try the numeric part only
        -   More clicks may be needed <br>e.g., clicking "Studies" (`icpsr`) or "Studies/Datasets" (`roper`)


## Codebook Downloading

:::{.r-stack}
![gesis](images/class_gesis.png){.fragment width=70%}

![icpsr](images/class_icpsr.png){.fragment width=70%}

![roper](images/class_roper.png){.fragment width=70%}

![ukds](images/class_ukds.png){.fragment width=70%}
:::


## Question Selection

1.  Search keywords relating to your topic
    -   e.g., for gender egalitarianism, you can search for "wom," "husband," "wife," etc.
2.  Look around the questions around the questions you found
3.  Look over the index of questions

## Question Recording

Download the [template](https://github.com/fsolt/DCPOtools/raw/master/data/questions_template.csv) from the `DCPOtools` website.

1.  `survey`: `survey` in the `surveys_data` spreadsheet;
2.  `variable`: The question index, e.g., "q56," "v122";
3.  `question_text`: The complete sentences read to the people taking the survey, or as close to that as you can find;
4.  `response_categories`: The number and the label of each of the options, e.g., "1. Strongly agree, 2. Agree, 3. Neither agree nor disagree, 4. Disagree, 5. Strongly disagree".

If, you're sure there are *no* relevant questions in the survey, enter the `survey` and put "NA" under `variable`, and move on.

::: footer
You may want to go over one `archive` at a time.

If there's anything you think is **important** but unable to structuralized, put them to the `note` column.
:::

# Question Clustering

## Classification

Three people per group, one group per topic.

::: r-stack
-   Immigration
-   Inequality
-   LGPTQIA+
:::

1. **Read** the questions through (at least 1/3 each of an archieve)
1. **Categorize** them into three topics
    - Using a term to represent each topic
    - Mark the topic for each question
1. Talk with your partners to justify/modify your categorization system to be a **consistent** one
1. **Mark** all the questions
1. **Measure** the intercoder reliability (ICR) with Fleiss' &kappa; to determine if you need to categorize it again

:::{.notes}
If two coders, use cohen's &kappa;
:::

## Tips

Make sure recording the full sentence of the questions

. . .

According to Landis & Koch (1977), let's aim [0.8]{.red}.

::: {.notes}
Landis, J. Richard, and Gary G. Koch. 1977. “The Measurement of Observer Agreement for Categorical Data.” Biometrics 33(1): 159–74.ss
:::

. . .

A high &kappa; is not the ultimate goal, a.k.a., [no! fake! consistency!]{.red}

. . . 

Twice communications with your partners:

1. After you are famililar with the data and communicate to nail down the categorization system
1. After calculating the ICR and try to figure out the problem if the &kappa; is low.

. . .

Make sure you record the data in the same way. 

## Outcome Example

::: {.r-fit-text style="margin-top: 2em"}
[Public Gender Egalitarianism Dataset](https://dcpo.org/data/pge/)
:::

# Be Prepared and Good Luck

<video width="1000" height="800" controls>
    <source src="https://link.jscdn.cn/1drv/aHR0cHM6Ly8xZHJ2Lm1zL3UvcyFBcnR0dk83MHdLSU8xSFV0Wl8wT25GTk1nTnE0P2U9eW9YMGRR.mp4" type="video/mp4">
</video>

