<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Hypothesis Testing</title>
    <meta charset="utf-8" />
    <meta name="author" content="Yue Hu" />
    <link rel="stylesheet" href="..\..\..\css\zh-CN_custom.css" type="text/css" />
    <link rel="stylesheet" href="..\..\..\css\styles.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Hypothesis Testing
## Analysis of Political Data (70700173)
### Yue Hu
### Political Science, Tsinghua University

---




---

class: inverse, bottom

# Hypothesizing

---

class: small

## Terminology

### Random variable

A variable that can take some array of values, with the probability that it takes any particular value defined according to some random/stochastic process.

### Probability

The chance of occurrence of `\(X_i\)` given the PDF of X

### Likelihood

How probable a given set of observations is for certain values of the parameters of a distribution.

---

## Probability vs. Likelihood

About probability: the integral, the area, the results

![](05_hypothesis_files/figure-html/probability-1.png)&lt;!-- --&gt;

---

About likelihood: the parameter, the product, the hypothesis

![](05_hypothesis_files/figure-html/likelihood-1.png)&lt;!-- --&gt;

---

Formally, let `\(O\)` be the set of observed outcomes and `\(\theta\)` be the set of parameters that describe the stochastic process. 

Probability function: `\(P(O|\theta)\)`

Likelihood function: `\(\mathcal{L}(\theta|O)\)`; 
`\(\mathcal{L} = \prod_{i=1}^n y_i\)`

Hint: `\(\mathcal{L}\)` can above 1.

???

https://acarril.github.io/posts/probability-likelihood
https://www.youtube.com/watch?v=pYxNSUDSFH4
https://khakieconomics.github.io/2018/07/14/What-is-a-likelihood-anyway.html

---

## Maximum Likelihood Estimation:

* Goal: Model (parameter) selection
    + What's the most appropriate estimation?
        + Maximizing the probability that `\(\mathcal{L}(\theta \vert O) = P(O \vert \theta)\)`
    + Point estimation: unbiasdness
    + Interval estimation: range of plausible values
    + Goodness of fit: explained variances
    + Diagnostic estimation: what if the assumptions are violated
    
---

background-image: url("images/mle_illustration.png")
background-position: center
background-size: contain

---

## Hypothesis test:

+ Null model: `\(Likelihood(null): Y = \beta_0 + \epsilon\)`
+ Theoretical model: `\(Likelihood(theory): Y = \beta_0 + \beta_1X + \epsilon\)`
+ Comparing `\(\mathcal{L}(null)\)` and `\(\mathcal{L}(theory)\)`

---

class:small

E.g., Given binomial distribution `\(L(\pi) = {n \choose s}\pi^s(1 - \pi)^{n - s}\)`, what `\(\pi\)` reaches the maximum likelihood?

`\(log[L(\pi)] = log{n\choose s} + s\cdot log(\pi) + (n - s)\cdot log(1 - \pi).\)`

To get the peak value, we use the derivative:

`$$\frac{dlog[L(\pi)]}{d\pi} = \frac{s}{\pi} - \frac{n - s}{1 - \pi}.$$`

To minimize this, let it equal 0, then `\(\pi = \frac{s}{n}\)`

---

## Model Comparison

The famous(notorious)

`$$R^2 = \frac{\sum(\hat{Y} - \bar Y)^2}{\sum(Y - \bar Y)^2}$$`

--

We'll come back to it in a few weeks. Spoil alert: 

---

background-image: url("images/bad4ya.jpg")
background-position: center
background-size: contain

---

## Better Option

Given k is the number of parameter estimates,

+ Akaike information criterion: `\(-log(L) + k\)`, therefore finding the .red[minimum].
+ Bayesian information criterion: `\(-log(L) + k\times \frac{log(n)}{2}\)`, n is number of observations

---

class: inverse, bottom

# Sampling

---

## Sample Distribution

* Population: Total collection of individuals
* Random sample: every individual has an equal chance of being selected

---

## Random Sample

+ Sample size: n
+ Value: `\(x_1, x_2,\dots, x_n\)` of random variable `\(X_1, X_2, \dots, X_n\)`.
+ IID: identically and independently distributed
    + Identical: X and Y are from the same distribution, `\({\displaystyle F_{X}(x)=F_{Y}(x)\,\forall x\in I}\)`.
    + Independent: `\({\displaystyle F_{X,Y}(x,y)=F_{X}(x)\cdot F_{Y}(y)\,\forall x,y\in I}\)`

---

## Reliable sample:

+ `\(\bar X \rightarrow \mu; p\rightarrow \pi.\)`

Unbiased Mean: 

`\begin{align}
\bar X =&amp; \frac{\sum X}{n}\\
E(\bar X) =&amp; \frac{1}{n}[E(X_1) + E(X_2) + \dots + E(X_n)]\\
  =&amp; \frac{1}{n}[\mu + \mu + \dots + \mu] = \mu
\end{align}`

---

class: small

Unbiased variance (standard error): 

`\begin{align}
s(\bar X)^2 =&amp; \frac{[E(s(X_1)^2) + E(s(X_2)^2) + \dots + E(s(X_n)^2)]}{n^2}\\
  =&amp; \frac{1}{n}[\sigma^2 + \sigma^2 + \dots + \sigma^2] = \frac{\sigma^2}{n}\\
\therefore\ SE =&amp; \frac{\sigma}{\sqrt{n}}.
\end{align}`


+ When n gets larger, `\(\bar X\)` is more concentrated around `\(\mu\)`.
+ Central limit theorem: For a random sample of n, `\(\bar X\)` fluctuate around `\(\mu\)` with a SE

---

E.g. Given the population mean as 69 and standard deviation as 3.2, how would the mean of a random sample of four observations fluctuate? 

`\begin{align}
E(\bar X) =&amp; \mu = 69\\
\therefore SE(\bar X) =&amp; \frac{3.2}{\sqrt 4} = 1.6.
\end{align}`

---

E.g. Given `\(\mu\)` = 72 and `\(\sigma\)` = 9, and a random sample of 10. Calculate the probabilities: (1) P(X &gt; 80); (2) `\(P(\bar X &gt; 80)\)`

1. `\(Z = \frac{80 - 72}{9} = .89\Rightarrow P(Z &gt; .89) =\)` 0.1867329;
2. `\(Z = \frac{80 - 72}{9/\sqrt{10}} = 2.81\Rightarrow P(Z &gt; 2.81) =\)` 0.0024771

---

## Comparison with the mean

`\(Z = \frac{\bar X - \mu}{SE}= \frac{\bar X - \mu}{\sigma/\sqrt n}\)`

Hint: A rule of thumb, N &gt; 30, large sample; for time series, N &gt; 80

---

## Proportion (average)

| `\(x\)` 	| `\(f(x)\)`   	| `\(xf(x)\)`   	| `\(x^2f(x)\)` 	|
|---	|--------	|---------	|--------	|
| 0 	| 1 - `\(\pi\)` 	| 0       	| 0      	|
| 1 	| `\(\pi\)`     	| `\(\pi = \mu\)` 	| `\(\pi\)`     	|

`\(\sigma^2 = E(X^2) - \mu^2 = \pi - \pi^2 = \pi(1 - \pi)\)`
Therefore, `\(\sigma = \sqrt{\pi(1 - \pi)}.\)`

---

Normal Approximation rule for proportion: In a sample of N, the sample proportion P fluctuates around the population proportion `\(\pi\)` with SE ( `\(\sqrt{\frac{\pi(1 - \pi)}{n}}\)` ).

The confidence interval: `\(\pi = P \pm Z\sqrt{\frac{P(1 - P)}{n}}, Z = \frac{P - \mu}{\sqrt{\frac{\pi(1 - \pi)}{n}}}.\)`

---

E.g., Given the Republican are 60% of the population, while the Democrats are 40. What's the probability that the Republican are the minority in a random sample of 100 people from the population?

Minority means `\(P(\pi &lt; 0.5)\)`. Then, `\(Z = \frac{5 - 6}{\sqrt{\frac{6(1 - 6)}{100}}} = -2\)`, therefore, `\(P(Z &lt; -2) =\)` 0.0227501

---

## Small population sampling

Without replacement, SE of `\(\bar X\)` is reduced by `\(\sqrt{\frac{N - n}{N - 1}}\)` (finite population correction, FPC). 

Leading to more uncertainty

---

E.g., If only sampling one people, n = 1. Then `\(SE = \frac{\sigma}{\sqrt{n}}\sqrt{\frac{N - n}{N - 1}} = \frac{\sigma}{\sqrt{n}}\)`, no changes; if sampling the entire population, then n = N, SE = 0. For a large sample of a large population (n = 1000, N = 100,000,000), the reductive factor is `\(\sqrt{\frac{100000000 - 1000}{100000000 - 1}}\approx .999\)`, little changes.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="../../../libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
