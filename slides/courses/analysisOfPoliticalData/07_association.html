<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Association Analysis</title>
    <meta charset="utf-8" />
    <meta name="author" content="Yue Hu" />
    <script src="07_association_files/header-attrs-2.11/header-attrs.js"></script>
    <link href="07_association_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="07_association_files/tile-view-0.2.4/tile-view.css" rel="stylesheet" />
    <script src="07_association_files/tile-view-0.2.4/tile-view.js"></script>
    <link href="07_association_files/tachyons-4.12.0/tachyons.min.css" rel="stylesheet" />
    <script src="07_association_files/xaringanExtra_fit-screen-0.2.4/fit-screen.js"></script>
    <link href="07_association_files/panelset-0.2.4/panelset.css" rel="stylesheet" />
    <script src="07_association_files/panelset-0.2.4/panelset.js"></script>
    <script src="07_association_files/js-cookie-3.0.0/js.cookie.js"></script>
    <script src="07_association_files/peerjs-1.3.1/peerjs.min.js"></script>
    <script src="07_association_files/tiny.toast-1.0.0/toast.min.js"></script>
    <link href="07_association_files/xaringanExtra-broadcast-0.2.4/broadcast.css" rel="stylesheet" />
    <script src="07_association_files/xaringanExtra-broadcast-0.2.4/broadcast.js"></script>
    <link href="07_association_files/xaringanExtra-extra-styles-0.2.4/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <link rel="stylesheet" href="zh-CN_custom.css" type="text/css" />
    <link rel="stylesheet" href="style_ui.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Association Analysis
## Large N &amp; Leeuwenhoek (70700173)
### Yue Hu

---





## Overview

.pull-left[

### Relations of Variable

+ Covariance
+ Correlation
+ Non-linear comparison

]

.pull-right[

### Nonparametric Tests

+ Sign &amp; ranking tests

### Treatments vs. Control

+ ANOVA
+ Nonparametric version

]

--

.center[Please pay attention to the .red[ASSUMPTIONS]!!!]

---

class: inverse, bottom

# Relations of Variables

---

## Associations: Relations among Two Variables

1. Covariance (dynamic)
1. Correlations (static)
    + Pearson's r
    + Kendall's &amp;tau;
    + Spearman's &amp;rho;


???

covariance measures how one change then the other

correlation measures if see the other high when one high

Covariance is the base of correlation

---

## Covariance

Remember Variance?

.center[&amp;sigma;&lt;sup&gt;2&lt;/sup&gt;&lt;sub&gt;X&lt;/sub&gt; = &amp;sum;(X - &amp;mu;&lt;sub&gt;X&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt;p(x) = &amp;sum;(X - &amp;mu;&lt;sub&gt;X&lt;/sub&gt;).red[(X - &amp;mu;&lt;sub&gt;X&lt;/sub&gt;)]p(x)].

--

Then covariance is:

.center[&amp;sigma;&lt;sub&gt;X, Y&lt;/sub&gt; = &amp;sum;(X - &amp;mu;&lt;sub&gt;X&lt;/sub&gt;).red[(Y - &amp;mu;&lt;sub&gt;Y&lt;/sub&gt;)]p(x, y)].

--

In other words, covariance is literally .red[co]-variance.


---

## Correlation (Pearson's r)

For a population

`$$\rho_{X,Y} = \frac{\sum(X - \mu_X)(Y - \mu_Y)p(x,y)}{\sqrt{\sum(X - \mu_X)^2p(X)}\sqrt{\sum(Y - \mu_Y)^2p(Y)}} = \frac{\sigma_{X, Y}}{\sigma_X\sigma_Y}.$$`

--

For a sample

`$$r_{XY}=\frac{\sum_{i=1}^n (x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^n(x_i-\bar{x})^2}\sqrt{\sum_{i=1}^n(y_i-\bar{y})^2}}.$$`

--

Multiple regressions: `\(partial\ r = \frac{b/SE}{\sqrt{(b/SE)^2 + (n - k -1)}}\)`, a.k.a., partial correlation.

---

class: middle

.center[
## .red[ASSUMPTION]

1\. Continuous data   
2\. Linear Relationship
]

--

## Properties 

1. &amp;rho;&amp;in; [-1, 1], 0 independent.
1. Greater value indicates stronger .red[linear] relationship.
1. Parametric test&lt;sup&gt;*&lt;/sup&gt;
1. .red[Not robust] to skewed data and outliers.

.footnote[\* Which means assuming normal distribution, linearity, and homoscedasticity.]

---

class: bottom, inverse

## When the Assumption Does Not Hold

# Non-Parametric Tests

---

.center[
## .red[ASSUMPTION]

~~1\. Continuous data~~ Ordinal/norminal data;   
~~2\. Linear Relationship~~ Monotonic relationship

Alternative: &amp;tau; &amp; &amp;rho;
]

--

## Terminology: Census of Ranking Pairs

For any pair of observations x&lt;sub&gt;i&lt;/sub&gt;, y&lt;sub&gt;i&lt;/sub&gt; and x&lt;sub&gt;j&lt;/sub&gt;, y&lt;sub&gt;j&lt;/sub&gt;, i &lt; j,

+ Concordant pairs: x&lt;sub&gt;i&lt;/sub&gt; &gt; x&lt;sub&gt;j&lt;/sub&gt; &amp; y&lt;sub&gt;i&lt;/sub&gt; &gt; y&lt;sub&gt;j&lt;/sub&gt; | x&lt;sub&gt;i&lt;/sub&gt; &lt; x&lt;sub&gt;j&lt;/sub&gt; &amp; y&lt;sub&gt;i&lt;/sub&gt; &lt; y&lt;sub&gt;j&lt;/sub&gt;;

+ Discordant pairs: x&lt;sub&gt;i&lt;/sub&gt; &gt; x&lt;sub&gt;j&lt;/sub&gt; &amp; y&lt;sub&gt;i&lt;/sub&gt; &lt; y&lt;sub&gt;j&lt;/sub&gt; | x&lt;sub&gt;i&lt;/sub&gt; &lt; x&lt;sub&gt;j&lt;/sub&gt; &amp; y&lt;sub&gt;i&lt;/sub&gt; &gt; y&lt;sub&gt;j&lt;/sub&gt;;

+ Tied pairs: x&lt;sub&gt;i&lt;/sub&gt; = x&lt;sub&gt;j&lt;/sub&gt; &amp; y&lt;sub&gt;i&lt;/sub&gt; = y&lt;sub&gt;j&lt;/sub&gt;;

???

tie on x or tie on y are also not concordant or discordant

---

## Kendall's &amp;tau;

.left-column[
### &amp;tau;&lt;sub&gt;A&lt;/sub&gt;
]

.right-column[
.pull-left[
`$$\tau_{A}=\frac{n_c-n_d}{n_c+n_d}=\frac{n_c-n_d}{\binom{n}{2}},$$`

* n&lt;sub&gt;c&lt;/sub&gt;: concordant pair.
* n&lt;sub&gt;d&lt;/sub&gt;: discordant pair.
]

.pull-right[


*Properties*ï¼š

1. &amp;tau;&lt;sub&gt;XY&lt;/sub&gt;, independent 0.
1. "Non-parametric"&lt;sup&gt;*&lt;/sup&gt;

]
]

.footnote[
\* In fact, still based on population parameters, so one can do significant test by `\(z={3(n_{c}-n_{d}) \over {\sqrt {n(n-1)(2n+5)/2}}}\)`.
]

--

.right-column[

.center[Problems?]

1. How to account ties?
1. What if the numbers of values in two variables are not identical?

]

???

https://statistics.laerd.com/spss-tutorials/kendalls-tau-b-using-spss-statistics.php
https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient

---

## Kendall's &amp;tau;

.left-column[
### &amp;tau;&lt;sub&gt;A&lt;/sub&gt;
### &amp;tau;&lt;sub&gt;B&lt;/sub&gt;
]

.right-column[

`$$\tau_{B}={\frac {n_{c}-n_{d}}{\sqrt {(n_{0}-n_{1})(n_{0}-n_{2})}}}$$`
where

.small[
`\begin{aligned}
n_{0}&amp;=n(n-1)/2\\n_{1}&amp;=\sum _{i}t_{i}(t_{i}-1)/2\\
n_{2}&amp;=\sum _{j}u_{j}(u_{j}-1)/2\\n_{c}&amp;={\text{Number of concordant pairs}}\\
n_{d}&amp;={\text{Number of discordant pairs}}\\
t_{i}&amp;={\text{Number of tied values in the }}i^{\text{th}}{\text{ group of ties for the first quantity}}\\u_{j}&amp;={\text{Number of tied values in the }}j^{\text{th}}{\text{ group of ties for the second quantity}}
\end{aligned}`
]

]

???

When the scale of the two variables are different, for example, X can take integer values from 1 to 10 while Y can take integer values from 1 to 20. 

---

## Kendall's &amp;tau;

.left-column[
### &amp;tau;&lt;sub&gt;A&lt;/sub&gt;
### &amp;tau;&lt;sub&gt;B&lt;/sub&gt;
### &amp;tau;&lt;sub&gt;C&lt;/sub&gt;
]

.right-column[

`$$\tau _{C}={\frac {2(n_{c}-n_{d})}{n^{2}{\frac {(m-1)}{m}}}}$$`
where

`\begin{aligned}
n_{c}&amp;={\text{Number of concordant pairs}},\\
n_{d}&amp;={\text{Number of discordant pairs}},\\
m&amp;=\min(r,c),\\
r&amp;={\text{Number of rows}},\\
c&amp;={\text{Number of columns}}.
\end{aligned}`
]

---

## Alternative: Spearman &amp;rho;

* "Non-parametric" version of Pearson R
* Ranking correlation 

`$$\rho _{\operatorname {rg} _{X},\operatorname {rg} _{Y}}={\frac {\operatorname {cov} (\operatorname {rg} _{X},\operatorname {rg} _{Y})}{\sigma _{\operatorname {rg} _{X}}\sigma _{\operatorname {rg} _{Y}}}}.$$`

`\(rg\)`: The rank of the variable

--

When all n ranks are distinct integers (no tie):

`$$\rho_{s}={1-{\frac {6\sum d_{i}^{2}}{n(n^{2}-1)}}},$$` where `\(d_{i}=\operatorname {rg} (X_{i})-\operatorname {rg} (Y_{i}).\)`

???

https://statistics.laerd.com/statistical-guides/spearmans-rank-order-correlation-statistical-guide.php

---

class: center, middle

## r vs. &amp;rho; vs. &amp;tau;

r vs. &amp;tau; &amp; &amp;rho;:

+ r: Linear relationship;
+ &amp;tau; &amp; &amp;rho;: Monotonic relationship.

--

&amp;rho; &amp; &amp;tau;:

+ Non-parametric;
+ Useful when continuity is *violated*;
+ Working for ordinal. 

--

&amp;rho; vs. &amp;tau;: 

+ &amp;tau; is more robust than &amp;rho;;
+ &amp;rho; has less cost than &amp;tau;.

---

## Nominal Variables

`\begin{align}
\chi^2 =&amp; \sum_i\sum_j \frac{(Observed - Expected)^2}{Expected}\\
       =&amp; \sum_{i,j}\frac{(n_{i,j}-\frac{n_{i\cdot}n_{\cdot j}}{n})^{2}}{\frac{n_{i\cdot}n_{\cdot j}}{n}}
\end{align}`

???

nonparametric,

(What's n&lt;sub&gt;i&amp;bullet;&lt;/sub&gt;?)

--

E.g., The partisan distribution of American fathers and sons. How do we know if father's partisanship affect their sons? 


| Father/Son 	| D  	| R  	| I  	| Total 	|
|------------	|----	|----	|----	|-------	|
| D          	| 45 	| 5  	| 10 	| 60    	|
| R          	| 2  	| 23 	| 5  	| 30    	|
| I          	| 3  	| 2  	| 5  	| 10    	|
| Total      	| 50 	| 30 	| 20 	| 100   	|


---

class: small

| Father/Son 	| D  	| R  	| I  	| Total 	|
|------------	|----	|----	|----	|-------	|
| D          	| 45 	| 5  	| 10 	| 60    	|
| R          	| 2  	| 23 	| 5  	| 30    	|
| I          	| 3  	| 2  	| 5  	| 10    	|
| Total      	| 50 	| 30 	| 20 	| 100   	|



Let's set up a hypothesis test: If there's an influence, we may expect

`\(H_0:\)` Sons' party ID has no relation with their fathers' party ID; formally, `\(\pi_{ij} = \pi_i \pi_j\)`, for all i, j.

&amp;alpha; = 0.05.

--

Then, let's calculate the expectations, e.g., E(D&lt;sub&gt;f&lt;/sub&gt;, D&lt;sub&gt;s&lt;/sub&gt;) = 50/100 &amp;times; 60/100 &amp;times; 100 = 30. (What's this?)

`$$\chi^2 = \frac{(45 - 30)^2}{30} + \frac{(5 - 18)^2}{18} + \dots + \frac{(5 - 2)^2}{2}\approx 56.07$$`. 

d.f.: (r - 1)(c - 1) = (3 - 1)(3 - 1) = 4.

--

`\(\chi^2_{critical} = \chi^2_{0.05, 4} =\)` 11.1433&lt; `\(\chi^2_{observed}\)`. H&lt;sub&gt;0&lt;/sub&gt; is rejected.

---

## Limitation of &amp;chi;&lt;sup&gt;2&lt;/sup&gt;

1. When sample is too small and/or having too many missing data, the distribution might be different from `\(\chi^2\)`
2. When N gets large, `\(\chi^2\)` also increase (esp. over 100,000)

--

Solution: &amp;Phi; and Cramer's V

* `\(\Phi = \sqrt{\frac{\chi^2}{n}}\in[0, 1]\)`
    + 2&amp;times;2 table
    + 0 means no association
    + 1 means perfect association
* Cramer's V
    + Beyond a 2*2 table (when `\(\Phi\)` &gt; 1).
    + `\(V = \sqrt{\frac{\chi^2}{n\times min_{r-1, c-1}}}\)`.

---

## Association for Matched Samples: Ranking

| Observation | Test 1        | Test 2        | &amp;Delta;                       |
|-------------|---------------|---------------|-------------------------------|
| 1           | X&lt;sub&gt;1&lt;/sub&gt; | Y&lt;sub&gt;1&lt;/sub&gt; | X&lt;sub&gt;1&lt;/sub&gt; - Y&lt;sub&gt;1&lt;/sub&gt; |
| 2           | X&lt;sub&gt;2&lt;/sub&gt; | Y&lt;sub&gt;2&lt;/sub&gt; | X&lt;sub&gt;2&lt;/sub&gt; - Y&lt;sub&gt;2&lt;/sub&gt; |
| 3           | X&lt;sub&gt;3&lt;/sub&gt; | Y&lt;sub&gt;3&lt;/sub&gt; | X&lt;sub&gt;3&lt;/sub&gt; - Y&lt;sub&gt;3&lt;/sub&gt; |

Goal: whether test 1 and test 2 yield identical results.

--

+ \+: X&lt;sub&gt;i&lt;/sub&gt; &gt; Y&lt;sub&gt;i&lt;/sub&gt;;
+ \-: X&lt;sub&gt;i&lt;/sub&gt; &lt; Y&lt;sub&gt;i&lt;/sub&gt;;
+ =: X&lt;sub&gt;i&lt;/sub&gt; = Y&lt;sub&gt;i&lt;/sub&gt;;

--

*Expectation*: if test 1 and 2 are identically distributed, the probability of &amp;Delta; to be + or - should follow the binomial distribution. That is, *H&lt;sub&gt;0&lt;/sub&gt;: Pr(+) = Pr(-) = 0.5*.

---

## Sign Test

.pull-left[
| Observation | Test 1 | Test 2 | &amp;Delta; | Sign |
|-------------|--------|--------|---------|------|
| 1           | 37     | 40     | âˆ’3      | âˆ’    |
| 2           | 72     | 73     | âˆ’1      | âˆ’    |
| 3           | 57     | 59     | âˆ’2      | âˆ’    |
| 4           | 44     | 43     | 1       | +    |
| 5           | 43     | 51     | âˆ’8      | âˆ’    |
| 6           | 64     | 67     | âˆ’3      | âˆ’    |
| 7           | 55     | 61     | âˆ’6      | âˆ’    |
| 8           | 65     | 74     | âˆ’9      | âˆ’    |
]

.pull-right[
H&lt;sub&gt;0&lt;/sub&gt;: Pr(+) = Pr(-) = 0.5;   
H&lt;sub&gt;1&lt;/sub&gt;: Pr(+) &lt; Pr(-).

&amp;alpha; = 0.05


.small[
`\begin{align}
Pr(n_-\geq 7) =&amp; Pr(n_- = 7) + Pr(n_- = 8)\\
=&amp; {8 \choose 7}(0.5)^7(0.5)^1 + {8 \choose 8}(0.5)^8\\
=&amp; 0.03125 + 0.0039 = 0.03516 &lt; 0.05.
\end{align}`
]
]

---

## Procedure of Sign Test

.pull-left[
1. Calculate the &amp;Delta; (or d); 
1. Giving the sign accordign to d, if d = 0, ignore the observation;
1. Calculate n&lt;sub&gt;-&lt;/sub&gt; and n&lt;sub&gt;+&lt;/sub&gt;, n = n&lt;sub&gt;-&lt;/sub&gt; + n&lt;sub&gt;+&lt;/sub&gt;
1. Set H&lt;sub&gt;0&lt;/sub&gt; and H&lt;sub&gt;1&lt;/sub&gt;, and &amp;alpha;
1. Calculate Pr(+/-)
    + `\(Pr(+) = \sum^{n_-}_{i = 0}Pr(n_+ + i)\)`;
    + `\(Pr(-) = \sum^{n_+}_{j = 0}Pr(n_- + j)\)`;
1. Compare the Pr(+/-) with &amp;alpha;.
]

--

.pull-right[
Hint:

1. Work on matched and nonmatched samples.
1. It is essentially a binomial test (again, "non-parametric" test).


```r
binom.test(7,8, p = .5, alternative = "greater", conf.level = 0.95)
```

```
## 
## 	Exact binomial test
## 
## data:  7 and 8
## number of successes = 7, number
## of trials = 8, p-value = 0.03516
## alternative hypothesis: true probability of success is greater than 0.5
## 95 percent confidence interval:
##  0.5293206 1.0000000
## sample estimates:
## probability of success 
##                  0.875
```

]


???

Although claiming non-parametirc, many of them calculate the significance according to populational parameters.

---

## Normal Approximation of Sign Test

(Often used when n &gt; 10, why? Well...)

--

.pull-left[
Using normal distribution to estimate sign tests:

&amp;mu; = np = n/2; &amp;sigma;&lt;sup&gt;2&lt;/sup&gt; = np(1 - p) = n/4.

`$$Z = \frac{x' - \mu}{\sigma} = \frac{2x' - n}{\sqrt{n}},$$` where&lt;sup&gt;*&lt;/sup&gt; x'=
`\begin{cases}
x + 0.5, if x &lt; \frac{n}{2}\\
x- 0.5, if x &lt; \frac{n}{2}
\end{cases}`
]

.footnote[\* &amp;pm;0.5 approximate to a continuous variable as an expedient, a.k.a., normal approximation.]

--

.pull-right[
e.g., n = 8, then `\(Pr(n_-\geq 7)\)` ?

`\begin{align}
Z =&amp; \frac{x' - \mu}{\sigma} = \frac{2x' - n}{\sqrt{n}},\\
=&amp; \frac{2(7 - 0.5) - 8}{\sqrt{8}} = 1.77.
\end{align}`

Then, Pr(Z &amp;geq; 1.77) &amp;approx; 0.038 &lt; 0.05.

]

---

## Advanced Version of Sign Test

Problems of sign test? 

&amp;rArr; Wilcoxon signed-rank test

???

Sign test ony identify the sign but not the magnitude, insufficiently using the data.


--

1. Calculate the d and .red[|d|];
1. Sort these quantities, and record their rankings as R&lt;sub&gt;i&lt;/sub&gt; so that 0 &lt; |d&lt;sub&gt;R1&lt;/sub&gt;| &lt; |d&lt;sub&gt;R2&lt;/sub&gt;| &lt;...&lt; |d&lt;sub&gt;Rn&lt;/sub&gt;|.
1. Let sign function sgn(d) = 1 if d &gt; 0, sgn(d) = -1, if d &lt; 0, then calculate the signed-rank sum `\(T = \sum^n_{i=1}sgn(d_i)R_i.\)`
    + `\(T^{+}=\sum _{d_{i}&gt;0}R_{i},\)`
    + `\(T^{-}=\sum _{d_{i}&lt;0}R_{i}.\)`

1. Compare the Pr(T) with &amp;alpha;.

---

.pull-left[
| Observation | Test 1 | Test 2 | &amp;Delta; | Ranking |
|-------------|--------|--------|---------|------|
| 1           | 37     | 40     | âˆ’3      | .red[4]    |
| 2           | 72     | 73     | âˆ’1      | .red[1]    |
| 3           | 57     | 59     | âˆ’2      | 3    |
| 4           | 44     | 43     | 1       | .red[1]    |
| 5           | 43     | 51     | âˆ’8      | 7    |
| 6           | 64     | 67     | âˆ’3      | .red[4]    |
| 7           | 55     | 61     | âˆ’6      | 6    |
| 8           | 65     | 74     | âˆ’9      | 8    |
]

--

.pull-right[



```r
wilcox.test(tb_sr$Test_1, tb_sr$Test_2, paired = TRUE)
```

```
## Warning in
## wilcox.test.default(tb_sr$Test_1,
## tb_sr$Test_2, paired = TRUE): cannot
## compute exact p-value with ties
```

```
## 
## 	Wilcoxon signed rank test with
## 	continuity correction
## 
## data:  tb_sr$Test_1 and tb_sr$Test_2
## V = 1.5, p-value = 0.02471
## alternative hypothesis: true location shift is not equal to 0
```

]

--

+ When tie happens, using Monte Carlo conditional p-value (`coin::wilcox_test`) to conduct outcomes .
+ When n &gt; 25, a normal approximation can be also conducted.

---

## Ranking Test for Nonmatched Samples

Given samples S1 and S2,

.left-column[
### Rank-sum test
]

.right-column[
+ Combining S1 and S2 and rank the pooled observations;
+ Adding the ranking quantities (i.e., Rs in signed-rank test);
+ Comparing the sums.
]

---

## Ranking Test for Nonmatched Samples

Given samples S1 and S2,

.left-column[
### Rank-sum test
### Wald-Wolfowitz Runs Test
]

.right-column[

Meaning: Values of sorted S1 and S2 randomly occure?

Procedure: 

1. Combine S1 and S2
1. Sorting the quantities
1. Giving those from S1 as 0 and those from S2 1 within their ranking order.
1. Testing whether the 0/1 occure stocastically.

When n&lt;sub&gt;1&lt;/sub&gt; &amp;geq; 20, n&lt;sub&gt;2&lt;/sub&gt; &amp;geq; 20, one can use normal approximation

]

???

Runs test means to test whether an item comes from population 1 and population 2 is random or not

---

## Runs

| Trial | 1  | 2  | 3  | 4  | 5  | 6  | 7  | 8  |
|-------|----|----|----|----|----|----|----|----|
| A     | 9  | 22 | 65 | 34 | 17 | 4  | 31 | 28 |
| B     | 58 | 53 | 26 | 11 | 52 | 51 | 8  |    |

--

.center[&amp;dArr;]

| 4 | 8 | 9 | 11 | 17 | 22 | 26 | 28 | 31 | 34 | 51 | 52 | 53 | 58 | 64 |
|---|---|---|----|----|----|----|----|----|----|----|----|----|----|----|
| 0 | 1 | 0 | 1  | 0  | 0  | 1  | 0  | 0  | 0  | 1  | 1  | 1  | 1  | 0  |

&lt;img src = "images/corr_runs.png"&gt;

---

## Example


```r
vec_runs1 &lt;- rep(c(0,1), times = 5)
vec_runs2 &lt;- rep(c(0,1), each = 5)
vec_runs3 &lt;- c(1, 0, 0, 1, 1, 1, 1, 0, 0, 0)

vec_runs1 # nonrandom
```

```
##  [1] 0 1 0 1 0 1 0 1 0 1
```

```r
vec_runs2 # nonrandom
```

```
##  [1] 0 0 0 0 0 1 1 1 1 1
```

```r
vec_runs3 # random
```

```
##  [1] 1 0 0 1 1 1 1 0 0 0
```

---

class: small


```r
library(randtests)

runs.test(vec_runs1)
```

```
## 
## 	Runs Test
## 
## data:  vec_runs1
## statistic = 2.6833, runs = 10,
## n1 = 5, n2 = 5, n = 10, p-value
## = 0.00729
## alternative hypothesis: nonrandomness
```

```r
runs.test(vec_runs2)
```

```
## 
## 	Runs Test
## 
## data:  vec_runs2
## statistic = -2.6833, runs = 2,
## n1 = 5, n2 = 5, n = 10, p-value
## = 0.00729
## alternative hypothesis: nonrandomness
```

```r
runs.test(vec_runs3)
```

```
## 
## 	Runs Test
## 
## data:  vec_runs3
## statistic = -1.3416, runs = 4,
## n1 = 5, n2 = 5, n = 10, p-value
## = 0.1797
## alternative hypothesis: nonrandomness
```


---

class: inverse, bottom

# Treatments vs. Control

---

## ANOVA

.pull-left[
Analysis of variance: A systematic way of variable comparison in the context of .red[experiment].

* Completely random design
* Equivalent to t-test
]

--

.pull-right[
When there are more than one treatment group, ANOVA is more useful to reduce the risk of Type I.

&lt;img src = "images/ci_errorType.png"&gt;
]

---

## .red[ASSUMPTION]

1. Y normally distributed in eqch group (Type I &amp;darr;)
1. Homogeneity of variance (Type I &amp; II &amp;darr;)
1. Independence of cases (Type I &amp;darr;)
1. No large outliers (Type II &amp;darr;)
1. Large sample (Type I &amp; II &amp;darr;)
    
    
---

## One-Way ANOVA

(Completely randomized design)

+ `\(\bar X\)` is the sample mean; `\(\bar{\bar{X}} = \frac{\sum \bar{X_i}}{K}\)`, where K is column number, a.k.a., the grant mean, mean of all the data
+ SST: Variance between the samples;
+ SSE: Variance within the samples.

--

| Source    	| Sum Square                                    	| d.f.  	| Mean Square                      	|
|-----------	|-----------------------------------------------	|-------	|----------------------------------	|
| Treat 	| `\(SST = \sum n_i (\bar X_i - \bar{\bar{X}})^2\)` 	| K - 1 	| MST = SST/(K - 1)                	|
| Error     	| `\(SSE = \sum \sum (X_{ik} - \bar{X_i})^2\)`      	| N - K 	| MSE = SSE/(N - K)                	|
| Total     	| `\(SS = SST + SSE\)`                              	| N - 1 	| `\(F_{\alpha, K-1, N-K} = MST/MSE\)` 	|

`$$F_{\alpha, K-1, N-1} = MST/MSE = \frac{Ratio\ of \ Explained\ Variance}{Ratio\ of\ Unexplained\ Variance}$$`

---

## Example

The following table shows the funding applications of six faculty members of Xavier Institution. Does mutants willingness of application relate to the funding type? 

| NS 	| ME 	| BJ 	|
|-----	|-----	|----	|
| 27  	| 23  	| 48 	|
| 22  	| 36  	| 35 	|
| 33  	| 27  	| 46 	|
| 25  	| 44  	| 36 	|
| 38  	| 39  	| 28 	|
| 29  	| 32  	| 29 	|


---

class: small

.pull-left[

| NS 	| ME 	| BJ 	|
|-----	|-----	|----	|
| 27  	| 23  	| 48 	|
| 22  	| 36  	| 35 	|
| 33  	| 27  	| 46 	|
| 25  	| 44  	| 36 	|
| 38  	| 39  	| 28 	|
| 29  	| 32  	| 29 	|
]
.pull-right[
`\(H_0: \mu_1 = \mu_2 = \mu_3,\)`     
`\(H_1: \mu_1 \neq \mu_2 \neq \mu_3.\)`
&amp;alpha; = 0.05.

`\begin{align}
\bar X_{NS} &amp;= 29;\\
\bar X_{ME} &amp;= 33.5;\\
\bar X_{BJ} &amp;= 37;\\
\bar{\bar{X}} &amp;= (29 + 33.5 + 37)/3 \approx 33.17
\end{align}`
]

--

| Source    	| Sum Square                                    	| d.f.  	| Mean Square                      	|
|-----------	|-----------------------------------------------	|-------	|----------------------------------	|
| Treat 	| `\(SST = \sum n_i (\bar X_i - \bar{\bar{X}})^2\)` 	| K - 1 	| MST = SST/(K - 1)                	|
| Error     	| `\(SSE = \sum \sum (X_{ik} - \bar{X_i})^2\)`      	| N - K 	| MSE = SSE/(N - K)                	|
| Total     	| `\(SS = SST + SSE\)`                              	| N - 1 	| `\(F_{\alpha, K-1, N-K} = MST/MSE\)` 	|


`\(\bar X_{NS} = 29; \bar X_{ME} = 33.5;\bar X_{BJ} = 37;\bar{\bar{X}} = 33.17\)`

Then, `\(SST = \sum 6\times (\bar X - \bar{\bar{X}}) = 193\)`; 
`\(SSE = [(27 - 29)^2 + (22 - 29)^2 + \dots + (29 - 37)^2] = 819.5\)`.

Given K = 3, N = 18, `\(F = \frac{193/(3 - 1)}{819.5/(18 - 3)} \approx 1.77\)`

We know F at the critical value 0.05, `\(F_{0.05, 2, 15}\)` = 4.7650483 &gt; F, so fail to reject `\(H_0\)`

---

class: middle, center

ANOVA is usually used when `\(K \in [2, 3]\)`;    
For larger K, often use [MANOVA](https://www.sciencedirect.com/topics/medicine-and-dentistry/multivariate-analysis-of-variance) (rarely used in Poli Sci)

---

## Two-Way ANOVA

* Two-way: 
    + Randomized block design (i blocks, j groups)
    + Matched sample in t-test

| Source    	| Sum Square                                                             	| d.f.           	| Mean Square                                    	|
|-----------	|------------------------------------------------------------------------	|----------------	|------------------------------------------------	|
| Treat 	| `\(SS_A: b\sum (\bar X_i - \bar{\bar{X}})^2\)`                            	| a - 1          	| MST_A = SS_A/(a - 1)                           	|
| Block     	| `\(SS_B: a\sum (\bar X_j - \bar{\bar{X}})^2\)`                            	| b - 1          	| MST_B = SS_B/(b - 1)                           	|
| Error     	| `\(SS_E: \sum^{ab} (X_{ij} - \bar{X_i} - \bar{X_j} + \bar{\bar{X}})^2\)` 	| (a - 1)(b - 1) 	| `\(MSE = \frac{SSE}{(a - 1)(b - 1)}\)`                     	|
| Total     	| `\(SS: SS_A + SS_B + SS_E\)`                                              	| ab - 1         	| `\(F_{\alpha, a-1, b-1} = \frac{MST_{A or B}}{MSE}\)` 	|

---

class: small

## Example

Students' final scores in three majors were recorded in the following table. Does the scores associate with majors?

| Major 	| Poli Sci 	| Sociology 	| Psychology 	|
|-------	|----------	|-----------	|------------	|
| A+    	| 41       	| 45        	| 51         	|
| A     	| 36       	| 38        	| 45         	|
| B+    	| 27       	| 33        	| 31         	|
| B     	| 32       	| 29        	| 35         	|
| C+    	| 26       	| 21        	| 32         	|
| C     	| 23       	| 25        	| 27         	|

`\(H_0: \mu_{PS} = \mu_{SO} = \mu_{PY},\)`  
`\(H_1: \mu_{PS} \neq \mu_{SO} \neq \mu_{PY}.\)`

&amp;alpha; = 0.05.

--

`\(\bar X_{PS} = 30.8; \bar X_{SO} = 33.5; \bar X_{PY} = 36.83\)`;
`\(\bar A_+ = 45.67; \bar A = 39.67; \bar B_+ = 30.33; \bar B = 32; \bar C_+ = 29.67; \bar C = 25.\)`

`\(\bar{\bar{X}} = 33.72.\)`

---

`\(\bar X_{PS} = 30.8; \bar X_{SO} = 33.5; \bar X_{PY} = 36.83\)`;
`\(\bar A_+ = 45.67; \bar A = 39.67; \bar B_+ = 30.33; \bar B = 32; \bar C_+ = 29.67; \bar C = 25.\)`
`\(\bar{\bar{X}} = 33.72\)`


For factor A (major), `\(SS_A = 6\times [(30.8 - 33.72)^2 + (33.5 - 33.72)^2 + (36.83 - 33.72)^2] = 109.48\)`

`\(MSA = SS_A/(a - 1) = 109.48/(3 - 1)\)`

--

For factor B (GPA), `\(SS_B = 3\times [(45.67 - 33.72)^2 + \dots + (25 - 33.72)^2] = 854.94\)`

`\(MSB = 854.94 / (6 - 1)\)`

--

`\(SST = \sum^a\sum^b(X_{ij} - \bar{\bar{X}})^2 = 1015.61\)`
`\(SSE = SST - SS_A - SS_B = 52.2\)`

Then, `\(F_{(3 - 1), (3 - 1)(6 -1)} = MS_A/MSE = \frac{109.5/(3 -1)}{52.2/(3 - 1)(6 - 1)}\)` is 10.4 &gt; critical F 5.4564, reject `\(H_0\)`.

---

.center[.red[ASSUMPTION]]

1. Y normally distributed in eqch group (Type I &amp;darr;)
1. Homogeneity of variance (Type I &amp; II &amp;darr;)
1. Independence of cases (Type I &amp;darr;)
1. No large outliers (Type II &amp;darr;)
1. Large sample (Type I &amp; II &amp;darr;)

--

When any one of them is not held,

## Nonparametric Version

Analysis of variance.red[-rank]
+ Kruskal-Wallis test;
+ Friedman test.

---

## One-Way Variance-Rank: Kruskal-Wallis Test

An extension of the two-sample Wilcoxon test

Procedure: 

+ Combine k samples and sorting
    + If the value are the same, use the average;
    + Let n&lt;sub&gt;k&lt;/sub&gt; as the size of the k sample, and n = &amp;sum;n&lt;sub&gt;i&lt;/sub&gt;, i &amp;isin; {1, 2, ..., k}.
+ Calculate the rank sum of each sample, R&lt;sub&gt;i&lt;/sub&gt;
+ `\(H = \frac{12}{n(n + 1)}\sum^k_{i = 1}\frac{R^2_i}{n_i} - 3(n + 1) \sim \chi^2(k - 1).\)`

---

## Example

Botanists conducted an experiment of plant growth.
The data records the results obtained under a control and two different treatment conditions (as measured by dried weight of plants).


|group | count|  mean|        sd| median|    IQR|
|:-----|-----:|-----:|---------:|------:|------:|
|ctrl  |    10| 5.032| 0.5830914|  5.155| 0.7425|
|trt1  |    10| 4.661| 0.7936757|  4.550| 0.6625|
|trt2  |    10| 5.526| 0.4425733|  5.435| 0.4675|

--


```r
kruskal.test(weight ~ group, data = PlantGrowth)
```

```
## 
## 	Kruskal-Wallis rank sum test
## 
## data:  weight by group
## Kruskal-Wallis chi-squared =
## 7.9882, df = 2, p-value =
## 0.01842
```

---

## Two-Way Variance-Rank: Friedman Test

An extension of the sign test, and also a special case of Durbin test. 

--

E.g., Person's recovery score after taking four types of drugs. The type 1 is the placebo. 


```
## Rows: 20
## Columns: 3
## $ person &lt;int&gt; 1, 1, 1, 1, 2, 2, 2,~
## $ drug   &lt;dbl&gt; 1, 2, 3, 4, 1, 2, 3,~
## $ score  &lt;dbl&gt; 30, 28, 16, 34, 14, ~
```

--


```r
friedman.test(y = df_drug$score,
              groups = df_drug$drug,
              blocks = df_drug$person)
```

```
## 
## 	Friedman rank sum test
## 
## data:  df_drug$score, df_drug$drug and df_drug$person
## Friedman chi-squared = 13.56, df
## = 3, p-value = 0.00357
```

&amp;rArr; Different type of drugs lead to different type of outcomes.

---

## Wrap Up

.pull-left[

### Relations of Variable

+ Covariance
+ Correlation
    + Pearson's r
    + Kendall's &amp;tau;
    + Spearman's &amp;rho;
+ Non-linear comparison
    + &amp;chi;&lt;sup&gt;2&lt;/sup&gt;
    + &amp;Phi; &amp; Cramer's V

]

.pull-right[

### Nonparametric Tests

+ Sign test, Signed-rank test
+ Rank-sum test &amp; runs test

### Treatments vs. Control

+ ANOVA (F test)
    + One-way/Two-way
+ Nonparametric version
    + Kruskal-Wallis Test
    + Friedman Test

]

&lt;img src = "images/ci_fsmrof.png" height = 60&gt;: &amp;Chi;&lt;sup&gt;2&lt;/sup&gt; is adding-up of n square normals representing variances; F is the ratio of two &amp;chi;&lt;sup&gt;2&lt;/sup&gt;s. 

---

&lt;iframe src="https://player.bilibili.com/player.html?aid=842607310&amp;bvid=BV1E54y1r76o&amp;cid=248007878&amp;page=2" scrolling="no" border="0" frameborder="yes" framespacing="0" allowfullscreen="true" height = "600" width = "1000"&gt; &lt;/iframe&gt;

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"highlightSpans": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
